<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[DataDeep]]></title>
  <link href="http://datadeep.ru/atom.xml" rel="self"/>
  <link href="http://datadeep.ru/"/>
  <updated>2015-10-30T15:29:19+03:00</updated>
  <id>http://datadeep.ru/</id>
  <author>
    <name><![CDATA[Команда datadeep.ru]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Тематическое моделирование Игры Престолов]]></title>
    <link href="http://datadeep.ru/blog/2015/10/28/tiematichieskoie-modielirovaniie-ighry-priestolov/"/>
    <updated>2015-10-28T23:59:59+03:00</updated>
    <id>http://datadeep.ru/blog/2015/10/28/tiematichieskoie-modielirovaniie-ighry-priestolov</id>
    <content type="html"><![CDATA[<div>
  <style type="text/css">

    ul{margin:1em 0 1em 2em;}
    ol{margin:1em 0 1em 2em;}

  </style>
</div>

<p>Когда мы имеем дело с большим количеством текстовых документов, первое что нас интересует — о чем эти документы: есть ли между ними что-то общее, о чем каждый из документов, о чем они в целом? Попробуем ответить на эти вопросы, воспользовавшись инструментарием науки о данных. Да не просто так, а на примере серии книг “Песнь Льда и Пламени” (кратко, ПЛиО), по мотивом которой снят не безызвестный сериал “Игра Престолов”.</p>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_tag_cloud.jpg" width="768" height="576" title="КДПВ" /></p>

<!-- more -->

<p>Одно из основных понятий, которое поможет ответить на заданные вопросы —  <em>тема</em>. Тема — это то, о чем говориться в тексте, например, объект его обсуждения. Разумеется, любой может определить основную тему текста, прочитав его. Однако, есть несколько причин поступить иначе. Во-первых, этот процесс достаточно трудоемкий, особенно если учесть потенциально большие коллекции документов (например, весь интернет) — одному человеку все не прочитать. Во-вторых, этот подход субъективный, а хотелось бы получить объективную (а еще лучше, численную) характеристику тематики текста. Наконец, этот блог не о чтении, а об анализе данных. И именно путем анализа данных мы и планируем пойти.</p>

<p>Для автоматического поиска тем в документах мы воспользуемся таким подходом, как <em>тематическое моделирование</em>. Тематическое моделирование — это подраздел машинного обучения, изучающий способы построения <em>тематических моделей</em> по заданному текстовому корпусу. В свою очередь, тематическая модель — это статистическая модель, которая моделирует взаимосвязь наблюдамемых переменных: слов и документов и ненаблюдаемых переменных — тем. Причем, темы строятся (ищутся) автоматически, без участия пользователя (который может лишь задать некоторые параметры модели, например количество тем). </p>

<p>Тем самым, тематическая модель дает ответы на два основных вопроса:</p>

<ol>
  <li>Какие слова образуют каждую из тем?</li>
  <li>К каким темам относится каждый из документов?</li>
</ol>

<p>Причем, тематическая модель отвечает на эти вопросы численно: </p>

<ol>
  <li>Для каждого слова и каждой темы дается численная характеристика важности слова для этой темы.</li>
  <li>Для каждой темы и каждого документа дается численная характеристика, характериизующая роль темы в этом документе.</li>
</ol>

<p>Таким образом, тема фактически задается весами составляющих ее слов. Более того, слова и документы описываются численным вектором в пространстве тем и…, не будем забегать вперед :)</p>

<p>В этой статье мы разберемся в одном из базовых методов тематического моделирования — Латентном Семантическом Анализе (aka, Latent Semantic Analysis, LSA, Latent Semantic Indexing, LSI), затем реализуем его на языке Python, а главное — применим на текстовом корпусе, составленном из книг серии “Песнь Льда и Пламени”. Таким образом, статья состоит из трех частей: теории, практики и результатов. Первая часть не отличается краткостью и может вызвать приступ “T.L.D.R.”, поэтому, если вы знакомы с основами тематического моделирования или же в них не заинтересованы, можете сразу переходить ко второй части. Если же вас интересуют лишь результаты — смело прокручивайте до последней.</p>

<h1 id="section">Часть 1. Теория</h1>

<p>Сначала опишем несколько алгоритмов и подходов, из которых состоит алгоритм тематического моделирования LSA, а затем объеденим их вместе.</p>

<p>Итак, определившись с тем, что мы хотим получить (тематическую модель), остается понять, как же это сделать. Сразу скажу, без математики не обойтись. К сожалению, математике не знакомы понятия “текст”, “документ”, “слово”, “тема” и т.п. Зато, ей хорошо понятен язык чисел и векторов. И именно на язык векторов нам и предстоит перейти для решения нашей задачи. Для этого мы воспользуемся так называемой <em>векторной моделью</em> текста — “переведем” наш корпус с прикладного языка слов и документов на абстрактный язык линейной алгебры.</p>

<h2 id="section-1">Векторная модель</h2>
<p>Векторная модель — модель представления текстовых документов в виде векторов, где каждое измерение вектора-документа соответствует какому-либо слову. Рассмотрим способ построения этой модели.</p>

<p>Итак, на входе у нас коллекция из <script type="math/tex">N</script> документов. Пронумеруем их числами от 1 до <script type="math/tex">N</script> так,  что индексом <script type="math/tex">d \in \{1..N\}</script> обозначается <script type="math/tex">d</script>-й элемент коллекции. Далее, рассмотрим словарь слов — это все уникальные слова, встречающиеся в наших документах. Допустим, таких слов <script type="math/tex">M</script> штук и пронумеруем их от 1 до <script type="math/tex">M</script> индексом <script type="math/tex">w</script>. Теперь, посчитаем сколько раз каждое слово <script type="math/tex">w=1..M</script> входит в каждый документ <script type="math/tex">d=1..N</script> и обозначим это число <script type="math/tex">n_{d,w}</script>. Из этих чисел сформируем матрицу <script type="math/tex">\mathbf{X} = (n_{d,w})_{d,w}</script> — <a href="https://en.wikipedia.org/wiki/Document-term_matrix">матрицу частот слов в документах</a>. Строки этой матрицы соответствуют документам, а столбцы — словам. Скорее всего, эта матрица будет <em>разряженной</em> — большая часть ее элементов будет равна нулю (ведь каждый документ содержит лишь небольшую долю всех слов).</p>

<p>Перевод окончен! Теперь наш текстовый корпус представлен в виде матрицы <script type="math/tex">\mathbf{X}</script>. 
В результате получится матрица выглядящая примерно следующим образом.</p>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_X_matrix_vis.svg" width="384" height="288" title="Матрица документ-слово" /></p>

<p>Стоит заметить, что подобная модель под собой имеет два основных предположения.</p>

<ul>
  <li>Порядок документов в коллекции не имеет значения.</li>
  <li>Порядок слов в документе не имеет значения (т.н. модель “мешка слов” или “bag of words”).</li>
</ul>

<p>Если первое предположение вполне естественно, то второе может показаться неоднозначным. Казалось, даже такая мелочь, как запятая в предложении “казнить нельзя, помиловать” полностью меняет его смысл, что уж говорить о порядке слов даже не в одном предложении, а в нескольких абзацах. Несмотря на это резонное замечание, модель “мешка слов” — одна из наиболее широко используемых и хорошо зарекомендовавшая себя на практике. Тем более это верно для такой задачи, как определение темы. Действительно, как не расставляй слова и знаки препинания в предложении “казнить, нельзя помиловать”, легко понять что речь идет о казни (“казнить” же или “помиловать” — детали).</p>

<h2 id="section-2">Стемминг</h2>
<p>Далее развивая мысль о значимости тех или иных деталей для определения тематики текста, можно заметить, что слово может встречаться в тексте в различных формах: с различными окончаниями и приставками, — но с единым смыслом. Например, неважно какую форму слова мы встретили в тексте: “казнить”, “казнят”, “казнен”, “казню”, “казнишь”, “казни” — все они относятся к теме “казнь”. Именно на нахождение <a href="https://ru.wikipedia.org/wiki/%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%B0_%D1%81%D0%BB%D0%BE%D0%B2%D0%B0">основы слова</a> по той или иной заданной его форме и направлен такой инструмент, как <em>стемминг</em>. 
Здесь мы не будем разъяснять, какие бывают алгоритма стемминга (а их довольно много) и как они работают. Если возникнет интерес, можно начать со 
<a href="https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B5%D0%BC%D0%BC%D0%B8%D0%BD%D0%B3">статьи в википедии</a>. Скажем только, что в дальнейшем мы будем использовать <a href="http://snowball.tartarus.org/">стеммер Snowball</a>, а точнее <a href="http://www.nltk.org/_modules/nltk/stem/snowball.html">его реализацию в NLTK</a>.</p>

<p>Имея в руках стеммер, можно использовать его для преобразования каждого слова каждого документа в его нормальную форму. Тем самым мы, во-первых, значительно уменьшим общее количество слов, а следовательно и вычислительную трудоемкость, а во-вторых, упростим дальнейшую интерпретацию результатов.	</p>

<h2 id="tf-idf">TF-IDF</h2>
<p>TF-IDF — (Term Frequency - Inverse Document Frequency) методика оценки важности слова в документе. Она опирается на два основных предположения</p>

<ol>
  <li>Частота появления слова в документе пропорциональна его важности в этом документе.</li>
  <li>Число документов, в котором встречается слово, обратно пропорционально его важности.</li>
</ol>

<p>Первое предположение вполне логично, а если поразмыслить то и с обоснованием второго не возникнет проблем: возьмем, например, “и” или “а” — они наверняка встретятся в большинстве документов, но на вряд ли привносят что-то в их тематику. Другой пример: возьмем текст новостей, посвященных гражданину N. Естественно, 99.9% из них будут содержать его фамилию в той или иной форме, которая в то же время, будет совершенно бесполезна для определение их темы (в контексте общей темы, посвященной этому гражданину).</p>

<p>Эти два предположения TFIDF учитывает с помощью функций  <script type="math/tex">\mathrm{tf}</script> и <script type="math/tex">\mathrm{idf}</script> соответственно. Задаются они следующим образом</p>

<ul>
  <li><script type="math/tex">\mathrm{tf}(w, d) = n_{w, d}</script> — число вхождений слова <script type="math/tex">w</script> в документ <script type="math/tex">d</script>;</li>
  <li><script type="math/tex">\mathrm{idf}(w) = \log \frac{N}{\lvert \{d \; : \; n_{w, d} > 0\} \rvert }</script> — логарифм обратной доли документов, содержащих слово <script type="math/tex">w</script>.  </li>
</ul>

<p>Итоговая же оценка важности слова <script type="math/tex">w</script> для документа <script type="math/tex">d</script> описывается функцией <script type="math/tex">\mathrm{tfidf}</script>: </p>

<script type="math/tex; mode=display">
\mathrm{tfidf}(w, d) = \mathrm{tf}(w, d) * \mathrm{idf}(w)
</script>

<p>Таким образом, заменяя <script type="math/tex">\mathbf{X} = (n_{d,w})_{d,w}</script> на матрицу <script type="math/tex">\mathbf{X}_{tfidf} = (\mathrm{tfidf}(w, d))_{d, w}</script>, мы понижаем важность слов, встречающихся в большинстве документов и повышаем ее у слов встречающихся в относительно небольшом подмножестве документов.</p>

<h2 id="section-3">Сингулярное разложение</h2>

<p>Потихоньку мы подбираемся к самому интересному. Как же найти ответы на поставленные вопросы?
Напомним, на какие вопросы должна ответить искомая тематическая модель коллекции документов.</p>

<ol>
  <li>Какие слова образуют каждую из тем?</li>
  <li>К каким темам относится каждый из документов?</li>
</ol>

<p>Наша задача — численно ответить на эти вопросы на том же языке, на котором описана матрица документов-слов <script type="math/tex">\mathbf{X}</script>. </p>

<p>Рассмотрим конкретную тему <script type="math/tex">t</script> и представи ответы на вопросы выше (пока гипотетически) в векторном виде:</p>

<ol>
  <li>Вектор <script type="math/tex">u_t \in \mathrm{R}^{N }</script>, <script type="math/tex">d</script>-й элемент которого <script type="math/tex">u_t^{(d)}</script> символизирует близость темы <script type="math/tex">t</script> документу <script type="math/tex">d</script>.</li>
  <li>Вектор <script type="math/tex">v_t \in \mathrm{R}^{M }</script>, <script type="math/tex">w</script>-й элемент которого <script type="math/tex">v_t^{(w)}</script> символизирует важность слова <script type="math/tex">w</script> для темы <script type="math/tex">t</script>. </li>
</ol>

<p>Заметим, что если слово <script type="math/tex">w</script> важно для темы <script type="math/tex">t</script> (<script type="math/tex">v_t^{(w)}</script> велико), а тема <script type="math/tex">t</script> близка документу <script type="math/tex">d</script> (<script type="math/tex">u_t^{(d)}</script> велико), то велико будет и их произведение: <script type="math/tex">u_t^{(d)} v_t^{(w)}</script>. Если же тема <script type="math/tex">t</script> близка документу <script type="math/tex">d</script>, а слово <script type="math/tex">w</script>, напротив, не играет роли в теме <script type="math/tex">t</script> (<script type="math/tex">v_t^{(w)} \sim 0</script>), то и их произведение будет близко к нулю: <script type="math/tex">u_t^{(d)} v_t^{(w)}\sim 0</script>.   Более того, если перемножить два этих вектора, то получившаяся матрица <script type="math/tex">]mathbf{X}_t = u_t v_t^T</script> будет ни чем иным как корпус с единственной темой — темой <script type="math/tex">t</script>. </p>

<p>Развивая эту идею, задачу построения тематической модели можно сформулировать следующим образом: </p>

<blockquote>
  <p>Необходимо найти комбинацию тем $t=1..K$ и соответствующих им векторов <script type="math/tex">u_t</script> и <script type="math/tex">v_t</script>, таких что их комбинация наилучшим образом описывает исходный корпус <script type="math/tex">\mathbf{X}</script>. </p>
</blockquote>

<p>“Наилучшим образом” будем понимать в смысле наименьшего квадратичного отклонения:</p>

<script type="math/tex; mode=display">
	\lvert\lvert X - \sum\limits_{t=1}^K \mathbf{X}_t^\top \rvert\rvert_2 
	 =
	\lvert\lvert X - \sum\limits_{t=1}^K u_t v_t^\top \rvert\rvert_2 
	\longrightarrow 
	\min\limits_{\{u_t, v_t\}_{t=1}^K}.
</script>

<p>Здесь на сцену выходит <em>сингулярное разложение</em> (<em>singular value decomposition</em>, <em>SVD</em>), решающее схожую задачу. Оно заключается в представлении вещественной матрицы <script type="math/tex">\mathbf{X} \in \mathrm{R}^{N\times M}</script>, <script type="math/tex">N > M</script> в виде:</p>

<script type="math/tex; mode=display">
\mathbf{X} = \mathbf{U} \mathbf{S} \mathbf{V}^\top = \sum_{t=1}^{M} s_t u_t v_t^\top,
</script>

<p>где <script type="math/tex">\mathbf{U} \in \mathrm{R}^{N\times M}</script>, <script type="math/tex">\mathbf{V} \in \mathrm{R}^{M\times M}</script> — ортогональные матрицы, состоящие из левых (<script type="math/tex">u_t</script>) и правых (<script type="math/tex">v_t</script>) сингулярных векторов, а <script type="math/tex">\mathbf{S} \in \mathrm{R}^{M\times M}</script> — диагональная матрица, на главной диагонали которой находятся сингулярные числа (<script type="math/tex">s_k</script>).</p>

<p>Сингулярное разложение — одно из важнейших матричных разложений, применяемое во множестве как теоретических, так и практических областей: нахождении псевдообратной матрицы, решении линейных уравнений, снижении размерности, анализе временных рядов, рекомендательных системах и др. В качестве отправной точки можно обратиться к <a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BD%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D0%B7%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5">википедии</a> или довольно наглядной статье на <a href="http://www.ams.org/samplings/feature-column/fcarc-svd">ams.org</a>.</p>

<p>SVD обладает множеством полезных свойтсва. В контексте нашей задачи определения тем в корпусе нам интересны следующие:</p>

<ol>
  <li>Все вектора <script type="math/tex">\{v_t\}</script> имеют длину равную единице и ортогональны друг другу — значит исключена возможность того, что все темы будут друг на друга похожи — в пространстве слов они ортогональны друг другу.</li>
  <li>Сингулярные числа <script type="math/tex">s_t</script> расположены на диагонали матрицы <script type="math/tex">S</script> по убыванию — сперва идут темы обладающие наибольшим вкладом в коллекцию.</li>
  <li>Сингулярные вектора определены с точность до знака: одновременно домножив <script type="math/tex">u_t</script> и <script type="math/tex">v_t</script> на -1 ничего не изменится — значит у каждой темы есть фактически два полюса: один описывается словами (элементами <script type="math/tex">\{v_t\}</script>) с наибольшим положительным весом, а другой — с наибольшим отрицательным.</li>
  <li>Если рассмотреть <em>сокращенное сингулярное разложение</em> (<em>truncated SVD</em>): <script type="math/tex">X_K = \sum_{t=1}^{K} s_t u_t v_t^\top </script>, то это будет <em>наилучшим приближением матрицы <script type="math/tex">X</script> ранга <script type="math/tex">K</script></em> (в терминах <script type="math/tex">\lvert\lvert.\rvert\rvert_2</script> нормы). Это означает, что любой другой набор из <script type="math/tex">K</script> тем, представленный в виде троек <script type="math/tex">\{u_t, s_t, v_t\}_1^K</script> будет хуже описывать наш исходный корпус.</li>
  <li>Так SVD разложение детерменировано, а значения <script type="math/tex">s_t</script> упорядочены, то выбор параметра <script type="math/tex">K</script> не влияет на сами темы — если выбрать <script type="math/tex">K=3</script> и <script type="math/tex">K=100</script>, то первые три темы в обоих случаях будут одинаковы.</li>
</ol>

<p>Довольно-таки неплохо! Учитывая, что это достается нам совершенно бесплатно :) </p>

<p>Подытожим. Имея матрицу <script type="math/tex">\mathbf{X}</script>, все что нам нужно сделать для получения его тематической модели — это выбрать число <script type="math/tex">% &lt;![CDATA[
K < N, M %]]&gt;</script> и воспользоваться truncated SVD:</p>

<script type="math/tex; mode=display">
	U=\mathbf{U}_K, \mathbf{S}_K, \mathbf{V}^\top_K = \mathrm{svd}(\mathbf{X}, K)
</script>

<p>и тогда каждую тройку <script type="math/tex">u_k, s_k, v_k</script> можно будет интерпретировать следующим образом:</p>

<ul>
  <li><script type="math/tex">u_t \in \mathrm{R}^{N}</script> — вектор соответствия темы <script type="math/tex">t</script> каждому из документов <script type="math/tex">d=1..N</script>, чем больше <script type="math/tex">u_t^{(d)}</script> — тем ближе документ <script type="math/tex">d</script> к теме <script type="math/tex">t</script>;</li>
  <li><script type="math/tex">v_t \in \mathrm{R}^{M}</script> — вектор соответствия слов <script type="math/tex">w=1..M</script> теме <script type="math/tex">t</script>, чем больше <script type="math/tex">v_t^{(w)}</script> — тем важнее слово <script type="math/tex">w</script> в теме <script type="math/tex">t</script>;</li>
  <li><script type="math/tex">s_t \in \mathrm{R}</script> — относительный вес темы <script type="math/tex">t</script> в корпусе.</li>
</ul>

<p>Для наглядности мы проиллюстрировали сокращенное сингулярное разложение матрицы документ-слово (крестиками обозначены ненулевые значения).</p>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_SVD_vis.svg" width="768" height="576" title="SVD матрицы документ-слово" /></p>

<p>Стоит отметить, что согласно пятому свойству, “больше” стоит понимать в абсолютном смысле, ведть большое отрицательно число можно легко превратить в большое положительно, домножив соответствующие вектора <script type="math/tex">u_t, v_t</script> на -1.</p>

<h2 id="section-4">Латентный Семантический Анализ</h2>

<p>На этом с математикой покончено! Осталось собрать элементы мозайки воедино. </p>

<p>Латентный семантический анализ фактически является комбинацией описанных ваше методов. Кратко алгоритм можно описать следющим образом.</p>

<ol>
  <li>На входе LSA поступает коллекция текстовых документов.</li>
  <li>Текстовые документы переводятся в матрицу частот слов в документах <script type="math/tex">X</script> посредством векторной модели.</li>
  <li>Элементы матрицы <script type="math/tex">\mathbf{X}</script> взвешиваются посредством TF-IDF: <script type="math/tex">\mathbf{X}_{tfidf} = \mathrm{tfidf}(\mathbf{X})</script>.</li>
  <li>К взвешенной матрице применяется SVD: <script type="math/tex">\mathbf{U}_K, \mathbf{S}_K, \mathbf{V}^\top_K = \mathrm{svd}(\mathbf{X}_{tfidf}, K)</script>.</li>
  <li>Полученные тройки <script type="math/tex">u_t, s_t, v_t</script> используются для интерпретаций тем <script type="math/tex">t=1..K</script>.</li>
</ol>

<p>Как видно, среди этапов алгоритма отсутствует стемминг. Тем не менее, эта операция является де-факто стандартом в задачах тематического моделирования и его мы добавили по собственной инициативе в следующем разделе (можно рассмотреть его в качестве шага алгоритма под номером <script type="math/tex">\frac{1}{2}</script>).</p>

<p>На этом с теорией наконец-то покончено, перейдем к практике!</p>

<h1 id="section-5">Часть 2. Практика</h1>

<p>С чего начать? С получения данных, конечно! Нам нужен текст серии “Песнь Льда и Пламени”, желательно всех вышедших книг. Есть различные схемы, в том числе черные и серые, но есть и белые. Мы воспользовались совершенно белым предложением интернет-магазина litres.ru (на правах рекламы :)), где можно приобрести всю серию по <a href="http://www.litres.ru/serii-knig/pesn-lda-i-ognya/elektronnie-knigi/">довольно привлекательной цене</a> — после этого все книги будут доступны в множестве форматов, в том числе и предпочтительным для нас txt.</p>

<p>Когда книги скачены, можно перейти первому этапу — предобработке данных.</p>

<h2 id="section-6">Предобработка данных</h2>

<p>Сначала, разберем текст книг по главам и посмотрим на их размер по числу слов.</p>

<p>На примере первой книги “Игре Престолов”:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Игра_Престолов</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">0. Пролог 2925
</span><span class="line">1. Бран 2295
</span><span class="line">2. Кейтилин 1643
</span><span class="line">3. Дейенерис 3284
</span><span class="line">4. Эддард 3068
</span><span class="line">...
</span><span class="line">68. Дейенерис 3273
</span><span class="line">69. Тирион 2738
</span><span class="line">70. Джон 3909
</span><span class="line">71. Кейтилин 3641
</span><span class="line">72. Дейенерис 2738
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>и последней на данный момент книге серии — 2-го тома “Танца с Драконами”:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Танец_с_Драконами_2</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">0. Принц Винтерфелла 4564
</span><span class="line">1. Страж 3891
</span><span class="line">2. Джон 2532
</span><span class="line">3. Тирион 3033
</span><span class="line">4. Переметчивый 3441
</span><span class="line">...
</span><span class="line">31. Укротитель драконов 2584
</span><span class="line">32. Джон 3897
</span><span class="line">33. Десница королевы 4106
</span><span class="line">34. Дейенерис 3775
</span><span class="line">35. Эпилог 4518
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Судя по списку глав все верно — текст мы распарсили правильно, двигаемся дальше. Далее нам нужна коллекция документов. В данном случае документы напрашиваются сами собой: возьмем главы каждой книги. Итого у нас получится 345 документов — не так уже и много, но документы внушительных размеров.</p>

<p>Теперь все готово: мы преобразовали исходные тексты в “документы” — объединенные блоки текста. Можно применять LSA.</p>

<h2 id="section-7">Перевод в векторную модель</h2>
<p>Как мы помним, первый этап LSA — перевод документов в векторный вид. 
Начнем с разбиения наших документов на слова и последующий их стемминг</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Разбиение документов на слова</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">re</span>
</span><span class="line"><span class="n">non_letter_rgxp</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">u&#39;[^а-яА-Я ]&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">remove_non_letters</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">doc</span><span class="p">:</span> <span class="n">non_letter_rgxp</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="nn">nltk</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">nltk.stem.snowball</span> <span class="kn">import</span> <span class="n">SnowballStemmer</span>
</span><span class="line">
</span><span class="line"><span class="n">stemmer</span> <span class="o">=</span> <span class="n">SnowballStemmer</span><span class="p">(</span><span class="s">&quot;russian&quot;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">stem</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">docs_tokens</span> <span class="o">=</span> <span class="p">[</span>
</span><span class="line">    <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span> <span class="n">stem</span><span class="p">(</span><span class="n">remove_non_letters</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39; &#39;</span><span class="p">))))</span>
</span><span class="line">    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span>
</span><span class="line"><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Теперь, посчитаем частоту слов</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Подсчет частоты слов</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">collections</span>
</span><span class="line"><span class="n">token_frequency_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
</span><span class="line"><span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">docs_tokens</span><span class="p">:</span>
</span><span class="line">    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
</span><span class="line">        <span class="n">token_frequency_dict</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Взглянем на наиболее часто встречающиеся слова</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Самые частые слова</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">400392 и
</span><span class="line">271847 он
</span><span class="line">261481 не
</span><span class="line">239817 в
</span><span class="line">187947 на
</span><span class="line">134724 с
</span><span class="line">129038 что
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>.., и на самые редкие</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Самые редкие слова</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">3 линнистер
</span><span class="line">3 близя
</span><span class="line">3 персонаж
</span><span class="line">3 нервнич
</span><span class="line">3 свежеоперен
</span><span class="line">3 прожиг
</span><span class="line">3 долженствова
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Как видно, среди часто встречающихся слов довольно много бессмысленных “коротышек”: “а”, “и”, “не” и т.п. От редких же слов больше вреда, чем пользы: они раздувают словарь слов (а значит и размерность будущей матрицы <script type="math/tex">X</script>, делая вычисления более сложными), а в определении темы вряд ли помогут, так как встречаются в считанном числе документов. </p>

<p>Решено! Отфильтруем самые редкие слова, а так же слова маленькой длины:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Фильтрация корпуса по словам</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">docs_tokens_filtered</span> <span class="o">=</span> <span class="p">[</span>
</span><span class="line">    <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">token_frequency_dict</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">5</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
</span><span class="line">    <span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">docs_tokens</span>
</span><span class="line"><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Остается перевести наши разбитые на слова и отфильтрованные документы в векторный вид. Следующий блок кода делает именно это.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Перевод текстовых документов в матрицу частот документ-слов </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">itertools</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">scipy</span> <span class="kn">as</span> <span class="nn">sp</span>
</span><span class="line"><span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">iterators_iterator</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">iterators_iterator</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">all_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">flatten</span><span class="p">(</span><span class="n">paragraphs_tokens_filtered</span><span class="p">))</span>
</span><span class="line">
</span><span class="line"><span class="n">id_token_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">))</span>
</span><span class="line"><span class="n">token_id_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(((</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">id_token_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">doc2vec</span><span class="p">(</span><span class="n">doc_tokens</span><span class="p">,</span> <span class="n">token_id_dict</span><span class="p">):</span>
</span><span class="line">    <span class="n">id_cnt_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">((</span><span class="n">token_id_dict</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">doc_tokens</span><span class="p">))</span>
</span><span class="line">    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">id_cnt_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">docs2csr_matrix</span><span class="p">(</span><span class="n">docs_tokens</span><span class="p">,</span> <span class="n">token_id_dict</span><span class="p">):</span>
</span><span class="line">    <span class="n">docs_vecs</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc2vec</span><span class="p">(</span><span class="n">doc_tokens</span><span class="p">,</span> <span class="n">token_id_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_tokens</span> <span class="ow">in</span> <span class="n">docs_tokens</span><span class="p">]</span>
</span><span class="line">    <span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">flatten</span><span class="p">((((</span><span class="n">id_cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">id_cnt</span> <span class="ow">in</span> <span class="n">doc_vec</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_vec</span> <span class="ow">in</span> <span class="n">docs_vecs</span><span class="p">))))</span>
</span><span class="line">    <span class="n">row_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">flatten</span><span class="p">((((</span><span class="n">doc_ind</span> <span class="k">for</span> <span class="n">id_cnt</span> <span class="ow">in</span> <span class="n">doc_vec</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_ind</span><span class="p">,</span> <span class="n">doc_vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">docs_vecs</span><span class="p">)))))</span>
</span><span class="line">    <span class="n">col_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">flatten</span><span class="p">((((</span><span class="n">id_cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">id_cnt</span> <span class="ow">in</span> <span class="n">doc_vec</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_vec</span> <span class="ow">in</span> <span class="n">docs_vecs</span><span class="p">))))</span>
</span><span class="line">    <span class="k">return</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="n">X</span> <span class="o">=</span> <span class="n">docs2csr_matrix</span><span class="p">(</span><span class="n">docs_tokens_filtered</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Ура, мы в векторе! Получилась матрица 345 на 11467, идем дальше.</p>

<h2 id="tfidf">TFIDF</h2>

<p>Следующим по списку стоит TFIDF. Воспользуемся собственной реализацией.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>TFIDF </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">tfidf</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
</span><span class="line">    <span class="n">idf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">((</span><span class="n">X</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.</span>
</span><span class="line">    <span class="n">idf</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">spdiags</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">idf</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">diags</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span class="line">    <span class="k">return</span> <span class="n">X</span> <span class="o">*</span> <span class="n">idf</span>
</span><span class="line">
</span><span class="line"><span class="n">X_tfidf</span> <span class="o">=</span> <span class="n">tfidf</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="svd">Применение SVD</h2>
<p>На этот раз свой велосипед писать не будем, воспользуемся готовой реализацией для разряженных матриц (а нас как-раз такая) из пакета <a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html">scipy</a>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>SVD </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svds</span><span class="p">(</span><span class="n">X_tfidf</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Вот и все, готово! Давайте посмотрим, какие темы нашел LSA.</p>

<h1 id="section-8">Часть 3. Результаты</h1>

<p>Сперва взглянем на сингулярные числа <script type="math/tex">s_t</script> соответствующую вкладу каждой тему в коллекцию</p>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_singular_values_histogram.png" width="768" height="576" /></p>

<p>Первое собственное число стоит одинокой башней. Неужели есть какая-та настолько “выдающаяся” тема?<br />
Как мы говорили выше, элементы вектора <script type="math/tex">v_t</script> соответствуют вкладу соответствующих слов в тему <script type="math/tex">t</script>. Посмотрим же на самые большие по модулю элементы вектора <script type="math/tex">v_0</script>. Для наглядности мы изобразили наиболее важные слова вместе с соответствующим им значением <script type="math/tex">v_0^{(w)}</script>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Основные слова темы 0</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">+0.30*был +0.24*лорд +0.21*сказа +0.19*сир +0.15*джон +0.15*тирион +0.14*рук +0.12*корол +0.11*больш +0.10*нег +0.10*говор +0.10*нет +0.10*глаз +0.09*брат +0.09*джейм +0.09*над +0.09*под +0.09*меч +0.08*черн +0.08*сэм
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Кажется удивительным, что все элементы одного знака, ни одного отрицательного! Получается такая тема, которой соответствуют все слова без исключения. Но если подумать, то ничего удивительного в этом нет. Вспомним базовую статистику. Если взять множество чисел, какое число будет минимизировать сумму квадратов расстояний от них? Правильно — их среднее. И здесь та же история: фактически, вектор <script type="math/tex">v_0</script> — это среднее по строкам матрицы <script type="math/tex">X_{tfidf}</script>, то есть вектор средних весов слов в нашем корпусе. По этой же причине у этой темы и столь выдаяющаесе собственной число. Исходя из этого, первая собственная тройка с точки зрения определения темы нам мало полезна, так что отбросим ее и вновь взглянем на график собственных чисел.</p>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_singular_values_histogram_without_1st.png" width="768" height="576" /></p>

<p>Теперь сильно выделяющихся тем нет. Далее пойдем по порядку, рассмотрим слова, образующие темы со 1-й по 7-ю (рассмотренную “среднюю” тему считаем за нулевую).</p>

<h2 id="section-9">Темы по документам</h2>

<p>Собственно, что мы ожидаем увидеть, рассматривая главы в качестве документов? Очевидно, что никакой конкретики здесь получить не удастся — главы большие и модель мешка слов стирает всю конкретику, перемешивая в кучу всех героев, события и прочее. Поэтому, наиболее вероятный результат — это что-то, что больше всего различает главы между собой: действующие лица, персонажи, локации. </p>

<p>Для наглядности мы будем визуализировать наиболее важные слова каждой темы облаком тэгов, где размер слова пропорционален его важности. При этом, для каждой темы облако будет два: одно для слов с положительным кладом (его будем рисовать зеленым цветом) и одно для слов с отрицательным (соответственно, красным). А для некоторых еще посмотрим на соответствующие ей документы.</p>

<h3 id="vs--">Тема 1. За Стеной vs Королевская Гавань</h3>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GoT_topic_1.png" width="768" height="576" title="Основные слова темы 1" /></p>

<p>Ого! Почти все самые важные слова темы, что с отрицательные, что положительные — это имена тех или иных персонажей. Похоже наша догадка по поводу того, что лежит в основе различия документов оказалась не далека от истины :). Попробуем проинтерпретировать как “положительную”, так и “отрицательную” часть темы.</p>

<p>Как видно, “положительная” часть посвящена преимущественно Джону и Сэму (“джон” и “сэм”  — самые ярко выраженные слова темы), а так же их похождениям по обе стороны от стены: об этом говорят такие слова, как “одичал”, “крастер”, “лилл”, “черн” и прочие. Так же сюда затесалось немного “ходора” и “брана”, видимо из-за особенностей местности — и одичалые и ходор с браном большую часть времени провели за стеной, а значит и слова описывающие местность у них совпадают (например, “снег”, или “волк”) :). </p>

<p>“Обратная” же тема, судя по словам, соответствует Тириону, а так же другим событиям, относящимся к королевской гавани — этим можно объяснить столь высокий вклад слова “сир”, а так же других ее обитателей: “петир”, “джейм”, “серсе”, “джофф” и т.п.</p>

<p>Соответствующие этой теме главы лишь подтверждают наши выводы:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 1</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 4, Глава 6, Сэмвел
</span><span class="line">Книга 3, Глава 20, Сэмвел
</span><span class="line">Книга 2, Глава 24, Джон
</span><span class="line">Книга 3, Глава 35, Сэмвел
</span><span class="line">Книга 5, Глава 8, Джон
</span><span class="line">Книга 1, Глава 53, Джон
</span><span class="line">Книга 4, Глава 27, Сэмвел
</span><span class="line">Книга 3, Глава 48, Сэмвел
</span><span class="line">Книга 3, Глава 17, Джон
</span><span class="line">Книга 3, Глава 77, Сэмвел
</span><span class="line">Книга 1, Глава 27, Джон
</span><span class="line">Книга 3, Глава 57, Джон
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 1 &#8220;наоборот&#8221;</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 3, Глава 62, Тирион
</span><span class="line">Книга 1, Глава 63, Тирион
</span><span class="line">Книга 3, Глава 68, Тирион
</span><span class="line">Книга 3, Глава 21, Тирион
</span><span class="line">Книга 2, Глава 42, Тирион
</span><span class="line">Книга 1, Глава 39, Тирион
</span><span class="line">Книга 2, Глава 4, Тирион
</span><span class="line">Книга 1, Глава 32, Тирион
</span><span class="line">Книга 4, Глава 28, Джейме
</span><span class="line">Книга 5, Глава 28, Тирион
</span><span class="line">Книга 3, Глава 69, Джейме
</span><span class="line">Книга 4, Глава 25, Серсея
</span><span class="line">Книга 3, Глава 6, Тирион
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="vs---1">Тема 2. Бес vs Луковый рыцарь</h3>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GoT_topic_2.png" width="768" height="576" title="Основные слова темы 2" /></p>

<p>Здесь “позитивная” тема похоже на тему Тириона. Сюда же “затесался” Джон: по сюжету Тирион и Джон Сноу пересекались в 1-ой книге, в Винтерфелле, а так же по дороге и на самой Стене. 
Но, если взглянуть на cоответствующие документы, то помимо 1-ой главы можно увидеть, например и 5-ую. Как объяснить 5-ую книгу серии? Дело в том, что Джон в книге не один: в 5-ой книге Тирион плыл с Джоном Когннингтоном по прозвищу “Грифф”. В пользу этой версии говорит и слово “грифф”.</p>

<p>Альтернативная тема по большей части посвящена Давосу. Здесь же сильны и признаки Дейнерис Бурерожденной: “ден”, “кхал”, “дракон”, “дрог”. Если вглядется, то можно увидеть всего по немножку: “бриен”, “ходор”, “бран”, “виктарион” и прочие. Одной из причин связи линии Давоса и линии Дейнерис может быть “дракон”: Драконий Камень, где расположен замок Станниса и настоящие драконы Дени. Тем не менее, основной в этой теме — Давос, что и подтверждают основные документы ниже. </p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 2</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 1, Глава 63, Тирион
</span><span class="line">Книга 3, Глава 62, Тирион
</span><span class="line">Книга 1, Глава 39, Тирион
</span><span class="line">Книга 3, Глава 68, Тирион
</span><span class="line">Книга 1, Глава 32, Тирион
</span><span class="line">Книга 1, Глава 22, Тирион
</span><span class="line">Книга 5, Глава 2, Тирион
</span><span class="line">Книга 2, Глава 4, Тирион
</span><span class="line">Книга 5, Глава 23, Тирион
</span><span class="line">Книга 5, Глава 28, Тирион
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 2 &#8220;наоборот&#8221;</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 2, Глава 43, Давос
</span><span class="line">Книга 2, Глава 59, Давос
</span><span class="line">Книга 2, Глава 11, Давос
</span><span class="line">Книга 3, Глава 12, Давос
</span><span class="line">Книга 3, Глава 38, Давос
</span><span class="line">Книга 3, Глава 56, Давос
</span><span class="line">Книга 2, Глава 1, Пролог
</span><span class="line">Книга 3, Глава 65, Давос
</span><span class="line">Книга 3, Глава 27, Давос
</span><span class="line">Книга 5, Глава 16, Давос
</span><span class="line">Книга 5, Глава 10, Давос
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="section-10">Тема 3. Узкое море</h3>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GoT_topic_3.png" width="768" height="576" title="Основные слова темы 3" /></p>

<p>Здесь с положительной темой никаких сомнений нет: сплошная Дейнерис. Отрицательная тема интересней — основной здесь выступает Кейтелин Старк, но присутствуют и “давос”, “робб”, “санса”, “алейн”, “джейм”, “джон”, “станнис” и т.д. И если присутствие большинства из них вполне объяснимо, то персонажи линии Станниса (“давос”, “станнис”, “мелисандр”) объяснить сложно. Получается в некотором смысле “глобальная” тема, охватывающая Старков, Фреев, Ланнистеров, Талли, Баратеонов, Грейджоев, Болтонов — почти всех обитателей Вестероса. </p>

<p>Это наталкивает на мысль, что эта тема — совего рода Узкое море — разделяет миры Вестероса и Эссоса. В пользу этого говорят и такие слова “положительной” части, как: “квентин”, “астапор”, “миэрин”. В этом смысле, забавно, что “положительная” часть так же включает слово “вестерос” — видимо на востоке от Узкого моря о вестеросе вспоминают чаще, чем в нем самом :)</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 3</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 1, Глава 65, Дейенерис
</span><span class="line">Книга 3, Глава 25, Дейенерис
</span><span class="line">Книга 3, Глава 73, Дейенерис
</span><span class="line">Книга 3, Глава 44, Дейенерис
</span><span class="line">Книга 3, Глава 59, Дейенерис
</span><span class="line">Книга 5, Глава 3, Дейенерис
</span><span class="line">Книга 5, Глава 17, Дейенерис
</span><span class="line">Книга 1, Глава 47, Дейенерис
</span><span class="line">Книга 1, Глава 24, Дейенерис
</span><span class="line">Книга 3, Глава 10, Дейенерис
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 3 &#8220;наоборот&#8221;</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 4, Глава 42, Алейна
</span><span class="line">Книга 4, Глава 24, Алейна
</span><span class="line">Книга 4, Глава 11, Санса
</span><span class="line">Книга 2, Глава 43, Давос
</span><span class="line">Книга 1, Глава 60, Кейтилин
</span><span class="line">Книга 1, Глава 35, Кейтилин
</span><span class="line">Книга 3, Глава 51, Кейтилин
</span><span class="line">Книга 2, Глава 40, Кейтилин
</span><span class="line">Книга 1, Глава 72, Кейтилин
</span><span class="line">Книга 3, Глава 21, Тирион
</span><span class="line">Документы
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="vs---">Тема 4. Контрабандист vs Ходор и Бран</h3>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GoT_topic_4.png" width="768" height="576" title="Основные слова темы 4" /></p>

<p>“Положительная” тема здесь — еще одна тема Давоса. Однако, здесь помимо Давоса выделяются “сэм” и “тирион”. Если с первым все объяснимо — Станнис довольно долго гостил на Стене у ночного дозора, то с Тирионом найти объяснение нелегко. Возможно, здесь роль сыграла битва при Черноводной: благо что “черноводн” среди списка слов встречается.</p>

<p>“Отрицательная” тема же здесь проста — практически все в ней относится к Ходору с Браном. </p>

<p>Список документов в данном случае ничего интересно не привноситю </p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 4</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 2, Глава 43, Давос
</span><span class="line">Книга 2, Глава 59, Давос
</span><span class="line">Книга 2, Глава 11, Давос
</span><span class="line">Книга 3, Глава 12, Давос
</span><span class="line">Книга 3, Глава 38, Давос
</span><span class="line">Книга 3, Глава 56, Давос
</span><span class="line">Книга 3, Глава 65, Давос
</span><span class="line">Книга 3, Глава 27, Давос
</span><span class="line">Книга 5, Глава 16, Давос
</span><span class="line">Книга 2, Глава 1, Пролог
</span><span class="line">Книга 5, Глава 10, Давос
</span><span class="line">Книга 3, Глава 7, Давос
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 4 &#8220;наоборот&#8221;</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 3, Глава 58, Бран
</span><span class="line">Книга 1, Глава 38, Бран
</span><span class="line">Книга 1, Глава 54, Бран
</span><span class="line">Книга 2, Глава 17, Бран
</span><span class="line">Книга 1, Глава 25, Бран
</span><span class="line">Книга 5, Глава 35, Бран
</span><span class="line">Книга 3, Глава 42, Бран
</span><span class="line">Книга 2, Глава 70, Бран
</span><span class="line">Книга 3, Глава 11, Бран
</span><span class="line">Книга 5, Глава 14, Бран
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="vs----1">Тема 5. Не совсем Бран vs Джейм и Бриенна</h3>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GoT_topic_5.png" width="768" height="576" title="Основные слова темы 5" /></p>

<p>Здесь “положительная” тема вновь похожа на винегрет: с одной стороны, лидирует “бран”, а с другой по пятам за ним следуют “тирион” и “давос”. И хоть Бран в этой теме явно доминирует (как-никак, первые девять глав темы — главы Брана), объяснить столь большой вес у слов “тирион” и “давос” непросто. Участие Тириона можно обяснить первой книгой, где он сначала пребывает в Винтерфелле, а затем путешествует на стену и там, в том числе, обсуждает Брана с Джоном Сноу. Присутствие Давос совсем загадочно. Единственное, что приходит на ум — все та же битва при Черноводной, тем более что 59-ая глава 2-ой книги посвящена именно ей.</p>

<p>“Отрицательная” тема, опять же, проста: ее документы относятся к Джейме Ланнистеру и Бриенне Тарт c легким оттенком Сансы Старк (Алейны Стоун), что понятно.</p>

<p>Документы этих тем:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 5</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 3, Глава 58, Бран
</span><span class="line">Книга 1, Глава 25, Бран
</span><span class="line">Книга 1, Глава 54, Бран
</span><span class="line">Книга 3, Глава 42, Бран
</span><span class="line">Книга 1, Глава 38, Бран
</span><span class="line">Книга 2, Глава 17, Бран
</span><span class="line">Книга 5, Глава 35, Бран
</span><span class="line">Книга 2, Глава 70, Бран
</span><span class="line">Книга 5, Глава 14, Бран
</span><span class="line">Книга 1, Глава 63, Тирион
</span><span class="line">Книга 3, Глава 11, Бран
</span><span class="line">Книга 2, Глава 59, Давос
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 5 &#8220;наоборот&#8221;</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 4, Глава 5, Бриенна
</span><span class="line">Книга 4, Глава 10, Бриенна
</span><span class="line">Книга 4, Глава 21, Бриенна
</span><span class="line">Книга 4, Глава 28, Джейме
</span><span class="line">Книга 4, Глава 15, Бриенна
</span><span class="line">Книга 4, Глава 42, Алейна
</span><span class="line">Книга 4, Глава 43, Бриенна
</span><span class="line">Книга 3, Глава 46, Джейме
</span><span class="line">Книга 3, Глава 69, Джейме
</span><span class="line">Книга 4, Глава 34, Джейме
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="vs---2">Тема 6. Сэм Тарли vs Джон Сноу</h3>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GoT_topic_6.png" width="768" height="576" title="Основные слова темы 6" /></p>

<p>Эта тема довольно интересна: в отличие от предыдущих здесь Сэм и Джон встречаются не вместе, а напротив, противопоставляются друг другу! Так, документы “положительной” относятся к похождениям и мыслям Сэма (и чуточку Брана), а “отрицательная” подтема полностью относится к Джону Сноу. </p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 6</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 3, Глава 20, Сэмвел
</span><span class="line">Книга 4, Глава 27, Сэмвел
</span><span class="line">Книга 3, Глава 48, Сэмвел
</span><span class="line">Книга 3, Глава 35, Сэмвел
</span><span class="line">Книга 4, Глава 6, Сэмвел
</span><span class="line">Книга 4, Глава 36, Сэмвел
</span><span class="line">Книга 4, Глава 46, Сэмвел
</span><span class="line">Книга 4, Глава 16, Сэмвел
</span><span class="line">Книга 3, Глава 58, Бран
</span><span class="line">Книга 3, Глава 77, Сэмвел
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 6 &#8220;наоборот&#8221;</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 3, Глава 17, Джон
</span><span class="line">Книга 3, Глава 75, Джон
</span><span class="line">Книга 3, Глава 57, Джон
</span><span class="line">Книга 3, Глава 43, Джон
</span><span class="line">Книга 6, Глава 17, Джон
</span><span class="line">Книга 6, Глава 22, Джон
</span><span class="line">Книга 3, Глава 9, Джон
</span><span class="line">Книга 1, Глава 20, Джон
</span><span class="line">Книга 3, Глава 71, Джон
</span><span class="line">Книга 3, Глава 66, Джон
</span><span class="line">Книга 3, Глава 28, Джон
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="vs----2">Тема 7. Петир и Санса vs Джейме и Бриенна</h3>

<p><img src="http://datadeep.ru/images/2015-09_TopicModelling_GameOfThrones/GoT_topic_7.png" width="768" height="576" title="Основные слова темы 7" /></p>

<p>Эта тема интерпретируется так же легко, как и предыдущая. “Положительная” часть относится к главам главам Сансы Старк (Алены Стоун) и Петира Бейлиша — к этому и “лиза” и “роберт” и “нестор”.
“Отрицательная” же — еще одна относящаяся к Джейме и Бриенне, но на этот раз без примеси Сансы, Сэма и прочих.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 7</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 4, Глава 42, Алейна
</span><span class="line">Книга 4, Глава 24, Алейна
</span><span class="line">Книга 4, Глава 11, Санса
</span><span class="line">Книга 3, Глава 70, Санса
</span><span class="line">Книга 3, Глава 82, Санса
</span><span class="line">Книга 1, Глава 16, Санса
</span><span class="line">Книга 3, Глава 8, Санса
</span><span class="line">Книга 1, Глава 52, Санса
</span><span class="line">Книга 3, Глава 30, Санса
</span><span class="line">Книга 1, Глава 35, Кейтилин
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Документы темы 7 &#8220;наоборот&#8221;</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Книга 4, Глава 21, Бриенна
</span><span class="line">Книга 4, Глава 10, Бриенна
</span><span class="line">Книга 3, Глава 46, Джейме
</span><span class="line">Книга 4, Глава 5, Бриенна
</span><span class="line">Книга 4, Глава 28, Джейме
</span><span class="line">Книга 3, Глава 3, Джейме
</span><span class="line">Книга 4, Глава 43, Бриенна
</span><span class="line">Книга 4, Глава 15, Бриенна
</span><span class="line">Книга 3, Глава 13, Джейме
</span><span class="line">Книга 3, Глава 23, Джейме
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h1 id="section-11">Заключение</h1>

<p>Мы рассмотрели теорию и практику тематического моделирования, а точнее метода LSA. Более того, мы применили его на тексте книг серии “Песнь Льда и Пламени” и получили очень даже неплохой результат! Действительно: рассмотренные нами темы естественно интерпретируются и довольно-таки неплохо описывают взаимодействия персонажей игры престолов. Еще более удивительно, что имена персонажей оказываются наиболее важными для определения тем, впрочем возможные причиные этого мы обсудили. </p>

<p>Как же на практике использовать тематическое моделирование? Во-первых, наиболее очевидное применение — для интерпретиации текста. Допустим мы не читали киниги и вообще ничего не слышали про Игру Престолов, тогда применив LSA к исходным текстам книг ПЛиО мы, выделив основные темы, узнали основных персонажей, их взаимосвязь с друг-другом, а так же связанные с ними понятия (например, слова соответствующие местности). Во-вторых, получившееся представление документов в виде векторов в пространстве тем <script type="math/tex">u_{\cdot}^{(d)}</script> можно использовать для дальнейшего анализа в других алгоритмах. Например, для решения более сложных задач машинного обучения: кластеризации документов, их классификации и т.д.</p>

<p>Стоит отметить, что  LSA является одним из самых базовых методов тематического моделирования. Среди его недостатков можно отметить следующие</p>

<ol>
  <li>Сложность интерпретации полюсов тем. Наличие “отрицательного” и “положительного” полюса у каждой темы контринтуитивно — пользователю приходится либо интерпретировать тему как набор свойственных и <strong>не</strong> свойственных теме слов, либо рассматривать одну тему LSA как две темы (так делали и мы).</li>
  <li>Сложность интерпретации ненормированных значений. <script type="math/tex">u_t^{(d)}</script> и <script type="math/tex">v_t^{(w)}</script> могут принимать любое значение от <script type="math/tex">-\infty</script> до <script type="math/tex">\infty</script>, тем самым сложно понять, например, какое значение <script type="math/tex">v_t^{(w)}</script> можно назвать “большим”, а какое “маленьким”.</li>
  <li>Сильные ограничения на формы тем. Темы, которые ищет LSA подчиняняются строгим законам: каждая тема должна описывать корпус <script type="math/tex">\mathbf{X}</script> наилучшим образов в смысле нормы Фробениуса за вычетом предыдущих, темы строго ортогональны друг другу, упорядочены по значению своего вклада, — все это значительно ограничивает ту “форму” тем, которая может быть найдена алгоритмом LSA в исходном пространстве слов. Так, например, если настоящая структура тем в документах имеет вид <a href="http://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/24616/versions/10/screenshot.jpg">схожих по размеру кластеров</a>, то LSA не удастся её выявить.</li>
</ol>

<p>В связи с этим, в последние годы методы тематического моделирования активно развиваются. Так, в 1999 году был предложен метод <a href="https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis">PLSA</a>, которыйй можно рассмотреть как “перевод” LSA на вероятностный язык.  2003 был предложен метод <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">LDA</a>, далее развивающий идею <em>вероятностного тематического моделирования</em>. Короче говоря, область не стоит на месте и активно развивается, а новые методы и их развития и/или обобщения появляются регулярно.</p>

<p>Если вас заинтересовал тема тем (прошу прощения за дурной каламбур) в “Песни Льда и Пламени”, то по <a href="https://gist.github.com/Obus/059805567893ba70dc22">ссылке</a> доступны по 20 наиболее важных слов для первых 150 тем. Если же хочется поиграться с темами самостоятельно, то в качестве отправных точек могу посоветовать следующее</p>

<ol>
  <li><a href="https://github.com/Obus/Topic_Modelling_Game_of_Thrones/blob/master/Song%20of%20Ice%20and%20Fire%20Topic%20Modelling.ipynb">IPython Notebook</a> с кодом для этой статьи и полученными результатами.</li>
  <li>Python пакет <a href="https://radimrehurek.com/gensim/">gensim</a>, содержащий как вспомогательный инструменты для создания корпуса, реализацию LSA, так и реализации гораздо более сложных, но и интересных методов тематического моделирования</li>
  <li><a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5">Статья</a> на machinelearning.ru, там же <a href="http://www.machinelearning.ru/wiki/images/2/22/Voron-2013-ptm.pdf">материалы</a> <a href="https://www.google.ru/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=4&amp;cad=rja&amp;uact=8&amp;ved=0CDgQFjADahUKEwjgoJvAuqbIAhWGCiwKHaGtAis&amp;url=http%3A%2F%2Fwww.machinelearning.ru%2Fwiki%2Findex.php%3Ftitle%3D%25D0%2592%25D0%25B5%25D1%2580%25D0%25BE%25D1%258F%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D0%25BD%25D1%258B%25D0%25B5_%25D1%2582%25D0%25B5%25D0%25BC%25D0%25B0%25D1%2582%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B5_%25D0%25BC%25D0%25BE%25D0%25B4%25D0%25B5%25D0%25BB%25D0%25B8_(%25D0%25BA%25D1%2583%25D1%2580%25D1%2581_%25D0%25BB%25D0%25B5%25D0%25BA%25D1%2586%25D0%25B8%25D0%25B9%252C_%25D0%259A.%25D0%2592.%25D0%2592%25D0%25BE%25D1%2580%25D0%25BE%25D0%25BD%25D1%2586%25D0%25BE%25D0%25B2)&amp;usg=AFQjCNHXh1sFBsjj9wVs3W7S5qn7gmoDmA&amp;sig2=G-MlJOF4N2orS105uZcisQ&amp;bvm=bv.104317490,d.bGg">курса по вероятностным тематическим моделям</a>.</li>
</ol>

<p>Надеюсь, вам было интересно :) В последующих статьях, быть может, мы продолжим тему автоматического анализа текстов Игры Престолов и постараемся вытащить из текстов книг ПЛиО что-нибудь менее тривиальное, чем факт знакомства Джона Сноу и Сэма Тарли. Если вы не прочь прочитать продолжение — смело лайкайте эту статью во всех возможных соцсетях :)</p>

<p>До встречи!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Многообразие визуализаций]]></title>
    <link href="http://datadeep.ru/blog/2015/09/02/mnoghoobraziie-vizualizatsii/"/>
    <updated>2015-09-02T19:47:49+03:00</updated>
    <id>http://datadeep.ru/blog/2015/09/02/mnoghoobraziie-vizualizatsii</id>
    <content type="html"><![CDATA[<div>
  <style type="text/css">

    ul{margin:1em 0 1em 2em;}
    ol{margin:1em 0 1em 2em;}

  </style>
</div>

<p>Визуализация является важной частью Data Science, представляя собой удобный интерфейс между данными и человеком. Но различные ее виды встречаются не только в науке о данных. Чтобы обозначить контекст, в котором существует визуализация <em>данных</em>, я покажу разнообразие жанров визуализации <em>вообще</em>, забираясь в миры естественных наук и даже искусства.    </p>

<p><img src="http://datadeep.ru/images/teaser.png" width="768" height="576" title="Иллюстрации из книги Эрнста Геккеля &#34;Красота форм в морских глубинах&#34;" alt="Иллюстрации из книги Эрнста Геккеля &#34;Красота форм в морских глубинах&#34;" /></p>

<!-- more -->

<p>В пайплайне науки о данных визуализация встречается преимущественно в двух ситуациях: для первичного анализа данных и для представления полученных результатов после окончания работы.</p>

<p>В связи с этим существует условное деление графики на исследовательскую (exploratory) и презентационую (explanatory).
Первая должна помогать в работе, вторая – нести внятное сообщение. </p>

<p>Такое деление достаточно грубое и в жизни чаще встречаются промежуточные варианты.
Для нас важно то, что у этих видов графики различные цели.
От целей мы и будем отталкиваться в разговоре о многообразии. Я рассмотрю следующие жанры:</p>

<ul>
  <li>Научная визуализация</li>
  <li>Исследовательская графика</li>
  <li>Аналитическая графика</li>
  <li>Презентационная графика</li>
  <li>Инфографика</li>
  <li>Скетч</li>
  <li>Data art.</li>
</ul>

<h2 id="section">Научная визуализация</h2>

<p>Визуализация в науке нужна для иллюстрации и интерпретации научных результатов.
Она помогает показать то, что иначе невозможно, либо очень сложно увидеть.</p>

<p>Это может быть что-то слишком большое (карта мира) или что-то слишком маленькое (модель атома), то, что невозможно увидеть (инфракрасное излучение, биополе:))) или что сложно достать (человеческие органы).
Визуализироваться могут этапы временного развития (развитие эмбриона) или коллекция  образцов, собранная в разных точках Земли. 
С помощью графического отображения можно упорядочить элементы реального мира или изобразить что-то, в природе не встречающееся (результаты компьютерного моделирования, математические объекты).</p>

<p>Стоит заметить, что картинки сильно различаются в зависимости от специфики научной области и задачи. Посмотрим на некоторые примеры из различных наук.</p>

<p><strong>Медицина</strong> </p>

<p><img src="http://datadeep.ru/images/Medical.png" title="Снимок УЗИ. Рисунок Леонардо да Винчи. Компьютерная модель сердца" /></p>

<p><strong>География</strong></p>

<p><img src="http://datadeep.ru/images/Geographic.png" title="Карты: геологическая, географическая и политическая" /></p>

<p><strong>Астрономия</strong> </p>

<p><img src="http://datadeep.ru/images/Astronomy.png" title="Зарисовки пятен на Солнце. Фотография Вселенной" /></p>

<p><strong>Химия</strong> </p>

<p><img src="http://datadeep.ru/images/Chemistry.png" title="Модель молекулы ДНК. Таблица Менделеева" /></p>

<p><strong>Физика</strong></p>

<p><img src="http://datadeep.ru/images/Physics.png" title="Симуляция смешивания жидкостей. Использование визуалицации в самолетосторении" /></p>

<p><strong>Математика</strong> </p>

<p><img src="http://datadeep.ru/images/Math.png" title="Архимед чертит геометрические фигуры на песке. Компьютерная визуализация аттрактора Лоренца" /></p>

<p>Как видно из этих иллюстраций, с течением времени меняются методы и возможности графического отображения. 
Этот вид визуализации появился одним из первых и всегда находится на переднем краю технологического прогресса.</p>

<p>Подробнее об актуальных направлениях можно почитать в <a href="http://en.wikipedia.org/wiki/Scientific_visualization">статье на Википедии</a> (русскоязычная версия отсутствует). На русском можно почитать материалы конференции <a href="http://www.graphicon.ru">Графикон</a> и журнал <a href="http://sv-journal.org">“Научная визуализация”</a>.</p>

<h2 id="section-1">Исследовательская (разведочная) графика</h2>

<p>Если до этого мы говорили о естественных науках и чистой математике, то теперь вернемся к тематике нашего блога и обратимся к науке о данных. Для начала рассмотрим примеры визуализаций, создаваемых на этапе исследования данных. Они делаются для персонального использования и нужны в первую очередь для анализа.</p>

<p>Этот этап по английски называется exploratory data analysis, в русскоязычной литературе встречаются термины “описательная статистка” и  “разведочный анализ данных”. Понятие ввел Дж. Тьюки в своей книге “Анализ результатов наблюдений”, в основу которой положен принцип:    </p>

<blockquote>
  <p>“Важно понять, что́ вы можете делать, прежде чем вы научитесь измерять, насколько хорошо вы это сделали.”</p>
</blockquote>

<p>Книга написана в 1977 году  и изложенные в ней методы уже не актуальны. Основными инструментами ему служили математические таблицы, логарифмическая линейка, миллиметровка и калька. Но принципы построения полезных графиков с тех пор не изменились. Вот еще одна важная цитата из книги:</p>

<blockquote>
  <p>“Графики, подчеркивающие лишь то, что нам уже известно, нередко не стоят места, которое они занимают. Графики, которые надо рассматривать с лупой, чтобы увидеть в них главное, заставляют нас тратить понапрасну время и мало полезны. График имеет наибольшую ценность тогда, когда он <em>вынуждает</em> нас заметить то, что мы совсем не ожидали увидеть.”</p>
</blockquote>

<p>Разведочный анализ — фундамент исследования данных. Графики на этом этапе позволяют решать следующие задачи:</p>

<ul>
  <li>понять свойства данных;</li>
  <li>выявить ошибки;</li>
  <li>определить взаимосвязи между переменными;</li>
  <li>обнаружить закономерности;</li>
  <li>предложить стратегии моделирования.</li>
</ul>

<p>Такие графики делаются быстро и в большом количестве. При этом не уделяется внимание легенде, осям, цветам и прочим элементам оформления.
	    Рассмотрим несколько примеров.</p>

<p>Пример 1: иногда визуальная оценка позволяет найти ошибки кластеризации и помогает подобрать правильный алгоритм.</p>

<p><img src="http://datadeep.ru/images/explore-2.png" /></p>

<p>Пример 2: визуализация при исследовании регрессии – иллюстрация <a href="https://ru.wikipedia.org/wiki/Парадокс_Симпсона">парадокса Симпсона</a>.</p>

<p><img src="http://datadeep.ru/images/explore-1.png" /></p>

<p>Пример 3: построение гистограмм для различных признаков – один из шагов в первичном исследовании данных.</p>

<p><img src="http://datadeep.ru/images/hist.png" /></p>

<p>Пример 4: график поведения функции потерь помогает выбрать оптимальное значение параметра алгоритма обучения с учителем</p>

<p><img src="http://datadeep.ru/images/nn_epochs.png" /></p>

<p>В следующих статьях мы подробнее рассмотрим инструменты, которые позволяют быстро проводить подобный визуальный анализ.</p>

<p>Как уже отмечалось ранее, графики из этой категории могут быть понятны только самому автору, так как не содержат необходимых пояснений и не предназначены для широкой аудитории.
Подобные диаграммы - инструмент ученого или аналитика. Их место на рабочем компьютере.
Стоит публиковать такие изображения только после некоторой доработки.</p>

<h2 id="section-2">Аналитическая графика</h2>

<p>Это промежуточный этап между исследованием и презентацией. А если точнее, то это презентация, которая не дает готовых выводов, но  предоставляет читателю возможность исследовать данные  и делать выводы самостоятельно.</p>

<p>Это, возможно, самый сложный для создания, но и самый интересный тип визуализации. Он объединяет в себе строгость в отношении к исходным данным и визуальную привлекательность. Много интересного можно почерпнуть из книг Эдварда Тафти. Он является ведущим современным специалистом в области визуализации, написал несколько книг по отображению информации.</p>

<p>Приведу здесь список принципов для аналитической графики по его книге Beautiful Evidence (глава The Fundamental Principles of Analytical Design)</p>

<ol>
  <li>Показывать сравнения;</li>
  <li>Показывать механизм, объяснение, структуру (причинно-следственные связи);</li>
  <li>Показывать многомерные данные;</li>
  <li>Объединять типы представления (разные графики, текст) в единое представление;</li>
  <li>Документация: пояснять данные с помощью легенды, масштабов, указания на источники;</li>
  <li>Содержание превыше всего.</li>
</ol>

<p>Рассмотрим несколько классических примеров. 
Основателем графических методов в статистике считается шотландский инженер и политэконом Уильям Плейфер. Его работы относятся к концу 18 - началу 19 века. На рисунке ниже представлены линейчатый график и гистограмма из работы “Коммерческий и политический атлас”  1786 года.</p>

<p><img src="http://datadeep.ru/images/Playfair.png" /></p>

<p>Диаграмма французского инженера Шарля Минара (Charles Minard) о походе Наполеона в Россию — отличная иллюстрация изложенных выше принципов. На схеме мы видим изменение численности французской армии по мере наступления на Москву (бежевый цвет) и последующего отступления (черный цвет). Для отступления прилагается график изменения температуры. Диаграмма снабжена пояснениями, подписями населенных пунктов и рек.</p>

<p><img src="http://datadeep.ru/images/Minard.jpg" /></p>

<p>Диаграмма Флоренс Найтингейл — одна из первых круговых диаграмам. С ее помощью сестра милосердия продемонстрировала, что в британской армии от антисанитарии умирает больше людей, чем от ранений.</p>

<p><img src="http://datadeep.ru/images/Nightingale-mortality.jpg" />	    </p>

<p>Графика этого типа отлично подходит для научной статьи, сайта в интернете или раздаточного материала.</p>

<p>На современные примеры аналитической графики повлияло развитие браузеров, поддерживающих анимацию и интерактивность. Более того, такая визуализация доступна любому пользователю сети.
С помощью интерактива можно группировать и фильтровать данные, рассматривать их в разном масштабе — от общей картины до частностей.
Много примеров такой графики создано с помощью Javascript библиотеки <a href="http://d3js.org">D3.js</a>. Хорошей иллюстрацией является <a href="http://white-nights.datalaboratory.ru">визуализация марафона “Белые ночи”</a> от Лаборатории данных.</p>

<p><img src="http://datadeep.ru/images/maraphon.png" />	    </p>

<p>Cоздающий подобную графику человек должен разбираться не только в данных и предметной области, но и в особенностях восприятия человеком визуальных образов, а еще в человеко-компьютерном взаимодействии.</p>

<p>Распространенным применением аналитической визуализации являются дэшборды — информационные панели, содержащие графики основных показателей. Они часто используются в бизнесе для мониторинга, создания отчетности и при принятии решений. Приведенный на картинке пример сделан с помощью сервиса <a href="http://www.tableau.com">Tableu</a>.</p>

<p><img src="http://datadeep.ru/images/Dashboard.png" />	    </p>

<p>Еще один замечательный пример интерактивного исследования данных — приложение <a href="http://www.gapminder.org">Gapminder</a>.
Пузырьковая диаграмма, демонстрирующая изменения экономических и социальных показателей для стран мира за последние десятилетия.</p>

<p><img src="http://datadeep.ru/images/hans-rosling.jpg" />	    </p>

<p>Стоит посмотреть шикарную <a href="http://www.youtube.com/watch?v=hVimVzgtD6w">первую презентацию</a>  этой программы ее автором — шведским профессором Хансом Рослингом на конференции TED. Это тот редкий случай, когда сложная графика на экране становится понятной благодаря анимации и сильному выступлению докладчика. Последующие выступления Рослинга также заслуживают внимания, в том числе с точки зрения наглядного изображения информации.</p>

<p>Самое время перейти к презентационной графике.</p>

<h2 id="section-3">Презентационная графика</h2>

<p>Здесь мы говорим о презентации в чистом виде, когда график несет в себе одну идею, недвусмысленное сообщение автора.
Отличие от аналитической графики заключается в том, что читатель не должен расшифровывать ваше послание, так как условия просмотра подобных изображений не предполагают длительного изучения.
Такую графику можно увидеть на слайдах презентации или по телевизору. Иногда простые графики встречаются в печатных изданиях.</p>

<p>При внешней простоте создать эффективную презентационную графику бывает непросто.</p>

<p>Для начала, важно подобрать подходящий <strong>тип диаграммы</strong>, который донесет нашу мысль наиболее наглядно.
 Много полезных советов о выборе типа графика можно найти в книге Джина Желязны “Говори на языке диаграмм”. Книга построена как учебник со множеством примеров и упражнений.</p>

<p>Далее, надо учесть <strong>контекст</strong> восприятия и не перегрузить диаграмму данными.
Обычно у зрителя нет возможности внимательно исследовать график. 
Очень часто люди показывают на слайдах непонятные, перегруженные текстом и данными графики, которые практически невозможно объяснить.</p>

<p>В качестве примера приведу иллюстрацию из замечательной книги Алексея Каптерева “Мастерство презентации”.
Так он представляет типичный слайд с графиком из корпоративной презентации:</p>

<p><img src="http://datadeep.ru/images/slide01.png" />	    </p>

<p>Научные презентации тоже часто изобилуют сложными диаграммами, как будто это повышает доверие к автору.
Но опять же, стоит учитывать ожидания аудитории — на научной конференции люди больше настроены думать и вникать, так что могут просто не доверять слишком простой диаграмме.
При этом не забывайте, что способности к восприятию ограничены даже у ученых. 
Не стоит превращать свои слайды в склад всех имеющихся данных. 
Алексей пишет:</p>

<blockquote>
  <p>“Данные — это всего лишь способ доказать свою идею. Хорошая новость состоит в том, что если у вас есть идея, если вы знаете, что именно вы хотите сказать, то существует множество способов представить свои данные красиво и при этом не перегрузить аудиторию.”</p>
</blockquote>

<p>Для того, чтобы презентационная диаграмма удалась, надо убрать все лишнее, оставив только то, что подтверждает основную идею.
Саму идею стоит вынести в заголовок графика.</p>

<p>Рассмотрим приведенное в той же книге преобразование диаграммы Минара. Превращаем аналитическую графику в картинку, которая будет убедительно смотреться на слайде презентации.
“Нижняя диаграмма выглядит сильно упрощенной, но она способна донести вложенное в нее послание. Дело в том, что на самом деле необязательно видеть каждую российскую речушку, чтобы понять: Наполеон не был побежден в какой-то крупной битве.”</p>

<p><img src="http://datadeep.ru/images/slide02.png" />	    </p>

<p>Из-за своей презентационной специфики этот тип визуализации наиболее подвержен <strong>графическим манипуляциям</strong>. Смещение оси ординат, игры с относительным масштабом и перспективой, все прелести круговой диаграммы и “крутые” 3D эффекты — все это встречается здесь очень часто. Иногда умышленно, иногда по незнанию. Те же трехмерные эффекты встроены в PowerPoint и к сожалению все еще пользуются популярностью. </p>

<p>На слайде старины Стива сектор 19.5% выглядит больше, чем  21.2% за счет добавления объема. С круговой диаграммой на второй картинке тоже что-то не так.
Подробнее про подобные манипуляции можно почитать <a href="http://en.wikipedia.org/wiki/Misleading_graph">здесь</a>.</p>

<p><img src="http://datadeep.ru/images/Presentation.png" />	    </p>

<h2 id="section-4">Инфографика</h2>

<p>Слово инфографика в последнее время стало очень популярно. 
Из-за отсутствия точного определения его часто путают с другими видами визуализации или называют инфографикой любую красивую картинку с цифрами.</p>

<p>Я бы выделил следующие особенности, присущие именно инфографике. Во-первых, цель инфографики — просвещение и развлечение. Во-вторых, инфографика создается дизайнерами и журналистами. Существует даже специальный термин — журналистика данных. В-третьих, большое внимание уделяется привлекательности картинки. </p>

<p>Хорошая инфографика похожа на аналитическую визуализацию. Но она не нацелена на поиск закономерностей или принятие решений, ее роль скорее просветительская. Рассмотрим несколько примеров.</p>

<p>Визуализация <a href="http://www.brainpickings.org/2012/11/29/giorgia-lupi-noble-prizes-visualization/">нобелевских лауреатов</a></p>

<p><img src="http://datadeep.ru/images/nobel-prizes-and-laureates.jpg" />	    </p>

<p>Красивая <a href="http://www.malofiejgraphics.com/la-ballena-franca-grafico-mas-influente-de-los-ultimos-veinte-anos/">инфографика о китах</a></p>

<p><img src="http://datadeep.ru/images/INFO-BALLENA.jpg" /></p>

<p>На <a href="http://www.scmp.com/infographics/article/1284683/iraqs-bloody-toll">картинке ниже</a> мы видим хорошее применение сильной метафоры.
В аналитической графике перевернутая ось ординат только сбивала бы с толку, но в инфографике для усиления эмоционального воздействия такой прием допустим.</p>

<p><img src="http://datadeep.ru/images/iraqdeaths.jpg" /></p>

<p>Примеры на русском можно посмотреть здесь: <a href="http://infographicsmag.ru/journal/">журнал “Инфографика”</a>, <a href="http://ria.ru/infografika/">инфографика РИА Новости</a>.</p>

<h2 id="section-5">Скетчи (рисунки на салфетке)</h2>

<p>Иногда нужно визуализировать не данные, а идеи, концепции и взаимосвязи. 
Тут на помощь приходят простые рисунки от руки. 
Применяются они на брейнштормах или при объяснении. Как и исследовательская графика, являются подручным инструментом, но основаны не на данных, а на идеях.
Картинка <a href="http://habrahabr.ru/post/249759/">отсюда</a>.</p>

<p><img src="http://datadeep.ru/images/sketch01.png" /></p>

<p>Важный поджанр — mind maps (интеллект-карты, диаграммы связей). Они используются при обучении или мозговом штурме, для запоминания или решения проблем с помощью визуального мышления. Часто назначение этого вида рисунков — выплеснуть на бумагу содержимое головы. 
Поэтому иногда понять смысл рисунка может только автор.</p>

<p><img src="http://datadeep.ru/images/sketch02.png" /></p>

<p>В мире скетчей существует свое разнообразие жанров и различные методики их использования, но в этой статье мы на них останавливаться не будем.
Подробнее про визуальное мышление можно почитать в книге Дэна Роэма “Практика визуального мышления”.</p>

<h2 id="section-6">Арт</h2>

<p>Художники, работающие в жанре генеративного искусства (не путать с дегенеративным) используют те же методы, что и исследователи данных, но стремятся достичь эстетической привлекательности результата. 
С помощью данных, полученных из интернета или каких-либо датчиков, он создают картины, видеоролики и интерактивные инсталляции.
Очень часто в качестве инструмента используют язык Processing.</p>

<p>Ярким представителем является берлинская студия <a href="http://www.onformative.com/">Onformative</a>. Ниже представлены примеры их работ: визуализация фейсбучной страницы и интерактивная витрина для магазина Nike.</p>

<p><img src="http://datadeep.ru/images/onformative_facebook.jpg" />
<img src="http://datadeep.ru/images/onformative_nike.jpg" /></p>

<p>Большинство работ подобного жанра, хоть и основаны на числовых данных, располагают только к эстетическому восприятию получившейся картины. Ниже изображена визуализация числа Пи.</p>

<p><img src="http://datadeep.ru/images/art-of-pi.png" title="Визуализация числа Пи" /></p>

<h2 id="section-7">Заключение</h2>

<p>Итак, мы достаточно поверхностно рассмотрели применение визуализации в различных областях человеческой деятельности от науки до искусства.
Про каждую из этих областей можно писать гораздо подробнее, ведь мир визуализаций невероятно разнообразен.
К тому же он подвижен, живет и развивается. Новые технологические изобретения, такие как дополненная и виртуальная реальности, голография и пр. привнесут свой вклад в развитие этой области.</p>

<p>В следующих статьях этого раздела мы рассмотрим инструменты для создания различных визуализаций. Начнем с разведочной графики, грамотное применение которой может существенно упростить работу датолога. Но вне зависимости от области применения при создании графики мы всегда должны помнить о цели нашей работы и задавать себе важнейшие вопросы:</p>

<ul>
  <li>что за данные мы визуализируем;</li>
  <li>что мы хотим сказать своей визуализацией;</li>
  <li>кто будет работать с этой графикой;</li>
  <li>и в каком контексте.</li>
</ul>

<p><img src="http://datadeep.ru/images/ending.png" title="Элементы компьютетной графики для фильма &#34;Трон: Наследие&#34;" alt="Элементы компьютетной графики для фильма &#34;Трон: Наследие&#34;" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Обнаружение дорожных знаков при помощи Deep Learning]]></title>
    <link href="http://datadeep.ru/blog/2015/08/22/obnaruzhieniie-dorozhnykh-znakov-pri-pomoshchi-deep-learning/"/>
    <updated>2015-08-22T15:15:32+03:00</updated>
    <id>http://datadeep.ru/blog/2015/08/22/obnaruzhieniie-dorozhnykh-znakov-pri-pomoshchi-deep-learning</id>
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.6/d3.min.js"></script>

<script type="text/javascript" src="http://code.jquery.com/jquery-1.11.3.min.js"></script>

<script type="text/javascript" src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

<link href="http://datadeep.ru/d3/bootstrap_tooltip_popover.css" rel="stylesheet" />

<p>Команда блога DataDeep не смогла остаться в стороне от <a href="https://meduza.io/news/2015/07/17/samoupravlyaemaya-mashina-google-popala-v-pervoe-dtp-s-postradavshimi">новости об аварии самоуправляемого автомобиля Google</a>, и поэтому я решил написать пост о своём опыте разработки системы для обнаружения дорожных знаков, основанной на машинном обучении. Такую систему вполне можно отнести к компонентам, которые используются как для разработки механизмов автономного упраления автомобилем, так и в современных системах помощи водителю :)  </p>

<p><img src="http://datadeep.ru/images/selfdrivingcar.jpg" width="768" height="576" title="Self-driving car" /></p>

<!-- more -->

<h2 id="section">Постановка задачи, описание данных</h2>

<p>Итак, мы хотим сделать приложение, которое будет максимально достоверно находить и выделять рамкой (region of interest, ROI) дорожные знаки на изображении, поступившем на вход. Сердцем метода, решающего эту задачу, будет, как не трудно предположить, машинное обучение. Для использования такого подхода необходимы тренировочные данные, в качестве которых будем использовать данные с соревнования <a href="http://benchmark.ini.rub.de/?section=gtsdb&amp;subsection=dataset">The German Traffic Sign Detection Benchmark</a>. Это соревнование по детектированию и определению категории дорожного знака, которое проводилось в 2013 году. В этих данных содержится информация о знаках из нескольких категорий, таких как предупреждающие, приоритета, запрещающие и предписывающие. Парным к нему является соревнование по распознаванию знаков The German Traffic Sign Recognition Benchmark, в котором алгоритм, построенный на основе глубоких нейронных сетей (deep learning), <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html?_r=0">превзошёл по точности распознавания уровень человека</a>. </p>

<p>Данные представляют собой 900 изображений размером $1360 \times 800$ в формате ppm, а также 1213 изображений дорожных знаков, взятых с этих картинок, размером от $16\times16$ до $128\times128$ в формате ppm.  Некоторые из больших изображений содержат один и более знак, в то время, как другие не содержат знаков вовсе. ROI задаётся с помощью четырёхмерного вектора с координатами прямоугольной рамки <script type="math/tex">(x_{min}, y_{min}, x_{max}, y_{max})</script>. Для всех 900 изображений заданы правильные ROI. Несколько примеров из данных:</p>

<p>Один дорожный знак:</p>

<p><img src="http://datadeep.ru/images/0.jpg" title="Один знак" /></p>

<p>Два знака:</p>

<p><img src="http://datadeep.ru/images/1.jpg" title="Два знака" /></p>

<p>Без знаков:</p>

<p><img src="http://datadeep.ru/images/2.jpg" title="Без знаков" /></p>

<p>Таким образом, наша задача заключается в том, чтобы обучить алгоритм, который для входного изображения будет выдавать ноль или более четырёхмерных векторов по числу обнаруженных дорожных знаков.      </p>

<h2 id="state-of-the-art-">Обзор <em>state of the art</em> подходов</h2>

<p>Начиная примерно с 2012 года, когда на очень известном в сообществе computer vision соревновании по распознаванию изображений <a href="http://www.image-net.org/">ImageNet</a> победила команда университета Торонто под руководством Джеффри Хинтона, показав при этом значительный отрыв в точности от других команд, state of the art методом для распознавания изображений считается использование глубоких свёрточных нейронных сетей (Convolutional neural network, CNN), которые, в свою очередь, являются представителем класса алгоритмов машинного обучения deep learning (глубокое или, если угодно, глубинное обучение). Очень многие лучшие на сегодняшний день системы машинного зрения основаны на CNN, например <a href="https://research.facebook.com/publications/480567225376225/deepface-closing-the-gap-to-human-level-performance-in-face-verification/">система распознавания лиц от Facebook</a> (к слову, глава Facebook AI Research Ян Лекун является одним из пионеров в исследовании CNN и deep learning). </p>

<p>В области детектирования предметов на изображении одним из самых эффективных является метод <em>Regions with CNN features</em> или <em>R-CNN</em>, представленный в 2014 году. Этот метод можно разделить на следующие этапы:</p>

<ol>
  <li>Определение областей изображения, которые могут содержать интересующие нас объекты, с помощью алгоритма <em>Selective search</em>;</li>
  <li>Выделение из полученных областей признаков, используя свёрточную нейронную сеть;</li>
  <li>Эти признаки подаются на вход SVM (support vectors machine), которая классифицирует объект.</li>
</ol>

<p>Существуют и другие успешные методы детектирования, основанные на CNN, например <a href="http://arxiv.org/abs/1312.6229">построение регрессии</a> для нахождения четырёхмерного вектора ROI (т.е. на последнем уровне CNN находятся не вероятности, а целые значения). Однако, идея алгоритма, который мы будем строить, вдохновлена в первую очередь R-CNN, благодаря его простоте и эффективности, и реализует три его этапа, хотя имеет ряд значительных отличий. </p>

<h2 id="section-1">Описание метода</h2>

<p>Перед тем, как описать структуру метода для обнаружения дорожных знаков на изображении, скажу пару слов о технологиях, которые будут использованы. В качестве языка программирования применяется Python, так как для него есть API всех необходимых библиотек, и в данном случае нам больше важна гибкость и лёгкость прототипирования, чем скорость работы приложения. </p>

<p>Вся работа со свёрточными нейронными сетями ведётся с помощью изумительной библиотеки <a href="http://caffe.berkeleyvision.org/">Caffe</a>. Она позволяет конструировать, обучать и применять CNN, содержит state of the art виды слоёв и методы тренировки сети, обрабатывает данные в различных форматах (в том числе HDF5), позволяет обучать сети на графическом процессоре (GPU) с использованием CUDA, имеет обёртку для Python pycaffe. Для Caffe есть хранилище Model zoo, в котором содержаться обученные модели, которые можно использовать для своих задач. Также хочется отметить хорошие туториалы и большое сообщество. Архитектура нейронных сетей и параметры метода обучения задаются в Caffe в файлах <a href="https://developers.google.com/protocol-buffers/docs/overview">формата prototxt</a>.</p>

<p>Для обработки изображений используется библиотека OpenCV, которая, я думаю, не нуждается в дальнейшем представлении. </p>

<h3 id="mser">Детектор MSER</h3>

<p>Приступим непосредственно к методу решения задачи. На первом этапе будем определять области входного изображения, которые потенциально могут содержать дорожный знак. Для этого было рассмотрено несколько детекторов (в частности selective search из R-CNN, который не смог хорошо выделить области со знаками). Метрикой качества служило среднее евкидово расстояние между настоящим ROI на изображениях из тренировочных данных и ближайшим к нему ROI, полученным с помощью детектора.   Лучше всего себя показал метод <a href="https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions">MSER</a> (maximally stable extremal regions). Из выделенных MSER областей отбирались те, в которых длина и ширина лежат в пределах от 16 до 128 и их соотношение не превышает 1.5 (т.е. более-менее близки по форме к квадрату). Таким образом, мы получаем набор областей, в которых может содержаться один дорожный знак.</p>

<h3 id="main-cnn">Main CNN</h3>

<p>На следующем этапе алгоритма для определения того, содержит ли область изображения из предыдущего этапа знак, будем применять классификатор. В этом качестве выступит представитель класса методов deep learning — глубокая свёрточная нейронная сеть. Ей на вход будет поступать изображение, а на выходе будут две вероятности, сумма которых равна 1: того, что изображение содержит и не содержит дорожный знак. Архитектура нейронной сети, которую мы будем использовать, сходна c архитектурой весьма эффективной сети <em>Network in network</em> (NIN), которая хорошо себя показала в 2014 году в конкурсе <a href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> (определение, к какой из 10 категорий принадлежит изображение). </p>

<p>На вход нейронная сеть получает RGB изображение размером $32\times32$, которое предварительно преобразуется в такой формат, если нужно. Рассмотрим вкратце слои сети: </p>

<ul>
  <li><em>Свёрточный слой</em> (CONVOLUTION) — как видно из названия, является основной частью CNN. Он реализует обычную операцию свёртки: мы идём по изображению скользящим окном, перемножаем значения в окне с заданными весами (ядром), а затем всё складываем. Наборов весов может быть несколько. Проиллюстрируем то, что делает свёрточный слой (картинка взята с <a href="http://habrahabr.ru/">хабра</a>):</li>
</ul>

<p><img src="http://datadeep.ru/images/cnn_principle.png" title="Свёртка" /> </p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)"><em>Rectified linear unit</em></a> (RELU) — слой, в котором нет какой-то сложной математики и, как следствие, настраиваемых параметров. Он служит для того, чтобы получить нелинейность. К каждому входному значению этого слоя применяется функция:</li>
</ul>

<p><img src="http://datadeep.ru/images/relu.jpeg" title="Rectified linear unit" /></p>

<p>Это то, что происходит в нейроне, так называемая <em>activasion function</em>. В “классических” нейронных сетях для этого используется сигмоидная функция или тангенс. Однако в последнее время эмпирически было установлено, что простая функция RELU оказывается очень эффективной.</p>

<ul>
  <li>
    <p><em>Pooling</em> (POOLING) — служит для уменьшения размерности. Входной двумерный массив делится на сектора, в зависимости от параметров, и в каждом из них происходит максимизация (MAX) или усреднение (AVE) (два самых распространённых вида pooling’а).</p>
  </li>
  <li>
    <p><em>Dropout</em> (DROPOUT) — недавно открытый, очень эффективный и простой способ регуляризации (т.е. снижения эффекта переобучения). Его суть заключается в том, что с заданной вероятностью нейроны сети отключаются и не участвуют в текущей итерации обучения. </p>
  </li>
</ul>

<p>Архитектура всей сети представляет собой 3 больших последовательно соединённых слоя, каждый из которых состоит из [CONVOLUTION -&gt; RELU -&gt; CONVOLUTION -&gt; RELU -&gt; CONVOLUTION -&gt; RELU -&gt; POOLING -&gt; DROPOUT]. На самом последнем слое мы получаем две вероятности. Назовём эту сеть <em>Main CNN</em>. </p>

<h4>Структура Main CNN (при наведении на слой отображаются его параметры)</h4>

<div id="container">     
</div>

<script type="text/javascript">

function removetooltips () {
  $('.tooltip').each(function() {
    $(this).remove();
  }); 
}

function showtooltip (d) {
  $(this).tooltip({
	animation: true,  
    placement: 'auto right',
    container: 'body',
    trigger: 'manual',
    html : true,
    title: function() { 
	  var info
	  
	  if (d.type == "DATA"){
	          info = d.description
          }
      else{    
      info = 
      "<strong>Название</strong>: " + d.name + "<br><strong>Тип</strong>: " + d.type;
      
      if (d.type=="CONVOLUTION"){
			  info+=
			  '<hr><em>Параметры слоя:</em><br>'+"<strong>Число элементов на выходе</strong>: "+d.convolution_param.num_output
			  +'<br>'+"<strong>Размер ядра</strong>: "+d.convolution_param.kernel_size
			  +'<br>'+"<strong>Инициализация весов</strong>: "+d.convolution_param.weight_filler.type
			  +'<br>'+"<strong>Инициализация смещения</strong>: "+d.convolution_param.bias_filler.type
			  ;
		  }
		  
	 if (d.type=="POOLING"){
			  info +=
			  '<hr><em>Параметры слоя:</em><br>'+"<strong>Тип pooling'а</strong>: "+d.pooling_param.pool
			  +'<br>'+"<strong>Размер ядра</strong>: "+d.pooling_param.kernel_size
			  +'<br>'+"<strong>Шаг</strong>: "+d.pooling_param.stride
			  ;
		  }
		  
		  if (d.type=="DROPOUT"){
			  info+='<hr><em>Параметры слоя:</em><br>'+"<strong>Вероятность dropout'а</strong>: "+d.dropout_param.dropout_ratio
			  ;
		  }	  
        }
      
      
      return info;
      }
  });
  $(this).tooltip('show')
}


        
var margin = {top: 0, right: 0, bottom: 20, left: 10}

var width = 700 - margin.left - margin.right
var height = 640 - margin.top - margin.bottom

var svg = d3.select("#container").append("svg")
        .attr("width", width + margin.left + margin.right)
        .attr("height", height + margin.top + margin.bottom)
        .append("g")
        .attr("transform", "translate(" + margin.left + "," + margin.top + ")")   
         	
       
var colors = d3.scale.category10();  

var w = 150;   

//Read JSON file    
        
d3.json("/d3/layers.json",function(data){
			

var  Network  = svg.append("g").attr("class","Network");
                      
              
                      
                
h = (height/ data.layers.length);
   
var layer = Network.selectAll("g.layer")
                    .data(data.layers)
                    .enter()
                    .append("g")
                    .attr("class","layer")
                    .attr("transform",function(d,i){
	                    var dy = i*h;
	                    return 'translate(0,'+dy+')'
                    });
                    


var lrect = layer.append("rect")
				.attr('class',"layerrect")
				.attr("x",0)  
				.attr("y",0)
				.attr("rx",function(d){
					if(d.type=="DROPOUT"){return 12}
						else if (d.type=="RELU"){return 0}
							else
								{return 5}
					})
				.attr("height",h-5)
				.attr("width",w)
				.style("fill",function(d){
						return colors(d.type)			
				})
				.style("fill-opacity",0.7);

layer.append("rect")
	.attr('class',"arrow")
	.attr("x",w/2-1)  
	.attr("y",h-5)                  
	.attr("height",function(d,i){if(i<data.layers.length-1) {return 5} else {return 0};})
	.attr("width",2)
	.style("fill",function(d){
						return colors(d.type)			
	})
	.style("fill-opacity",0.7);


layer.append("text")
	.attr("dy", h/2+2)
	.attr("dx",w/2)
	.attr("fill","white")
	.style("text-anchor", "middle")
	.text(function(d){return d.name})

layer.on("mouseover", function(d,i) { 
									d3.select(this).select(".layerrect")
												   .attr( "width", w+10);
									showtooltip.call(this, d);                  
			                                               } )
     .on("mouseout", function() { 
	     							d3.select( this ).select(".layerrect")
	     											 .transition()
			                                         .ease("elastic")
			                                         .attr( "width", w);
			                        removetooltips();
			                                                } )

	return data;	
})

             
</script>

<p><a href="https://github.com/andrewbo29/traffic_signs_detector/blob/master/model/signet_nin_finetune_train_val.prototxt">Полное описание свёрточной нейронной сети</a> в формате prototxt, которое применятся для её обучения с помощью Caffe.</p>

<p>Для того, чтобы обучить всю эту сеть, будем использовать стандартный метод оптимизации <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Batch stochastic gradient descent</a> с уменьшением параметра learning rate в 10 раз каждые 1000 шагов, начальный learning rate — 0.000001. Кроме того, применим метод Momentum Нестерова с параметром 0.9. В качестве регуляризации будем использовать <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">Weight decay</a> с параметром 0.0001. Обучение будет остановлено или при достижении максимального количества итераций, или при малом изменении функции потерь. Prototxt файл со всеми параметрами оптимизации, который используется в Caffe:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Solver</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="json"><span class="line"><span class="err">test_iter:</span> <span class="mi">100</span>
</span><span class="line"><span class="err">test_interval:</span> <span class="mi">1000</span>
</span><span class="line"><span class="err">base_lr:</span> <span class="mf">0.000001</span>
</span><span class="line"><span class="err">momentum:</span> <span class="mf">0.9</span>
</span><span class="line"><span class="err">weight_decay:</span> <span class="mf">0.0001</span>
</span><span class="line"><span class="err">lr_policy:</span> <span class="s2">&quot;step&quot;</span>
</span><span class="line"><span class="err">gamma:</span> <span class="mf">0.1</span>
</span><span class="line"><span class="err">stepsize:</span> <span class="mi">1000</span>
</span><span class="line"><span class="err">display:</span> <span class="mi">100</span>
</span><span class="line"><span class="err">max_iter:</span> <span class="mi">50000</span>
</span><span class="line"><span class="err">snapshot:</span> <span class="mi">1000</span>
</span><span class="line"><span class="err">solver_mode:</span> <span class="err">GPU</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Для ускорения обучения будем применять подход <em>Fine-tuning</em>: веса нейронной сети инициализируются предобученными для другой (но похожей) задачи. Мы используем веса, которые были обучены авторами NIN для задачи CIFAR-10.</p>

<h3 id="features-learning-cnn">Features learning CNN</h3>

<p>Итак, с помощью описанной выше CNN мы отберём области изображения, скорее всего содержащие знак (т.е. те, для которых вероятность наличия знака, выданная сетью, больше порога 0.5). Для того, чтобы улучшить качество распознавания, построим поверх нейронной сети ещё один классификатор. Для этого будем использовать CNN, аналогичную той, которую мы уже построили, только без последних двух слоёв pooling’а и вероятностей. Если посмотреть на параметры в описании архитектуры используемой CNN, то от туда можно понять, что новая сеть будет выдавать на выходе вектор размерности 128. Назовём её <em>Features learning CNN</em>. В качестве весов она использует натренированные веса Main CNN. Features learning CNN мы будем применять к областям изображений, которые по мнению Main CNN содержат дорожный знак.  Мы получим 128-размерный вектор признаков, который будем “скармливать” машине опорных векторов (SVM) с полиномиальным ядром степени 2 и параметром регуляризации 0.1.</p>

<p>Таким образом, полный алгоритм представляет собой ансамбль:</p>

<p><img src="http://datadeep.ru/images/pipeline.png" title="Pipeline" /></p>

<h3 id="bootstrap">Bootstrap</h3>

<p>Для того, чтобы нарисовать ROI, содержащую дорожный знак, нам остался ещё один шаг. В силу особенностей метода MSER может получиться ситуация, когда для одного знака получается несколько очень близко расположенных рамок (т.е. областей изображения, отобранных на предыдущем этапе). Объединив такие рамки в одну (взяв наибольшую из них), мы получим финальный ROI. </p>

<h2 id="section-2">Применение метода</h2>

<p>Теперь опишем то, как обучался алгоритм и что из этого вышло. Прежде всего, нам необходимы тренировочные данные для Main CNN. Разделим имеющиеся в нашем распоряжении 900 изображений на 600 тренировочных и 300 тестовых. В исходных данных уже есть изображения дорожных знаков, т.е. положительные прецеденты, однако нет отрицательных, т.е. изображений без знаков. Для того, чтобы получить эти данные, используем следующую процедуру: к каждому изображению из тренировочных данных применяется MSER и отбираются те его области, которые похожи по размерам на ROI (см. выше), не пересекаются с настоящим ROI, но при этом лежат относительно “не далеко” от него. Последний пункт нужен, т.к. CNN будет хорошо “отличать” дорожный знак от, например, неба или асфальта, но плохо от окна, фары машины, листвы и т.д., т.е. от объектов, которые на изображении находятся достаточно близко к знаку. Таким образом, если мы будем брать любые области, не пересекающиеся с ROI, то большинство из них будет содержать небо, дорожное покрытие, стены домов и т.п., что негативно отразится на качестве классификации. Всего таких отрицательных прецедентов отберём около 2000, чтобы выборка для обучения Main CNN была сбалансированной.</p>

<p>Примеры положительных прецедентов:</p>

<p><img src="http://datadeep.ru/images/train_main_cnn_plus.png" title="Положительные прецеденты" /></p>

<p>Примеры отрицательных прецедентов:</p>

<p><img src="http://datadeep.ru/images/train_main_cnn_minus.png" title="Отрицательные прецеденты" /></p>

<p>Чтобы улучшить качество распознавания дорожных знаков с помощью Main CNN будем использовать трюк, который является формой boosting’а:</p>

<ol>
  <li>Обучим Main CNN на полученных нами на предыдущем этапе тренировочных данных;</li>
  <li>Определим, на каких отрицательных прецедентах Main CNN ошибается;</li>
  <li>Сформируем из них и положительных прецедентов новую тренировочную выборку;</li>
  <li>Продолжим обучение Main CNN с помощью Fine-tuning, где в качестве начальных весов используются веса, полученные в пункте 1;</li>
  <li>Повторим пункты 1–4 три раза.</li>
</ol>

<p>Примеры новых отрицательных прецедентов:</p>

<p><img src="http://datadeep.ru/images/train_main_cnn_new_minus.png" title="Новые отрицательные прецеденты" /></p>

<p>При обучении SVM на изначальных тренировочных данных Main CNN результаты следующие: F1-score — 0.85, точность — 0.85.</p>

<p>После тренировки всех частей ансамбля алгоритмов мы можем применить их к тестовым данным. В качестве метрики точности для изображений, содержащих дорожные знаки, возьмём наименьшее евклидово расстояние между векторами, описывающими ROI. Это не самая точная метрика, однако она даёт представление о качестве работы метода. Результаты на тестовых данных (300 изображений): 39.9; число случаев, когда алгоритм не показал ROI, а они есть (False negative): 33; число случаев, когда алгоритм показал ROI, а их нет (False positive): 5. Ниже представлено несколько характерных примеров работы алгоритма.</p>

<p>Все знаки правильно обнаружены:</p>

<p><img src="http://datadeep.ru/images/all_1.jpeg" title="Все знаки" /></p>

<p><img src="http://datadeep.ru/images/all_2.jpeg" title="Все знаки" /></p>

<p><img src="http://datadeep.ru/images/all_3.jpeg" title="Все знаки" /></p>

<p>Алгоритм может ошибаться, принимая такие объекты, как фара машины, за знак:</p>

<p><img src="http://datadeep.ru/images/light.jpeg" title="Фара машины" /></p>

<p>Иногда алгоритм находит не все знаки:</p>

<p><img src="http://datadeep.ru/images/not_all.jpeg" title="Не все знаки" /></p>

<p>False positive:</p>

<p><img src="http://datadeep.ru/images/false_positive.jpeg" title="False positive" /></p>

<p><img src="http://datadeep.ru/images/false_positive_2.jpeg" title="False positive" /></p>

<h2 id="section-3">Заключение</h2>

<p>Подводя итог, можно сказать, что был разработан несложный, но вполне рабочий алгоритм, основанный на deep learning для обнаружения дорожных знаков на изображении. В силу того, что обучение происходило на машине с относительно слабой конфигурацией (8 Гб оперативной памяти, GPU: GeForce 730, 2Гб памяти), увеличение вычислительных мощностей и добавление дополнительных данных приведёт к улучшению качества работы как свёрточной нейронной сети, так и SVM. </p>

<p>В статье мы рассмотрели использование CNN, коснулись ReLU, Pooling, Dropout и других понятий, входящих в такую область машинного обучения, как deep learning. Для того, чтобы больше узнать об этом стремительно набирающем в последние несколько лет популярность направлении, в дальнейшем будет сделан цикл статьей по теории и практике глубоких нейронных сетей, благо название блога обязывает! </p>

<h2 id="section-4">Ссылки</h2>

<ol>
  <li><a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Статья с описанием метода команды университета Торонто</a>  </li>
  <li><a href="http://www.cs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf">Regions with CNN features</a></li>
  <li><a href="http://arxiv.org/abs/1312.4400">Network in network</a></li>
  <li><a href="https://github.com/andrewbo29/traffic_signs_detector">Код на github</a></li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Краткое введение в D3.js]]></title>
    <link href="http://datadeep.ru/blog/2014/12/04/kratkoie-vviedieniie-v-d3-dot-js/"/>
    <updated>2014-12-04T20:44:23+03:00</updated>
    <id>http://datadeep.ru/blog/2014/12/04/kratkoie-vviedieniie-v-d3-dot-js</id>
    <content type="html"><![CDATA[<script src="http://d3js.org/d3.v2.js"></script>

<div>
  <style type="text/css">

    .axis path, .axis line {
      fill: none;
      stroke: #000;
      shape-rendering: crispEdges;
    }
    ul{margin:1em 0 1em 2em;}
    ol{margin:1em 0 1em 2em;}
    
    .container0 .container5{
    	  font-size: x-small;
    }
    


  </style>
</div>

<p>В этой статье мы познакомимся с мощным инструментом визуализации данных – библиотекой D3.js.
Она позволяет представлять ваши данные в различных формах и  добавлять эффектные графики на веб-страницы.</p>

<p><img src="http://datadeep.ru/images/d3.png" width="768" height="316" title="D3.js examples" /></p>

<!-- more -->

<p>Существует много различных инструментов визуализации, некоторые из них имеют долгую историю и плотно прижились среди специалистов. Например, с помощью библиотеки ggplot2 для языка R можно строить достаточно сложные графики всего несколькими строчками кода, а ученые, использующие язык Python, создают графики при помощи библиотеки matplotlib.</p>

<p>Но увеличение количества информации, развитие Интернета и рост графических возможностей современных программ создают новые ожидания от визуального представления данных:</p>

<ul>
  <li><strong>Интерактивность.</strong> Интерактивный график может демонстрировать изменения в зависимости от настройки параметров, сравнивать показатели для определенной пользователем выборки или вовсе показывать изменения данных в реальном времени. Такая визуализация не только предъявляет результат, но и позволяет зрителю анализировать данные самостоятельно;</li>
  <li><strong>Возможность публикации в Интернете.</strong> Визуализация служит не только для анализа данных, это еще и лучший способ поделиться своими выводами с миром. Выложить в сеть статичную картинку нетрудно, но интерактивная визуализация должна быть доступна без установки дополнительных приложений, то есть исполняться прямо в браузере;</li>
  <li><strong>Доступность данных.</strong> В случае со статичной картинкой, вы не можете получить доступ к исходным данным, чтобы что-то уточнить или проверить. Визуализация, создаваемая в вашем браузере на основе массива данных, не лишает вас такой возможности;</li>
  <li><strong>Информационная эстетика.</strong> Речь здесь идет не о красоте, а об удобстве восприятия. Настройки по умолчанию для шрифтов и цветовых схем в некоторых системах зачастую не самые удачные, а изменить их не всегда легко. К тому же многие старые системы генерируют только растровые изображения, которые невозможно увеличить без потери качества. Выход: использовать векторную графику и графические возможности современных браузеров.</li>
</ul>

<p>В связи с этими ожиданиями создаются новые инструменты или улучшаются старые. Например, библиотека Bokeh для языка Python использует для визуализации элемент canvas, созданный как контейнер для графики в HTML5, а инструмент Plotly  позволяет экспортировать результаты работы ggplot2, matplotlib и MATLAB в интерактивные веб-графики.</p>

<p>Но стандартом интерактивных веб-визуализаций можно смело назвать JavaScript библиотеку D3.js Майка Бостока. Библиотека создана в 2011 году, родившись из проекта Protovis. Основной принцип работы D3 заключается в создании элементов  веб-страницы на основе загруженных данных. Для этого используются современные стандарты HTML, SVG (векторная графика), CSS. Основные форматы данных - CSV и JSON.  D3 расшифровывается как Data Driven Documents, что вполне описывает философию библиотеки.</p>

<p>Основные преимущества D3:</p>

<ul>
  <li><strong>Прозрачность связи данных и представления.</strong> Визуальные элементы, создаваемые с помощью библиотеки, напрямую связаны с вашими данными. Данные хранятся в атрибутах графических элементов;</li>
  <li><strong>Гибкость в выборе представления.</strong> В D3 нет заготовок для различного вида графиков (для хорошей визуализации надо написать не один десяток строк кода), но она позволяет создавать графические элементы и изменять их параметры в соответствии с задачей. Именно поэтому она так хороша для создания нестандартных визуализаций;</li>
  <li><strong>Интерактивность.</strong> D3 позволяет без особых сложностей превратить график в интерактивный интерфейс, который показывает только актуальную для пользователя информацию.</li>
</ul>

<p>Очень много крутых примеров можно найти на <a href="http://bost.ocks.org/mike/">сайте</a> создателя библиотеки Майка Бостока.</p>

<h2 id="section">Практический пример</h2>

<p>Попробуем создать несложный график и познакомиться с принципами работы D3.</p>

<p>Перед началом работы для удобства отладки необходимо <a href="https://github.com/mbostock/d3/">скачать</a> библиотеку и сохранить ее в директорию проекта. Структура папок при этом будет выглядеть так:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">project-folder/
</span><span class="line">               d3/
</span><span class="line">                  d3.js
</span><span class="line">                  d3.min.js (optional)
</span><span class="line">               index.html</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Папка с библиотекой может иметь и другое имя, например содержать номер актуальной версии. Слово min означает ограниченный функционал для разработчика, но и ее вполне хватит для начала работы. </p>

<p>Я не буду останавливаться на описании основ веб-технологии, которые вы можете изучить самостоятельно. Для начала достаточно понимать, как работает HTML-документ, для чего нужны стили CSS и  как устроена SVG графика. Весь приведенный в последующих примерах код должен работать в таком шаблоне (в поле src должен быть указан путь к той версии библиотеки, которую вы скачали, или же ссылка на актуальную версию в Интернете “http://d3js.org/d3.v3.min.js”):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="cp">&lt;!DOCTYPE html&gt;</span>
</span><span class="line"><span class="nt">&lt;html&gt;</span>
</span><span class="line">    <span class="nt">&lt;head&gt;</span>
</span><span class="line">        <span class="nt">&lt;meta</span> <span class="na">charset=</span><span class="s">&quot;utf-8&quot;</span><span class="nt">&gt;</span>
</span><span class="line">        <span class="nt">&lt;title&gt;</span>D3 Page<span class="nt">&lt;/title&gt;</span>
</span><span class="line">        <span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/javascript&quot;</span> <span class="na">src=</span><span class="s">&quot;d3/d3.js&quot;</span><span class="nt">&gt;&lt;/script&gt;</span>
</span><span class="line">    <span class="nt">&lt;/head&gt;</span>
</span><span class="line">    <span class="nt">&lt;body&gt;</span>
</span><span class="line">    <span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">&quot;container&quot;</span><span class="nt">&gt;&lt;/div&gt;</span>
</span><span class="line">        <span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/javascript&quot;</span><span class="nt">&gt;</span>
</span><span class="line">            <span class="c1">// Your D3 code will go here</span>
</span><span class="line">        <span class="nt">&lt;/script&gt;</span>
</span><span class="line">    <span class="nt">&lt;/body&gt;</span>
</span><span class="line"><span class="nt">&lt;/html&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Начнем изучение с простейшего примера – построим вот такую диаграмму рассеяния (<em>scatterplot</em>) для небольшого массива данных:</p>

<div id="container0" align="center"></div>

<script type="text/javascript">
        
        var w = 400;
        var h = 200;
        var padding = 40;

        
        var svg = d3.select("#container0")
             	      .append("svg")
          			  .attr("width", w)
          			  .attr("height", h);
        
        var dataset = [
                [50, 20], [480, 90], [250, 50], [100, 133], [330, 95],
                [410, 12], [475, 44], [25, 167], [185, 21], [120, 88],[600, 150]
              ];

        
        var xScale = d3.scale.linear()
                     .domain([0, d3.max(dataset, function(d) { return d[0]; })])
                     .range([padding, w-padding]); 
                     
        var yScale = d3.scale.linear()
                     .domain([0, d3.max(dataset, function(d) { return d[1]; })])
                     .range([h - padding, padding]);
                     
        var rScale = d3.scale.linear()
                     .domain([0, d3.max(dataset, function(d) { return d[1]; })])
                     .range([2, 5]);  
                     
                                
        var xAxis = d3.svg.axis()
                  .scale(xScale)
                  .orient("bottom")
                  .ticks(5);
                  
         var yAxis = d3.svg.axis()
                  .scale(yScale)
                  .orient("left")
                  .ticks(5);                    
                     
                     
         svg.selectAll("circle")
			   .data(dataset)
			   .enter()
			   .append("circle")
			   .attr("cx", function(d) {return xScale(d[0]);})
			   .attr("cy", function(d) {return yScale(d[1]);})
			   .attr("r", function(d) { return rScale(d[1]);})
			   .attr("fill",function(d){if (d[0]>100) {return "teal"} else {return "orange"}});

		
			svg.append("g")
			    .attr("class", "axis")
			    .attr("transform", "translate(0," + (h - padding) + ")")
                .call(xAxis);  
            svg.append("g")
                .attr("class", "axis")
                .attr("transform", "translate(" + padding + ",0)")
                .call(yAxis);                                 
        
</script>

<p>Но для начала нарисуем круг. Для этого нам надо выполнить несколько простых шагов:</p>

<ol>
  <li>Выделить элемент страницы, на который мы хотим добавить графику. В нашем случае мы выделяем элемент, у которого id = “container”;</li>
  <li>Добавить элемент svg и обозначить его параметры: ширину и высоту;</li>
  <li>Добавить в SVG контейнер наш кружок;</li>
  <li>Задать параметры кружка: координаты центра, радиус и цвет.</li>
</ol>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="javascript"><span class="line"><span class="kd">var</span> <span class="nx">svg</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s2">&quot;#container&quot;</span><span class="p">)</span>       <span class="c1">//1</span>
</span><span class="line">            <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;svg&quot;</span><span class="p">)</span>              <span class="c1">//2</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;width&quot;</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;height&quot;</span><span class="p">,</span><span class="mi">100</span><span class="p">);</span>          			
</span><span class="line"><span class="nx">svg</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>                    <span class="c1">//3</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cx&quot;</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>                      <span class="c1">//4</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cy&quot;</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;fill&quot;</span><span class="p">,</span><span class="s2">&quot;orange&quot;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Вот что у нас должно получится:</p>

<div id="container1"></div>
<script>


             var svg = d3.select("#container1")
             	      .append("svg")
          			  .attr("width",100)
          			  .attr("height",100);
          			  
          	svg.append("circle")
			   .attr("cx", 50)
			   .attr("cy", 50)
			   .attr("r", 30)
			   .attr("fill","orange");		  
	    
</script>

<p>Свойства нашего нового объекта мы можем менять не только при создании, но и при дальнейшей работе. Для этого есть два способа:</p>

<ul>
  <li>создать js-переменную и обращаться к ней;</li>
  <li>обращаться к элементам с помощью функции выделения select или selectAll.</li>
</ul>

<p>В примере ниже мы меняем радиус круга с помощью первого способа (1), а цвет – с помощью второго (2):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="javascript"><span class="line"><span class="kd">var</span> <span class="nx">svg</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s2">&quot;#container&quot;</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;svg&quot;</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;width&quot;</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;height&quot;</span><span class="p">,</span><span class="mi">100</span><span class="p">);</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">circle</span> <span class="o">=</span> <span class="nx">svg</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cx&quot;</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cy&quot;</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">);</span>
</span><span class="line"><span class="nx">circle</span><span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span><span class="mi">50</span><span class="p">);</span>                    <span class="c1">//1</span>
</span><span class="line"><span class="nx">svg</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>                    <span class="c1">//2</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;fill&quot;</span><span class="p">,</span><span class="s2">&quot;teal&quot;</span><span class="p">);</span>	
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div id="container2"></div>
<script>


             var svg = d3.select("#container2")
             	      .append("svg")
          			  .attr("width",100)
          			  .attr("height",100);
          			  
          	var circle=svg.append("circle")
			   .attr("cx", 50)
			   .attr("cy", 50)
			   .attr("r", 30);
			   
			circle.attr("r",50);
			
			svg.selectAll("circle").
			attr("fill","teal");	
			
				  
	    
</script>

<p>Все это прекрасно, но <strong>где же данные?</strong></p>

<p>Теперь используем массив данных для создания нескольких кругов.
Для этого применяется не вполне очевидная конструкция:</p>

<ol>
  <li>мы задаем данные, которые будем визуализировать</li>
  <li>выделяем несуществующие элементы: selectAll(“circle”);</li>
  <li>связываем их с нашим массивом данных: data(dataset);</li>
  <li>создаем элементы: enter();</li>
  <li>добавляем на страницу окружности, используя данные.</li>
</ol>

<p>Механизм добавления окружностей тот же, что и примере выше. Отличие лишь в том, что окружность теперь создается для каждого элемента массива dataset. Атрибуты окружности (положение её центра) в данном случае определяются конкретными данными.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="javascript"><span class="line"><span class="kd">var</span> <span class="nx">svg</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s2">&quot;#container&quot;</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;svg&quot;</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;width&quot;</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;height&quot;</span><span class="p">,</span><span class="mi">200</span><span class="p">);</span>          			
</span><span class="line"><span class="kd">var</span> <span class="nx">dataset</span> <span class="o">=</span> <span class="p">[</span>
</span><span class="line">            <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">480</span><span class="p">,</span> <span class="mi">90</span><span class="p">],</span> <span class="p">[</span><span class="mi">250</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">133</span><span class="p">],</span> <span class="p">[</span><span class="mi">330</span><span class="p">,</span> <span class="mi">95</span><span class="p">],</span>
</span><span class="line">            <span class="p">[</span><span class="mi">410</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="p">[</span><span class="mi">475</span><span class="p">,</span> <span class="mi">44</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">167</span><span class="p">],</span> <span class="p">[</span><span class="mi">185</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="p">[</span><span class="mi">120</span><span class="p">,</span> <span class="mi">88</span><span class="p">],[</span><span class="mi">600</span><span class="p">,</span> <span class="mi">150</span><span class="p">]</span>
</span><span class="line">              <span class="p">];</span>                                            <span class="c1">//1	</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">circle</span> <span class="o">=</span> <span class="nx">svg</span><span class="p">.</span><span class="nx">selectAll</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>                        <span class="c1">//2</span>
</span><span class="line">              <span class="p">.</span><span class="nx">data</span><span class="p">(</span><span class="nx">dataset</span><span class="p">)</span>                                <span class="c1">//3</span>
</span><span class="line">              <span class="p">.</span><span class="nx">enter</span><span class="p">()</span>                                      <span class="c1">//4</span>
</span><span class="line">              <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>                             <span class="c1">//5</span>
</span><span class="line">              <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cx&quot;</span><span class="p">,</span><span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">){</span><span class="k">return</span> <span class="nx">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]})</span>
</span><span class="line">              <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cy&quot;</span><span class="p">,</span><span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">){</span><span class="k">return</span> <span class="nx">d</span><span class="p">[</span><span class="mi">1</span><span class="p">]})</span>
</span><span class="line">              <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">);</span>
</span><span class="line"><span class="nx">circle</span><span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;fill&quot;</span><span class="p">,</span><span class="s2">&quot;teal&quot;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div id="container3"></div>
<script>
             var svg = d3.select("#container3")
             	      .append("svg")
          			  .attr("width",200)
          			  .attr("height",200);
          			 
        var dataset = [
                [50, 20], [480, 90], [250, 50], [100, 133], [330, 95],
                [410, 12], [475, 44], [25, 167], [185, 21], [120, 88],[600, 150]
              ];		  
          	var circle=svg.selectAll("circle")
          	.data(dataset)
          	.enter()
          	   .append("circle")
			   .attr("cx",function(d){return d[0]})
			   .attr("cy",function(d){return d[1]})
			   .attr("r", 10);
			   
			circle.attr("fill","teal");
</script>

<p>Мы нарисовали много кружков, но у нас появилось пара проблем.</p>

<p>Во-первых кружков на рисунке явно меньше, чем элементов в нашем массиве. Это произошло из-за того, что размер нашего svg-элемента всего 200x200 пикселей, а значения в массиве dataset выходят за эти границы.</p>

<p>Во-вторых координатная система в svg устроена так, что ось Y направлена сверху вниз, что нас не устраивает, так как не очень удобно для восприятия.</p>

<p>Обе эти проблемы решаются с помощью функции масштабирования: scale. Это отображение, переводящее число из одного интервала в число из другого интервала. Областью значений чаще всего является разрешение картинки в пикселях. На рисунке ниже показан пример работы масштабирования для числовой и временной осей (рисунок взят из <a href="http://www.d3noob.org/2012/12/setting-scales-domains-and-ranges-in.html">cтатьи</a> с более подробным пояснением).</p>

<p><img src="http://datadeep.ru/images/scale1.png" title="Scale" /></p>

<p>В примере ниже мы используем два таких отображения (для осей X и Y), задавая области определения (domain), области значений (range) и характер функции (linear).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class="javascript"><span class="line"><span class="kd">var</span> <span class="nx">w</span> <span class="o">=</span> <span class="mi">400</span><span class="p">;</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">h</span> <span class="o">=</span> <span class="mi">200</span><span class="p">;</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">padding</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">dataset</span> <span class="o">=</span> <span class="p">[</span>
</span><span class="line">            <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">480</span><span class="p">,</span> <span class="mi">90</span><span class="p">],</span> <span class="p">[</span><span class="mi">250</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">133</span><span class="p">],</span> <span class="p">[</span><span class="mi">330</span><span class="p">,</span> <span class="mi">95</span><span class="p">],</span>
</span><span class="line">            <span class="p">[</span><span class="mi">410</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="p">[</span><span class="mi">475</span><span class="p">,</span> <span class="mi">44</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">167</span><span class="p">],</span> <span class="p">[</span><span class="mi">185</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="p">[</span><span class="mi">120</span><span class="p">,</span> <span class="mi">88</span><span class="p">],[</span><span class="mi">600</span><span class="p">,</span> <span class="mi">150</span><span class="p">]</span>
</span><span class="line">              <span class="p">];</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">xScale</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">scale</span><span class="p">.</span><span class="nx">linear</span><span class="p">()</span>
</span><span class="line">                     <span class="p">.</span><span class="nx">domain</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">max</span><span class="p">(</span><span class="nx">dataset</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">d</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="p">})])</span>
</span><span class="line">                     <span class="p">.</span><span class="nx">range</span><span class="p">([</span><span class="nx">padding</span><span class="p">,</span> <span class="nx">w</span><span class="o">-</span><span class="nx">padding</span><span class="o">*</span><span class="mi">2</span><span class="p">]);</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">yScale</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">scale</span><span class="p">.</span><span class="nx">linear</span><span class="p">()</span>
</span><span class="line">                     <span class="p">.</span><span class="nx">domain</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">max</span><span class="p">(</span><span class="nx">dataset</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">d</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span> <span class="p">})])</span>
</span><span class="line">                     <span class="p">.</span><span class="nx">range</span><span class="p">([</span><span class="nx">h</span> <span class="o">-</span> <span class="nx">padding</span><span class="p">,</span> <span class="nx">padding</span><span class="p">]);</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">svg</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s2">&quot;#container&quot;</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;svg&quot;</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;width&quot;</span><span class="p">,</span><span class="nx">w</span><span class="p">)</span>
</span><span class="line">            <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;height&quot;</span><span class="p">,</span><span class="nx">h</span><span class="p">);</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">circle</span> <span class="o">=</span> <span class="nx">svg</span><span class="p">.</span><span class="nx">selectAll</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>
</span><span class="line">                <span class="p">.</span><span class="nx">data</span><span class="p">(</span><span class="nx">dataset</span><span class="p">)</span>
</span><span class="line">                <span class="p">.</span><span class="nx">enter</span><span class="p">()</span>
</span><span class="line">                <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>
</span><span class="line">                <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cx&quot;</span><span class="p">,</span><span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">){</span><span class="k">return</span> <span class="nx">xScale</span><span class="p">(</span><span class="nx">d</span><span class="p">[</span><span class="mi">0</span><span class="p">])})</span>
</span><span class="line">                <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cy&quot;</span><span class="p">,</span><span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">){</span><span class="k">return</span> <span class="nx">yScale</span><span class="p">(</span><span class="nx">d</span><span class="p">[</span><span class="mi">1</span><span class="p">])})</span>
</span><span class="line">                <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span><span class="line">                <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;fill&quot;</span><span class="p">,</span><span class="s2">&quot;teal&quot;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div id="container4"></div>
<script>
       var w = 400;
        var h = 200;
        var padding = 30;
        
        
        var dataset = [
                [50, 20], [480, 90], [250, 50], [100, 133], [330, 95],
                [410, 12], [475, 44], [25, 167], [185, 21], [120, 88],[600, 150]
              ];
                
       var xScale = d3.scale.linear()
                     .domain([0, d3.max(dataset, function(d) { return d[0]; })])
                     .range([padding, w-padding*2]); 
                     
        var yScale = d3.scale.linear()
                     .domain([0, d3.max(dataset, function(d) { return d[1]; })])
                     .range([h - padding, padding]);

             var svg = d3.select("#container4")
             	      .append("svg")
          			  .attr("width",w)
          			  .attr("height",h);
          			 
	
              	  
          	var circle=svg.selectAll("circle")
          	.data(dataset)
          	.enter()
          	   .append("circle")
			   .attr("cx",function(d){return xScale(d[0])})
			   .attr("cy",function(d){return yScale(d[1])})
			   .attr("r", 5)
			   .attr("fill","teal");
</script>

<p>Теперь все точки на месте и будут отображаться корректно, даже если мы решим изменить размер контейнера.</p>

<p>Осталось совсем немного: нарисуем оси с помощью функции d3.svg.axis(), добавим еще один масштаб для радиусов окружности и поиграемся с цветом. Чтобы оси были тонкие и красивые, добавим немного CSS. Итоговый код страницы будет выглядеть как-то так:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span> (intro_d3_js.html)</span> <a href="http://datadeep.ru/downloads/code/intro_d3_js.html">download</a></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
<span class="line-number">55</span>
<span class="line-number">56</span>
<span class="line-number">57</span>
<span class="line-number">58</span>
<span class="line-number">59</span>
<span class="line-number">60</span>
<span class="line-number">61</span>
<span class="line-number">62</span>
<span class="line-number">63</span>
<span class="line-number">64</span>
<span class="line-number">65</span>
<span class="line-number">66</span>
<span class="line-number">67</span>
<span class="line-number">68</span>
<span class="line-number">69</span>
<span class="line-number">70</span>
<span class="line-number">71</span>
<span class="line-number">72</span>
<span class="line-number">73</span>
<span class="line-number">74</span>
<span class="line-number">75</span>
<span class="line-number">76</span>
<span class="line-number">77</span>
<span class="line-number">78</span>
<span class="line-number">79</span>
<span class="line-number">80</span>
<span class="line-number">81</span>
<span class="line-number">82</span>
<span class="line-number">83</span>
<span class="line-number">84</span>
<span class="line-number">85</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="cp">&lt;!DOCTYPE html&gt;</span>
</span><span class="line"><span class="nt">&lt;html&gt;</span>
</span><span class="line">    <span class="nt">&lt;head&gt;</span>
</span><span class="line">        <span class="nt">&lt;meta</span> <span class="na">charset=</span><span class="s">&quot;utf-8&quot;</span><span class="nt">&gt;</span>
</span><span class="line">        <span class="nt">&lt;title&gt;</span>D3 Page<span class="nt">&lt;/title&gt;</span>
</span><span class="line">        <span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/javascript&quot;</span> <span class="na">src=</span><span class="s">&quot;d3/d3.js&quot;</span><span class="nt">&gt;&lt;/script&gt;</span>
</span><span class="line">
</span><span class="line">        <span class="nt">&lt;style </span><span class="na">type=</span><span class="s">&quot;text/css&quot;</span><span class="nt">&gt;</span>
</span><span class="line">                     <span class="nc">.axis</span> <span class="nt">path</span><span class="o">,</span>
</span><span class="line">                     <span class="nc">.axis</span> <span class="nt">line</span> <span class="p">{</span>
</span><span class="line">                                  <span class="n">fill</span><span class="o">:</span> <span class="k">none</span><span class="p">;</span>
</span><span class="line">                                  <span class="n">stroke</span><span class="o">:</span> <span class="nb">black</span><span class="p">;</span>
</span><span class="line">                                  <span class="n">shape</span><span class="o">-</span><span class="n">rendering</span><span class="o">:</span> <span class="n">crispEdges</span><span class="p">;</span>
</span><span class="line">                                <span class="p">}</span>
</span><span class="line">        <span class="nt">&lt;/style&gt;</span>
</span><span class="line">    <span class="nt">&lt;/head&gt;</span>
</span><span class="line">
</span><span class="line">    <span class="nt">&lt;body&gt;</span>
</span><span class="line">    <span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">&quot;container&quot;</span><span class="nt">&gt;&lt;/div&gt;</span>
</span><span class="line"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/javascript&quot;</span><span class="nt">&gt;</span>
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">w</span> <span class="o">=</span> <span class="mi">400</span><span class="p">;</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">h</span> <span class="o">=</span> <span class="mi">200</span><span class="p">;</span>
</span><span class="line"><span class="kd">var</span> <span class="nx">padding</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">svg</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s2">&quot;#container&quot;</span><span class="p">)</span>
</span><span class="line">             <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;svg&quot;</span><span class="p">)</span>
</span><span class="line">          	 <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;width&quot;</span><span class="p">,</span> <span class="nx">w</span><span class="p">)</span>
</span><span class="line">          	 <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;height&quot;</span><span class="p">,</span> <span class="nx">h</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">dataset</span> <span class="o">=</span> <span class="p">[</span>
</span><span class="line">            <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">480</span><span class="p">,</span> <span class="mi">90</span><span class="p">],</span> <span class="p">[</span><span class="mi">250</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">133</span><span class="p">],</span> <span class="p">[</span><span class="mi">330</span><span class="p">,</span> <span class="mi">95</span><span class="p">],</span>
</span><span class="line">            <span class="p">[</span><span class="mi">410</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="p">[</span><span class="mi">475</span><span class="p">,</span> <span class="mi">44</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">167</span><span class="p">],</span> <span class="p">[</span><span class="mi">185</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="p">[</span><span class="mi">120</span><span class="p">,</span> <span class="mi">88</span><span class="p">],[</span><span class="mi">600</span><span class="p">,</span> <span class="mi">150</span><span class="p">]</span>
</span><span class="line">              <span class="p">];</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">xScale</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">scale</span><span class="p">.</span><span class="nx">linear</span><span class="p">()</span>
</span><span class="line">               <span class="p">.</span><span class="nx">domain</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">max</span><span class="p">(</span><span class="nx">dataset</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">d</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="p">})])</span>
</span><span class="line">               <span class="p">.</span><span class="nx">range</span><span class="p">([</span><span class="nx">padding</span><span class="p">,</span> <span class="nx">w</span><span class="o">-</span><span class="nx">padding</span><span class="o">*</span><span class="mi">2</span><span class="p">]);</span>
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">yScale</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">scale</span><span class="p">.</span><span class="nx">linear</span><span class="p">()</span>
</span><span class="line">                <span class="p">.</span><span class="nx">domain</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">max</span><span class="p">(</span><span class="nx">dataset</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">d</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span> <span class="p">})])</span>
</span><span class="line">                 <span class="p">.</span><span class="nx">range</span><span class="p">([</span><span class="nx">h</span> <span class="o">-</span> <span class="nx">padding</span><span class="p">,</span> <span class="nx">padding</span><span class="p">]);</span>
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">rScale</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">scale</span><span class="p">.</span><span class="nx">linear</span><span class="p">()</span>
</span><span class="line">               <span class="p">.</span><span class="nx">domain</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">max</span><span class="p">(</span><span class="nx">dataset</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">d</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span> <span class="p">})])</span>
</span><span class="line">               <span class="p">.</span><span class="nx">range</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]);</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">xAxis</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">svg</span><span class="p">.</span><span class="nx">axis</span><span class="p">()</span>
</span><span class="line">               <span class="p">.</span><span class="nx">scale</span><span class="p">(</span><span class="nx">xScale</span><span class="p">)</span>
</span><span class="line">               <span class="p">.</span><span class="nx">orient</span><span class="p">(</span><span class="s2">&quot;bottom&quot;</span><span class="p">)</span>
</span><span class="line">               <span class="p">.</span><span class="nx">ticks</span><span class="p">(</span><span class="mi">5</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">yAxis</span> <span class="o">=</span> <span class="nx">d3</span><span class="p">.</span><span class="nx">svg</span><span class="p">.</span><span class="nx">axis</span><span class="p">()</span>
</span><span class="line">              <span class="p">.</span><span class="nx">scale</span><span class="p">(</span><span class="nx">yScale</span><span class="p">)</span>
</span><span class="line">              <span class="p">.</span><span class="nx">orient</span><span class="p">(</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
</span><span class="line">              <span class="p">.</span><span class="nx">ticks</span><span class="p">(</span><span class="mi">5</span><span class="p">);</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="nx">svg</span><span class="p">.</span><span class="nx">selectAll</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">data</span><span class="p">(</span><span class="nx">dataset</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">enter</span><span class="p">()</span>
</span><span class="line">   <span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;circle&quot;</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cx&quot;</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span> <span class="p">{</span><span class="k">return</span> <span class="nx">xScale</span><span class="p">(</span><span class="nx">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]);})</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;cy&quot;</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span> <span class="p">{</span><span class="k">return</span> <span class="nx">yScale</span><span class="p">(</span><span class="nx">d</span><span class="p">[</span><span class="mi">1</span><span class="p">]);})</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">rScale</span><span class="p">(</span><span class="nx">d</span><span class="p">[</span><span class="mi">1</span><span class="p">]);})</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;fill&quot;</span><span class="p">,</span><span class="kd">function</span><span class="p">(</span><span class="nx">d</span><span class="p">){</span><span class="k">if</span> <span class="p">(</span><span class="nx">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">100</span><span class="p">)</span> <span class="p">{</span><span class="k">return</span> <span class="s2">&quot;teal&quot;</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span><span class="k">return</span> <span class="s2">&quot;orange&quot;</span><span class="p">}});</span>
</span><span class="line">
</span><span class="line">		
</span><span class="line"><span class="nx">svg</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;class&quot;</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="s2">&quot;translate(0,&quot;</span> <span class="o">+</span> <span class="p">(</span><span class="nx">h</span> <span class="o">-</span> <span class="nx">padding</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">call</span><span class="p">(</span><span class="nx">xAxis</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="nx">svg</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;class&quot;</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">attr</span><span class="p">(</span><span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="s2">&quot;translate(&quot;</span> <span class="o">+</span> <span class="nx">padding</span> <span class="o">+</span> <span class="s2">&quot;,0)&quot;</span><span class="p">)</span>
</span><span class="line">   <span class="p">.</span><span class="nx">call</span><span class="p">(</span><span class="nx">yAxis</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="nt">&lt;/script&gt;</span>
</span><span class="line"><span class="nt">&lt;/body&gt;</span>
</span><span class="line">
</span><span class="line"><span class="nt">&lt;/html&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>А вот и результат наших трудов:</p>

<div id="container5">
<style>

</style>
</div>
<script type="text/javascript">
        
        var w = 400;
        var h = 200;
        var padding = 40;

        
        var svg = d3.select("#container5")
             	      .append("svg")
          			  .attr("width", w)
          			  .attr("height", h);
        
        var dataset = [
                [50, 20], [480, 90], [250, 50], [100, 133], [330, 95],
                [410, 12], [475, 44], [25, 167], [185, 21], [120, 88],[600, 150]
              ];

        
        var xScale = d3.scale.linear()
                     .domain([0, d3.max(dataset, function(d) { return d[0]; })])
                     .range([padding, w-padding]); 
                     
        var yScale = d3.scale.linear()
                     .domain([0, d3.max(dataset, function(d) { return d[1]; })])
                     .range([h - padding, padding]);
                     
        var rScale = d3.scale.linear()
                     .domain([0, d3.max(dataset, function(d) { return d[1]; })])
                     .range([2, 5]);  
                     
                                
        var xAxis = d3.svg.axis()
                  .scale(xScale)
                  .orient("bottom")
                  .ticks(5);
                  
         var yAxis = d3.svg.axis()
                  .scale(yScale)
                  .orient("left")
                  .ticks(5);                    
                     
                     
         svg.selectAll("circle")
			   .data(dataset)
			   .enter()
			   .append("circle")
			   .attr("cx", function(d) {return xScale(d[0]);})
			   .attr("cy", function(d) {return yScale(d[1]);})
			   .attr("r", function(d) { return rScale(d[1]);})
			   .attr("fill",function(d){if (d[0]>100) {return "teal"} else {return "orange"}});

		
			svg.append("g")
			    .attr("class", "axis")
			    .attr("transform", "translate(0," + (h - padding) + ")")
                .call(xAxis);  
            svg.append("g")
                .attr("class", "axis")
                .attr("transform", "translate(" + padding + ",0)")
                .call(yAxis);                                 
        
</script>

<h2 id="section-1">Источники для самостоятельного изучения</h2>

<p>В этой статье мы очень поверхностно ознакомились с самыми основными принципами рисования графики с помощью D3.js. Для подробного изучения стоит прочитать несколько книг.</p>

<p>Начинать стоит с книги <strong>Interactive Data Visualization</strong>. Лучше использовать ее <a href="http://chimera.labs.oreilly.com/books/1230000000345/">бесплатную электронную версию</a>, потому что там более актуальный код и есть интерактивные примеры.</p>

<p>Для дальнейшего углубления подойдет <strong>Data Visualization with D3.js Cookbook</strong>. В ней хорошо и подробно описаны фундаментальные принципы работы библиотеки.</p>

<p><img src="http://datadeep.ru/images/bookcover1.jpg" width="272" height="336" title="Interactive Data Visualization" /> <img src="http://datadeep.ru/images/bookcover2.png" width="272" height="336" title="Data Visualization with D3.js Cookbook" /></p>

<p>Помимо книг, есть несколько хороших источников знаний по теме в Интернете:</p>

<ul>
  <li><a href="http://bost.ocks.org/mike/">сайт Майка Бостока</a> — автора библиотеки. Здесь много хороших примеров и просто интересных статей;</li>
  <li><a href="https://github.com/mbostock/d3/wiki">wiki проекта на GitHub</a> — наиболее полное описание всех функций;</li>
  <li><a href="https://www.dashingd3js.com/">Learn how to make Data Visualizations with D3.js</a> — пошаговое руководство для начинающих;</li>
  <li><a href="http://square.github.io/intro-to-d3/">Intro to D3.js</a> — еще одно;</li>
  <li><a href="http://www.d3noob.org/">D3.js Tips &amp; Tricks</a> — здесь встречаются полезные советы и объяснения тонких мест.</li>
</ul>

<p>Единственным полезным источником на русском (помимо нашего блога) являются материалы «Лаборатории данных»:</p>

<ul>
  <li><a href="http://d3-js.ru/mike/join/">«Мыслим связками»</a> — перевод статьи Майка Бостока. Очень полезная статья для понимания связи между данными и представлением в D3;</li>
  <li><a href="http://habrahabr.ru/company/datalaboratory/blog/217905/">Введение в D3</a> на Хабре;</li>
  <li><a href="http://brainwashing.pro/dataviz-online">Онлайн-курс «Визуализация. Основы»</a> включает в себя раздел про D3.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Оптимизация в машинном обучении]]></title>
    <link href="http://datadeep.ru/blog/2014/11/20/optimizatsiia-v-mashinnom-obmuchienii/"/>
    <updated>2014-11-20T23:00:01+03:00</updated>
    <id>http://datadeep.ru/blog/2014/11/20/optimizatsiia-v-mashinnom-obmuchienii</id>
    <content type="html"><![CDATA[<p><img src="http://datadeep.ru/images/optim_surface.png" width="768" height="576" title="Surface" />
<script type="math/tex">
\newcommand{loss}{\ell}
\newcommand{risk}{F}
\newcommand{hyp}{h}
\newcommand{eps}{\varepsilon}
</script></p>

<p>Привет, читатель! Обсуждая науку о данных, нельзя не упомянуть машинное обучение, а говоря о машинном обучении, никак невозможно пройти мимо такой темы как <em>оптимизация</em>. Что же такое оптимизация и какая она бывает? Как оптимизация связана с машинным обучением? Как быть быстрее, оптимальнее, точнее? </p>

<p>Если эти вопросы вызывают интерес — заходите.</p>

<!-- more -->

<h2 id="section">Связь оптимизации и машинного обученния</h2>

<p>Что такое оптимизация? В двух словах, оптимизация (как область знаний) изучает как <em>что-то</em> сделать <em>лучше</em>. Вернее, как <em>что-то</em> сделать <em>наилучшим образом</em>, то есть — <em>оптимально</em>. Оптимальность, обычно, понимается в смысле максимизации или минимизации определенного значения. Например, мы можем искать наиболее выгодную стратегию игры на бирже, максимизируя ожидаемую прибыль, или аэродинамически наиболее эффективную форму кузова автомобиля, минимизируя сопротивление воздуха. Конечно же, этими примерами оптимизация не ограничивается, встречаясь повсеместно. Можно даже придти к выводу, что практически любой процесс — оптимизационный с той или иной точки зрения, но это, скорее, вопрос философский.</p>

<p>Разобравшись с оптимизацией “на пальцах”, определим ее формально, а формально задача математической оптимизации записывается следующим образом:</p>

<script type="math/tex; mode=display">
\risk(\theta) \longrightarrow \min\limits_{\theta\in\mathcal{X}}.
</script>

<p>Так вот, просто и незатейливо. Но постойте, кто эти <script type="math/tex">\risk</script>, <script type="math/tex">\theta</script>, <script type="math/tex">\mathcal{X}</script> и какое отношение они имеют к машинному обучению?</p>

<p>Оказывается, большинство задач машинного обучения формулируются именно таким образом: в виде минимизации некоего функционала <script type="math/tex">\risk</script> по некоторому параметру <script type="math/tex">\theta</script>. Например, в случае задачи классификации или регрессии мы стараемся предсказывать одну переменную (<script type="math/tex">y</script>) на основе другой (<script type="math/tex">x</script>) с помощью набора функций–“оракулов” <script type="math/tex">\{\hyp_\theta\}_{\theta\in\mathcal{X}}</script>, выбирая наилучшую из них на основе <em>обучающей выборки</em> <script type="math/tex">\{x_i, y_i\}_{1}^N</script> — в таком случае мы хотим минимизировать ошибку предсказания на имеющейся выборке. Ошибку предсказания чаще всего записывают как</p>

<script type="math/tex; mode=display"> \risk(\theta) = \sum_{i=1}^n \loss(\hyp_{\theta}(x_i), y_i),</script>

<p>где <script type="math/tex">\loss(\hyp_{\theta}(x_i), y_i)</script> — мера отличия предсказания <script type="math/tex">\hyp_{\theta}(x_i)</script> от истинного значения <script type="math/tex">y_i</script>. Чтобы не витать в облаках, рассмотрим конкретный вид <script type="math/tex">\risk(\theta)</script> для двух распространенных методов машинного обучения: метода <script type="math/tex">K</script>-средних и линейной регрессии с квадратичной функцией потерь.</p>

<h4 id="k-">Метод <script type="math/tex">K</script>-средних</h4>

<p>Этот метод решает задачу кластеризации — разбиения множества точек <script type="math/tex">\{x_i\}_1^N</script> на <script type="math/tex">K</script> (<script type="math/tex">\leq N</script>) непересекающихся множеств-кластеров.  Результат кластеризации методом $K$-средних — это, во-первых, разбиение множества ${1,\ldots,N}$ на <script type="math/tex">K</script> кластеров: <script type="math/tex">\{\mathcal{C}_k\}_1^K</script> и, во-вторых, центр каждого из этих кластеров: <script type="math/tex">\{\mu_k\}_1^K</script>. Функция <script type="math/tex">\risk(\theta)</script> при фиксированном $K$ для метода $K$-средних записывается следующим образом</p>

<script type="math/tex; mode=display">
\risk\left(\theta = \left(\{\mathcal{C}_k\}_1^K, \{\mu_k\}_1^K\right)\right) = \sum_{k=1}^K \sum_{i\in \mathcal{C}_k} (x_i - \mu_k)^2 \to \min\limits_{\theta},
</script>

<p>— то есть метод <script type="math/tex">K</script>-средних ищет такое разбиение множества <script type="math/tex">\{x_i\}_1^N</script> на кластеры, чтобы сумма расстояний от каждой точки до центра кластера, которому она принадлежит, была минимальна.</p>

<h4 id="section-1">Линейная регрессия с квадратичной функцией потерь</h4>

<p>Этот метод решает задачу регрессии — предсказания выходов <script type="math/tex">y_i\in\mathbb{R}</script> по входам <script type="math/tex">x_i=(x_i^{(1)},\ldots,x_i^{(p)})^T\in\mathbb{R}^p</script> на основе обучающей выборки <script type="math/tex">\{ x_i, y_i \}_1^N</script>. Метод линейной регрессии “предполагает”, что выход <script type="math/tex">y_i</script> может быть представлен в виде линейной функции от входов <script type="math/tex">x_i^{(1)},\ldots,x_i^{(p)}</script> и от параметров <script type="math/tex">\theta^{(1)},\ldots,\theta^{(p)}</script>: <script type="math/tex">y_i = \sum_{j=1}^p \theta^{(j)} x_i^{(j)}</script>. <script type="math/tex">\risk(\theta)</script> записывается следующим образом:</p>

<script type="math/tex; mode=display">
\risk(\theta) = \sum_{i=1}^N (x_i^T\theta - y_i)^2 \to \min\limits_{\theta},
</script>

<p>— здесь минимизируется среднеквадратичное отклонение “предсказаний” <script type="math/tex">x_i^T\theta</script> от истинных значений <script type="math/tex">y_i</script>.</p>

<p>Таким образом, и метод <script type="math/tex">K</script>-средних и линейная регрессия минимизируют конкретные функции <script type="math/tex">F(\theta)</script> (вся хитрость методов, в том <strong>как</strong> они это делают), решая частные задачи оптимизации. Приложив определенные усилия, функция <script type="math/tex">\risk(\theta)</script> может быть выписана для сколь угодно сложной модели, например, для сверточной нейронной сети. Но мы этого делать не будем: и так хорошо понятно, что в машинном обучении оптимизация играет очень важную роль. </p>

<h2 id="section-2">Математическая оптимизация</h2>

<p>Решив, что оптимизация в машинном обучении, а значит и в нашем арсенале — must have, обсудим ее поподробнее.</p>

<p>Математическая оптимизация зародилась в XVIII–XIX века и окончательно оформилась в XX веке. За этот срок у нее появилось множество видов, подвидов, методов и приложений. Как мы и упомянали выше, общая задача оптимизации ставится следующим образом</p>

<script type="math/tex; mode=display">
\risk(\theta) \longrightarrow \min\limits_{\theta\in\mathcal{X}},
</script>

<p>но от настолько общей постановки мало толку — совершенно непонятно как ее решать: не имея информации о природе <script type="math/tex">\risk</script> и <script type="math/tex">\mathcal{X}</script>, мы безоружны, можем только вслепую тыкать “пальцем в небо” (вернее, в <script type="math/tex">\mathcal{X}</script>) в надежде попасть в точку минимума.
Собственно, чем не вариант, есть даже схожий по идее метод с вполне себе научным названием: метод <em>равномерного поиска</em> (aka перебора). Суть его, как вы уже догадались, состоит в том, чтобы наложить <script type="math/tex">\varepsilon</script>-сетку на множество <script type="math/tex">\mathcal{X}</script> и измерить функцию <script type="math/tex">\risk</script> в каждом узле сетки. Так найдется узел <script type="math/tex">\hat\theta</script> с наименьшим значением <script type="math/tex">\risk</script>, и … пользы от этого знания будет чуть больше чем никакой.
Без дополнительных ограничений на <script type="math/tex">\risk</script> и/или <script type="math/tex">\mathcal{X}</script> наш <script type="math/tex">\hat\theta</script> ничего не говорит ни о наимаеньшем значении <script type="math/tex">\risk^* = \min\limits_{\theta\in\mathcal{X}} \risk(\theta)</script> не о соответствующем аргументе <script type="math/tex">\theta^* = \arg\min\limits_{\theta\in\mathcal{X}} \risk(\theta)</script>. Действительно, <script type="math/tex">\risk</script> может меняться сколь угодно быстро, принимая между узлами сетки какие угодно значения, а то и вовсе быть разрывной. То есть знания о функции в узлах не говорит ничего о ней вне этих узлов. Так вот, старались-старались, считали функцию в каждом узле, а толку — ноль.</p>

<p>Но не стоит отчаиваться, надо это дело исправить. В чем наша проблема?
Проблема наша в излишнней свободе функции $\risk$, точнее в неограниченной скорости ее изменения. </p>

<p>Так давайте ее ограничим! Например, вот так:</p>

<script type="math/tex; mode=display">
|\risk(\theta_1) - \risk(\theta_2)| \leq L |\theta_1 - \theta_2|
</script>

<p>т.е. мы запретили <script type="math/tex">\risk</script> менятся как угодно быстро, ограничив ее изменение линейно изменением ее аргумента (это условие на <script type="math/tex">\risk</script>, называется <em>условием Липшица</em>, очень, кстати, полезное и распространенное свойство в оптимизации). Теперь наша оценка <script type="math/tex">\hat\theta</script> кое-чего стоит:</p>

<script type="math/tex; mode=display">|\risk(\hat\theta) - \risk^*| \leq \varepsilon L \sqrt{p}, </script>

<p>где <script type="math/tex">p</script> — размерность <script type="math/tex">\mathcal{X}</script>. Местоположении <script type="math/tex">\theta^*</script>, однако, до сих пор остается загадкой.</p>

<p>Можно продолжить модифицировать метод перебора, добиваясь лучших гарантий точности (как по параметру, так и по значению функции), и увеличивая вычислительную эффективность (мы вычислили <script type="math/tex">\risk</script> порядка <script type="math/tex">O\left(\frac{V(\mathcal{X})}{\varepsilon^p}\right)</script> раз, где <script type="math/tex">V(\mathcal{X})</script> — объем <script type="math/tex">\mathcal{X}</script>, что даже в невинном единичном кубе при <script type="math/tex">\varepsilon = 0.01</script> даст миллион). Но это займет немало времени, а метод перебора интересен нам сейчас с той только точки зрения, что демонстрирует две важные идеи:</p>

<ol>
  <li><a href="http://www.no-free-lunch.org/">There is no free lucnh</a>. Чтобы эффективно решить задачу оптимизации, нам нужно ее ограничить — сузить круг поисков. Тем быстрее и точнее мы хотим ее решить, тем более жесткие ограничения нам придется накладывать;</li>
  <li>Лучшее — враг хорошего. Иногда достаточно найти приближенное к оптимальному решение, сэкономив при этом на ресурсах.</li>
</ol>

<p>Как было сказано, оптимизация как наука обширна и изучает множество различных задач и методов. Все, однако, нам рассматривать не нужно: в машинном обучении актуальны только некоторые из них, в частности очень распространены так называемые <em>градиентные методы</em>. Нам градиентные методы интересны как с точки зрения того, что развивают две усвоенные ранее идеи, так и из тех соображений, что они являются основой для многих других методов оптимизации. Именно о градиентных методах и пойдет речь далее.</p>

<h2 id="section-3">Градиентные методы</h2>

<p>Идея градиентных методов в том, что в каждой точке <script type="math/tex">\theta_0</script> мы можем измерить градиент функции <script type="math/tex">\nabla \risk(\theta_0)</script>, который подскажет нам, как изменяется функция в окрестности <script type="math/tex">\theta</script>. Попробуем объяснить, откуда растут ноги у этой идеи: зафиксируем <script type="math/tex">\theta_0</script>, <script type="math/tex">\delta</script> и расмотрим разложение функции <script type="math/tex">\risk</script> в ряд Тейлора в точке <script type="math/tex">\theta_0 + \delta</script>:</p>

<script type="math/tex; mode=display">
\risk(\theta_0 + \delta) = \risk(\theta_0) +
\nabla \risk(\theta)\delta +
\nabla^2 \risk(\theta_0) \frac{\delta^2}{2} +
\ldots +
\nabla^n \risk(\theta_0) \frac{\delta^n}{n!} +
\ldots
</script>

<p><script type="math/tex">\delta</script> предполагается достаточно малым, поэтому <script type="math/tex">\delta^n</script> убывает очень быстро и обычно рассматривают только первую компоненту:</p>

<script type="math/tex; mode=display">
\risk(\theta_0 + \delta) \simeq \risk(\theta_0) +
\nabla \risk(\theta)\delta.
</script>

<p>Таким образом, в окрестности точки <script type="math/tex">\theta_0</script> мы приблизили <script type="math/tex">\risk</script> линейной функцией. Градиентные методы эксплуатируют это приближение, полагаясь на то, что минимизация <script type="math/tex">\risk</script> эквивалентна минимизации ее линейного приближения в небольшой окрестности точки <script type="math/tex">\theta_0</script>. А что такое “небольшая окрестность”? Ограничим ее шаром с радиусом <script type="math/tex">\alpha</script> <script type="math/tex">(\mid\delta\mid \leq \alpha)</script>, тогда в этой окрестности минимум будет достигаться при</p>

<script type="math/tex; mode=display">
\delta^* = \arg\min\limits_{|\delta|\leq \alpha}\left[ \risk(\theta_0) + \nabla \risk(\theta)\delta \right] = - \alpha\frac{\nabla \risk(\theta)}{|\nabla \risk(\theta)|}.
</script>

<p>Фактически, мы сделали шажок длиной <script type="math/tex">\alpha</script> в направлении <em>противоположном</em> направлению градиента <script type="math/tex">\nabla \risk(\theta)</script>. Это вполне логично, ведь направление градиента — это направление наибольшего роста функции, а противоположное ему — направление наискорейшего ее уменьшения. В этом и заключается основная идея градиентных методов: шаг за шагом, спускаться против направления градиента к минимуму. С этими знаниями можем уже сформулировать простенький алгоритм оптимизации</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\text{Simple_Gradient_Descent}(\risk, \, \theta_0, \, \alpha):
\\
\begin{eqnarray*}
& \qquad \qquad & k \leftarrow 0
\\
& \qquad \qquad& \textbf{while} \; not \; converged \;:
\\
& \qquad \qquad & \qquad k \leftarrow k + 1
\\
& \qquad \qquad & \qquad \theta_k \leftarrow \theta_{k-1} - \alpha\frac{\nabla \risk(\theta_{k-1})}{|\nabla \risk(\theta_{k-1})|}
\\
& \qquad \qquad & \textbf{return}\; \theta_k
\end{eqnarray*}
 %]]&gt;</script>

<p>Действительно, ничего сложного: один за другим делаем шажочки длиной <script type="math/tex">\alpha</script> против направления градиента. Условие остановки <script type="math/tex">not\;converged</script> мы пока конкретизировать не будем, это может быть условие на максимальное количество итераций (<script type="math/tex">% &lt;![CDATA[
k < k_{max} %]]&gt;</script>), изменение значения функции <script type="math/tex">% &lt;![CDATA[
f(\theta_{k-1}) - f(\theta_{k}) < \eps %]]&gt;</script>, параметра <script type="math/tex">% &lt;![CDATA[
||\theta_{k-1} - \theta_{k}||_2 < \eps %]]&gt;</script>, нам сейчас это не важно (справедливости ради, на практике зачастую оказывается одним из важнейших вопросов).
Алгоритм выглядит разумно, но у него есть серьезный недостаток: он учитывает только направление, но не длину градиента. Так мы можем сделать слишком маленький шаг там, где градиент велик, тем самым увеличив количество итерации, либо слишком большой шаг там, где градиент мал, пройдя мимо точки оптимума.</p>

<p>К счастью, мы можем избавится от этих недостатков, немного изменив наш алгоритм</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\text{Gradient_Descent}(\risk, \, \theta_0, \, \alpha):
\\
\begin{eqnarray*}
& \qquad \qquad & k \leftarrow 0
\\
& \qquad \qquad& \textbf{while} \; not \; converged \;:
\\
& \qquad \qquad & \qquad k \leftarrow k + 1
\\
& \qquad \qquad & \qquad \theta_k \leftarrow \theta_{k-1} - \alpha_k\nabla \risk(\theta_{k-1})
\\
& \qquad \qquad & \textbf{return}\; \theta_k
\end{eqnarray*}
 %]]&gt;</script>

<p>Этот “алгоритм” есть ни что иное, как метод <em>градиентного спуска</em> (<em>gradient descent</em>). Известно, что при некоторых условиях на <script type="math/tex">\risk</script> и <script type="math/tex">\alpha_k</script> (например, <script type="math/tex">\risk</script> выпукла, <script type="math/tex">\nabla \risk</script> удовлетворяет условию Липшица, а <script type="math/tex">\alpha_k = \alpha</script> ), значение <script type="math/tex">\risk</script> в оценках метода градиентного спуска <script type="math/tex">\theta_k</script> стремится к оптимальному</p>

<script type="math/tex; mode=display">
|\risk(\theta_k) - \risk^*| \xrightarrow{k\to\infty} 0
</script>

<p>— это не может не радовать.</p>

<p>Теперь у нас есть теоретически обоснованный алгоритм оптимизации, пора применить его в боевых условиях.</p>

<h2 id="section-4">Пример. Линейная регрессия с использованием метода градиентного спуска</h2>

<p>Выше мы уже упомянали задачу линейной регрессии (с квадратичной функцией ошибки). Напомним ее целевую функцию <script type="math/tex">\risk</script>:</p>

<script type="math/tex; mode=display">
\risk(\theta) = \sum_{i=1}^N (x_i^T\theta - y_i)^2 \to \min\limits_{\theta},
</script>

<p>В матричном виде она записывается как</p>

<script type="math/tex; mode=display">
\risk(\theta) = ||X\theta - y||_2^2 = (X\theta - y)^T (X\theta - y) \to \min\limits_{\theta},
</script>

<p>где <script type="math/tex">X\in\mathbb{R}^{N\times p}</script> — матрица, чьи строки — <script type="math/tex">x_i</script>, а <script type="math/tex">y = (y_1,\ldots,y_N)</script>.
Существует аналитическое решение этой задачи: <script type="math/tex">\hat\theta = (X^T X)^{-1} X^T y</script> (оценка <a href="http://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BD%D0%B0%D0%B8%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B8%D1%85_%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BE%D0%B2">методом наименьших квадратов</a>). Но операция обращения матрицы довольно <a href="http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Matrix_algebra">дорогая</a>, в особенности в задачах, где размерность <script type="math/tex">x</script> огромна и матричные операции просто не могут быть выполнены в памяти.
К счастью, наша функция <script type="math/tex">\risk</script> удовлетворяет всем необходимым условиям и для нее выполняется соотношение <script type="math/tex">|\risk(\theta_k) - \risk^*| \xrightarrow{k\to\infty} 0</script>. Поэтому мы имеем полное право воспользоваться методом градиентного спуска.</p>

<p>В первую очередь нам нужны данные: <script type="math/tex">\{x_i, y_i\}_1^N</script>, для простоты возьмем модельные (<script type="math/tex">N=1000</script>):</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{eqnarray*}
&x^{(1)}_i & \sim \mathcal{N}(0, 1), \quad &i=1,\ldots, 1000
\\
&y_i &= 2 x^{(1)}_i - 0.5 + \varepsilon_i, \qquad &\varepsilon_i \sim \mathcal{N}(0, 1).
\end{eqnarray*}
 %]]&gt;</script>

<p>То есть все <script type="math/tex">x_i^{(1)}</script> распределены по стандартному нормальному закону, а <script type="math/tex">y_i</script> — линейная функция от <script type="math/tex">x_i^{(1)}</script> с аддитивной помехой (так же имеющей стандртное нормальное распределение). Ниже изображены эти данные в плоскости <script type="math/tex">(x^{(1)}, y)</script>.
<img src="http://datadeep.ru/images/data.png" width="768" height="576" title="Data" /></p>

<p>“Лишний” индекс <script type="math/tex">^{(1)}</script> к <script type="math/tex">x^{(1)}</script> мы добавили неспроста: если обозначить <script type="math/tex">x_i^{(2)}=1</script> для всех <script type="math/tex">i</script>, то можно переписать <script type="math/tex">y_i = 2 x_i^{(1)} - \frac{1}{2}x_i^{(2)} + \varepsilon_i</script> и более того, в матричной форме</p>

<script type="math/tex; mode=display">y = X\theta^* + \varepsilon.</script>

<p>где </p>

<script type="math/tex; mode=display">% &lt;![CDATA[

	y = (y_1,\ldots,y_n)^T,
\\
	X = \begin{pmatrix}
		x_1^{(1)} & x_1^{(2)} \\ 
		x_2^{(1)} & x_2^{(2)} \\ 
		\vdots & \vdots \\
		x_n^{(1)} & x_n^{(2)}
	\end{pmatrix},
\\
	\varepsilon =(\varepsilon_1,\ldots,\varepsilon_n)^T,
\\
 	\text{a }\, \theta^*=(2, -\frac{1}{2}).
 %]]&gt;</script>

<p>Итак, мы определили <script type="math/tex">X</script> и <script type="math/tex">y</script> (и неизвестный нам по легенде <script type="math/tex">\theta^*</script>). Для того, чтобы воспользоваться методом градиентного спуска остается найти производную <script type="math/tex">\nabla \risk</script>, что довольно просто:</p>

<script type="math/tex; mode=display">
\nabla \risk(\theta) =\nabla_\theta \left[ (X\theta - y)^T (X\theta - y)\right] = X^T (X\theta - y) .
</script>

<p>Теперь все готово. Остается применить метод градиентного спуска к задаче линейной регрессии со сгенерированными нами данными.
Зададим <script type="math/tex">\alpha=0.0001</script>. Ниже иллюстрируется работа нашего алгоритма: как изменялась линия регрессии, построенная по оценкам <script type="math/tex">(\theta_k^{(1)},\theta_k^{(2)})</script>, на каждой итерации.</p>

<p><img src="http://datadeep.ru/images/LinearRegression_GradientDescent_50iter.gif" width="768" height="576" title="Gradient Descent iterations" /></p>

<p>Успех: за 56 итераций мы получили приближение c точностью до второго знака после запятой как по параметру <script type="math/tex">(\mid\mid\theta^* - \theta_{56}\mid\mid \simeq 0.02)</script>, так и по значению функции <script type="math/tex">(F(\theta_{56}) - F(\theta^*) \simeq 0.07)</script></p>

<h2 id="section-5">Заключение</h2>
<p>Надеюсь, мне удалось ответить на вопросы, заданные в самом начале статьи. Мы поставили общую задачу оптимизации, на паре примеров узнали как она связана с задачей машинного обучения, и логично пришли к методу градиентного спуска, даже применив его на практике. Вполне неплохо, в последующих статьях я постараюсь лучше раскрыть тему применения алгоритмов оптимизации в машинном обучении и прояснить некоторые интересные детали.</p>

<p>Напоследок, порекомендую пару интересных материалов по теме:</p>

<ul>
  <li><a href="http://www.mdk-arbat.ru/bookcard?book_id=3326320">Введение в оптимизацию. Поляк Б.Т.</a> — книга от ученого с мировым именем, не только формальным, но и доступным языком рассказывает об основнах оптимизации, помогая уяснить в первую очередь не конкретные задачи и метода, а идеи, стоящие за ними;</li>
  <li><a href="http://web.stanford.edu/class/ee364a/">EE364a: Convex Optimization. Бойд С.</a> — записанные курсы Стэндфордского университета по выпуклой оптимизации (мы этого еще не знаем, но методы выпуклой оптимизации — если не самые важные, то абсолютно незаменимые в машинном обучении);</li>
  <li><a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D0%BE%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%B2_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%29">Методы оптимизации в машинном обучении. Кропотов Д.А.</a> — развернутое содержание курса лекций факультета вычислительной математики и кибернетики МГУ. Без конспектов, к сожалению но с отличной подборкой литературы;</li>
  <li><a href="https://www.coursera.org/course/ml">Machine learning</a> — курс посвященный машинному обучению от известного ученого и сооснователя сервиса онлайн-обучения <a href="https://www.coursera.org">Coursera.org</a> Andrew Ng, который помимо объяснения самих алгоритмов большое внимание уделяет вопросу оптимизации. Между прочим, картинка для привлечения внимания взята из слайдов одной и лекций этого курса (лекции второй недели, посвященные простейшей линейной регрессии).</li>
</ul>

<p>До встречи!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Что такое Data Science?]]></title>
    <link href="http://datadeep.ru/blog/2014/11/07/chto-takoie-data-science/"/>
    <updated>2014-11-07T14:08:41+03:00</updated>
    <id>http://datadeep.ru/blog/2014/11/07/chto-takoie-data-science</id>
    <content type="html"><![CDATA[<p>Блог datadeep.ru будет посвящён <em>Data Science</em> (<em>Науке о данных</em>, по-русски её также иногда называют <em>Даталогия</em>). Поэтому первый пост в блоге мне представляется логичным посвятить описанию науки о данных в представлении авторов блога, чтобы читатель мог составить для себя мнение о том, что его ждёт в дальнейшем.</p>

<p><img src="http://datadeep.ru/images/data_science.jpg" width="768" height="576" title="Data Science" /></p>

<!-- more -->

<p><a href="http://blog.andreamostosi.name/2014/09/how-to-stay-updated-about-data-science-and-big-data/">Первоисточник картинки.</a></p>

<p>В последние несколько лет в науке и промышленности можно наблюдать повышенный интерес к новой области знания, называемой Data Science или Наука о данных. Компания McKinsey оценивает нехватку специалистов к 2018 году в 140 000 - 190 000 человек. Журнал Harvard Business Review назвал науку о данных одной из самых перспективных профессий (the sexiest job) XXI века. Резко возрос спрос на таких специалистов.</p>

<p><img src="http://datadeep.ru/images/Data_Scientist_Job_Trend.png" title="Job Trends" /></p>

<p>Такие компании, как Google, Facebook, Microsoft, Apple, Linkedin, Baidu активно нанимают к себе профессионалов в области науки о данных. В Интернете появилось большое количество ресурсов, посвящённых Data Science, например, различные MOOC (online-курсы по Machine Learning и Data Mining на образовательных сайтах), специализированные блоги. В прессе появляется всё больше сообщений об успехах в области науки о данных. Университеты предлагают студентам программы обучения по Data Science (например, Имперский колледж Лондона, Вашингтонский университет, Нью-Йоркский университет и т.д.). Что же такое — наука о данных? </p>

<p>Потребность в анализе данных, нахождении в них закономерностей во многом обусловлена феноменом Big Data, т.е. необходимостью в манипулировании и обработке данных огромных объёмов, различной природы, часто плохо структурированных. Это стало возможно благодаря развитию Интернета и технологий хранения и передачи информации. У компаний накопилось очень много различных данных, и закономерно появилась задача извлечения из них полезной информации, которая может помочь в принятии решений. Традиционным подходом к проблемам такого вида была статистика, получившая большое развитие в XX веке. Однако, одних возможностей, которые предоставляет статистический аппарат, мало для всестороннего анализа больших неструктурированных данных. Стало понятно, что специалисту по анализу данных необходим сплав знаний из различных областей математики, статистики, информатики и предметной области знаний. Кроме того, стоит выделить в отдельную категорию задачи, связанные с искусственным интеллектом, такие как компьютерное зрение, обработка естественного языка, речи. Таким образом, Data Science является весьма эклектичной дисциплиной, это хорошо показано на диаграмме (ставшей обязательной для статей о Data Science, <a href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram">первоисточник</a>):</p>

<p><img src="http://datadeep.ru/images/venn_diag.png" title="Venn Diagram" /></p>

<p>На мой взгляд, основные области, в которых требуются знания человеку, занимающемуся наукой о данных (его называют <em>data scientist</em> или иногда <em>датологом</em>) являются статистика и математика, машинное обучение, информатика (Computer Science), различные прикладные области. Сделаем их краткий обзор. Однако, перед этим давайте разберёмся с самим термином “наука о данных”.</p>

<p>Сейчас можно найти огромное количество различной информации на этот счёт: от Википедии до блогов. Во всех этих источниках нет чёткого и однозначного определения Data Science, что не удивительно, потому что наука о данных — ещё очень молодая и активно развивающаяся область знания, она не успела как следует оформиться ни в академических кругах, ни в обществе. </p>

<p>Существует несколько более-менее устоявшихся в научной литературе и публицистике терминов, связанных с наукой о данных: Data Science, Data Mining (интеллектуальный анализ данных), Machine Learning (машинное обучение). Значения и взаимосвязь этих терминов в разных источниках могут трактоваться по-разному, я рассматриваю Machine Learning как часть Data Mining, которая в свою очередь входит в понятие Data Science. В этой статье я постараюсь рассказать, чем является наука о данных на мой взгляд. </p>

<h2 id="section">Статистика и математика</h2>

<p>Для успешного применения алгоритмов анализа данных, для того, чтобы иметь возможность их исследовать и модернизировать под нужды конкретной задачи, важна базовая математическая подготовка на уровне университетских курсов. Нужны знания в линейной алгебре, математическом анализе, функциональном анализе, теории графов. Конечно, вполне возможно просто применять готовые решения к данным (например, библиотеки Apache Mahout для Java, scikit-learn для Python, множество пакетов для языка R и т.д.), однако для получения наилучшего результата анализа данных часто бывает необходима настройка алгоритмов для решения поставленной задачи, и человек, обладающий соответствующей математической подготовкой, имеет большую свободу в этом вопросе. И я не говорю про научное исследование методов анализа данных, в этом случае ясно, что без знания математических основ не обойтись. Отмечу, что на мой взгляд для успешной практики в Data Science не требуются глубокие знание в описанных выше областях, но вполне могут возникнуть задачи, для решения которых потребуется увеличить познания в какой-то из этих тем, например, для решения задачи кластеризации на графах явно не будет лишним повысить осведомлённость в теории графов.</p>

<p>Особняком стоит теория вероятностей. Она является базой для математической статистики и машинного обучения. Почти все методы анализа данных основаны на ней. Кроме того, существует перспективный класс методов стохастической оптимизации, который использует аппарат теории вероятностей, а оптимизация является составной частью машинного обучения. Про машинное обучение и оптимизацию будет рассказано дальше. Исходя из всего этого, достаточно глубокие знания в теории вероятностей очень важны для успешного анализа данных.</p>

<p>Одним из краеугольных камней Data Science является математическая статистика. Это наука, которая на основе ограниченной выборки позволяет сделать выводы о структуре данных, используя для оценки точности этих выводов теорию вероятностей. Статистический аппарат представляет собой совокупность различных методов построения вероятностных моделей для описания природы случайных событий. Долгое время анализ данных и статистика были практически синонимами. Можно выделить несколько разделов статистики. Такие методы, как построение таблиц, графиков данных, выделение различных количественных показателей из данных (среднее значение, стандартное отклонение, эксцесс, квантиль, математическое ожидание, дисперсия и т.д.) являются элементами описательной статистики. Она часто применяется при первичной обработке данных для того, чтобы составить некоторое первоначальное представление о них. С этой процедурой связаны методы очистки данных, т.е. удаления инородных, ненужных элементов, которые могут отрицательно сказаться на результатах анализа. Кроме того, стоит упомянуть связанные с предыдущими процедуры Data Munging или Data Wrangling, которые используют визуализацию, статистические модели, методы описательной статистики и другие подходы для преобразования данных в некоторый более удобный для дальнейшей работы вид.</p>

<p>Следующим разделом статистики являются методы оценивания. Они позволяют по выборке данных построить оценки различных параметров (в предположении, что данные описываются некоторыми вероятностными распределениями): математического ожидания, стандартного отклонения, квантилей, плотности и функции распределений. Также существуют методы, которые строят так называемые доверительные интервалы для искомых параметров. Другой важной областью является проверка статистических гипотез, задача которой состоит в проверке утверждений о распределении случайной величины по выборке из данных. Для этого строятся доверительная, критическая области, статистика критерия (с помощью выборки) и проверяется её попадание в одну из этих областей, на основании чего делаются некоторые вероятностные выводы о том, отвергается ли утверждение. Сюда относятся такие понятия, как ошибки первого и второго рода, мощность критерия, уровень значимости.</p>

<h2 id="section-1">Машинное обучение</h2>

<p>Следующей частью, входящей в состав науки о данных, является <em>Машинное обучение</em> (<em>Machine Learning</em>). Существует большое количество вариантов определения этого понятия. В книге Тома Митчелла (Tom Mitchell) “Machine Learning” приводится следующее объяснение (довольно часто цитируемое):</p>

<blockquote>
  <p>Будем говорить, что компьютерная программа обучается из опыта E относительно некоторого класса задач T и меры качества P, если качество её работы на задачах из T, измеренное с помощью P, возрастает с опытом E.</p>
</blockquote>

<p>Машинное обучение применяется в тех случаях, когда существует некоторая закономерность, структура в данных, которую необходимо извлечь, но это нельзя сделать обычным математическим путём, и для достижения поставленной цели используются данные. Таким образом, можно сказать, что машинное обучение занимается обучением модели из доступных данных так, чтобы она наилучшим образом обобщалась на неизвестные данные относительно некоторой меры качества.</p>

<p>Существует несколько близких к понятию Machine Learning, а, зачастую, и обозначающих его в книгах и статьях, терминов: <em>Statistical Learning</em> и <em>Pattern Recognition</em>. Statistical learning (статистическое обучение) встречается в работах, связанных с теорией Вапника-Червоненкиса, машиной опорных векторов (SVM), обобщающей способностью алгоритмов. Pattern recognition (распознавание образов) часто упоминается в статьях и книгах по кибернетике и математической оптимизации.</p>

<p>Рассмотрим основные классы методов машинного обучения. Пусть входные данные состоят из объектов, имеющих как наблюдаемые свойства, так и ненаблюдаемые, но известные. Алгоритмы, которые вычисляют эти ненаблюдаемые свойства по наблюдаемым, причём не только для входных данных, но и для любых других, называются алгоритмами <em>обучения с учителем</em> (<em>supervised learning</em>). Т.е. тренировочная выборка данных состоит из пар $(x_k, y_k)$, где $x_k$ — объект данных, а $y_k$ — некоторое числовое значение. На практике обычно строят хотя бы алгоритм, который ошибается не очень часто и не очень сильно. После обучения получается модель $h_{\theta}(x)$, зависящая от параметров $\theta$, и принимающая на вход новые объекты, для которых предсказывает соответствующее числовое значение. Задачи обучения с учителем различают в зависимости от природы $y_k$: если $y_k$ означает принадлежность к какому-то классу (метка класса), т.е. принимает значения на ограниченном множестве целых чисел, то задача называется задачей <em>классификации</em> (или <em>распознавания</em>), в противном случае, когда $y_k$ может быть любым вещественным числом, задача называется <em>задачей регрессии</em>. Примеры методов этого класса: метод $k$ ближайших соседей, логистическая регрессия, нейронные сети, машина опорных векторов, наивный байесовский классификатор.</p>

<p>Приведу пример работы алгоритма обучения с учителем. На картинке ниже изображены данные: ярким цветом — тренировочные, более блёклым — тестовые.</p>

<p><img src="http://datadeep.ru/images/supervised_learning_data.png" title="Supervised Learning Data" /></p>

<p>На следующей картинке изображён результат работы метода $k$ ближайших соседей на этих данных, ошибка классификации: $0.9$.</p>

<p><img src="http://datadeep.ru/images/supervised_learning_res.png" title="Supervised Learning Result" /></p>

<p>Существует и класс алгоритмов <em>обучения без учителя</em> (<em>unsupervised learning</em>). В этом случае входные данные состоят только из объектов $x_k$. Обучение без учителя является очень важным разделом машинного обучения, т.к. данных, не имеющих меток (например, картинок, для которых не указано, что на них изображено), в огромное количество раз больше, чем размеченных данных, потому что метки классов чаще всего расставляются вручную. К этому классу алгоритмов можно отнести методы понижения размерности данных, <em>обучения признаков</em> (<em>feature learning</em>), но одними из самых используемых являются методы <em>кластерного анализа</em> (<em>cluster analysis</em>). Пусть входные данные состоят из объектов с некоторыми наблюдаемыми свойствами. Алгоритм, который разбивает данные на группы (кластеры) и определяет, какому кластеру принадлежит объект, называется алгоритмом <em>кластеризации</em>. Данные разбиты на группы так, что внутри каждого кластера объекты похожи, а объекты из разных кластеров — непохожи. При этом такое разбиение статистически верно не только для входных данных, но и для новых, неизвестных ранее объектов. Примеры: метод $k$-средних, спектральная кластеризация, анализ главных компонент (PCA).</p>

<p>Проиллюстрирую работу алгоритма обучения без учителя. На картинке ниже изображены входные не размеченные данные.</p>

<p><img src="http://datadeep.ru/images/unsupervised_learning_data.png" title="Unsupervised Learning Data" /></p>

<p>На следующей картинке изображён результат работы метода $k$-средних для $k=3$.</p>

<p><img src="http://datadeep.ru/images/unsupervised_learning_res.png" title="Unsupervised Learning Result" /></p>

<p>В отдельный класс выделяют алгоритмы <em>обучения с подкреплением</em> (<em>reinforcement learning</em>). Это особый вид машинного обучения, при котором обучение происходит путём взаимодействия с внешней средой. На вход такому алгоритму подаются данные, состоящие из $(x_k, y_k)$, где $y_k$ — некая реакция среды. Обучение с подкреплением является очень интересной областью для исследований, которая активно используется в кибернетике и робототехнике. Хорошими примерам задач для методов этого класса являются игры. Например, существуют реализации алгоритмов обучения с подкреплением для игры в шахматы или в “Space Invaders” (компания <a href="http://deepmind.com/">DeepMind</a>). Примером таких методов может служить Q-обучение. </p>

<p>Двумя основными дисциплинами, на пересечении которых находится машинное обучение, являются статистика и математическая оптимизация. О статистике мы уже говорили в предыдущем разделе. Алгоритмы машинного обучения строят вероятностные модели, используя аппарат теории вероятностей и математической статистики, например, широко применяются такие инструменты, как байесовская статистика, анализ главных компонент, факторный анализ, анализ временных рядов, метод максимума правдоподобия, корреляционный анализ и т.д.</p>

<p>Оптимизация — это класс задач нахождения некоторых наилучших, оптимальных значений для достижения поставленной цели. Говоря более формально, задача оптимизации заключается в нахождении максимума или минимума (экстремума) целевой функции при выполнении некоторых линейных или нелинейных ограничений. Методами решения таких задач занимается математическое программирование. Оптимизация исключительно важна для машинного обучения, потому что после выбора модели необходимо найти её оптимальные параметры. Эта процедура сводится к минимизации некоторого функционала среднего риска</p>

<script type="math/tex; mode=display">
F(\theta) \to \min_{\theta},
</script>

<p>задаваемого с помощью меры ошибки. Например, достаточно распространённой является квадратичная мера ошибки, тогда </p>

<script type="math/tex; mode=display">
F(\theta) = \frac{1}{N} \sum_{k=1}^N (y_k - h_{\theta}(x_k))^2.
</script>

<p>Этот процесс и называется обучением. В машинном обучении широко применяются такие алгоритмы оптимизации, как градиентный спуск,  квазиньютоновский метод, метод множителей Лагранжа, стохастическая оптимизация и другие.</p>

<p>Методы оптимизации — это сердце каждого алгоритма машинного обучения, т.к. именно с помощью них происходит непосредственно обучение. От них во многом зависит скорость работы и количество используемых ресурсов. Развитие машинного обучения напрямую связано с развитием техник оптимизации. К примеру, открытие и развитие метода обратного распространения ошибки оказало большое влияние на возобновление интереса учёных и практиков к нейронным сетям. Многие открытые проблемы алгоритмов машинного обучения связаны с задачами оптимизации. <em>Вычислительная теория обучения</em> (<em>Computational Learning Theory</em>) занимается вопросами, во многом относящимися к оптимизации в машинном обучении. Существуют конференции, посвящённые проблемам оптимизации в машинном обучении, например крупная конференция <a href="http://orfe.princeton.edu/conferences/colt2015/the-conference/announcements/announcement-2014-10-04-134500">Conference on Learning Theory</a>. В последнее время в связи с развитием концепции Big Data становится актуальной задача распределённых вычислений и оптимизации в машинном обучении.</p>

<p>Кроме того, хочется отметить значимую роль машинного обучения в кибернетике и исследованиях, связанных с искусcтвенным интеллектом. Оно является важной частью ИИ, и развитие в этой области во многом сопряжено с прогрессом в машинном обучении. Алгоритмы машинного обучения позволяют компьютеру самостоятельно извлекать информацию из данных в процессе работы и помогают ему принимать решения. При использовании этих методов исследователи добиваются значительного прогресса в таких областях искусственного интеллекта, как понимание машиной текстов, человеческой речи, компьютерное зрение, синтез речи. Кроме того, с помощью алгоритмов машинного обучения создаются интеллектуальные сервисы, такие как переводчики с одного языка на другой, системы, рекомендующие контент на соответствующих сайтах и т.д. Учёные в области искусственного интеллекта активно занимаются исследованиями в машинном обучении, например, известный футуролог Рэймонд Курцвейл работает в должности технического директора в области машинного обучения и обработки естественного языка в компании Google.</p>

<h2 id="computer-science--">Computer Science и программирование</h2>

<p>Навыки в области Computer Science (информационных технологий) очень важны для того, кто занимается Data Science. В одной из <a href="http://www.quora.com/What-is-the-difference-between-a-data-scientist-and-a-statistician">дискуссий на Quora</a> я встретил такое определение: </p>

<blockquote>
  <p>Человек, занимающийся наукой о данных — это тот, кто лучше разбирается в статистике, чем любой программист, и лучше разбирается в программировании, чем любой статистик.</p>
</blockquote>

<p>Data scientist является практиком, а не теоретиком. Он постоянно работает с данными и исследует работу алгоритмов машинного обучения на практике. Для этого он использует различные технологии, языки программирования и библиотеки.</p>

<p>Для разработки прикладных программ тому, кто занимается наукой о данных, нужно знать некоторые теоретические вещи из Computer Science: классические алгоритмы и структуры данных, умение оценивать вычислительную сложность алгоритмов, знание принципов объектно ориентированного программирования и шаблонов проектирования. </p>

<p>Из языков программирования наиболее распространёнными и востребованными в области анализа данных являются Java, Python, C/C++, Scala. Также необходимы навыки работы с базами данных и знание SQL. Будут полезны навыки работы в Linux. Кроме того, существуют специализированные инструменты и библиотеки для использования методов машинного обучения и работы с данными, основные из них:</p>

<ul>
  <li>Библиотеки для Python: NumPy, SciPy, Pandas, IPython, scikit-learn, Nltk, Theano и другие;</li>
  <li>Язык программирования R — специализированный язык для анализа данных, имеет большое количество модулей, реализующих статистические инструменты и методы машинного обучения;</li>
  <li>Weka — инструментарий для анализа данных, написанный на Java;</li>
  <li>Apache Mahout — библиотека, реализованная на Java.</li>
</ul>

<p>Кроме вышеперечисленных, существуют языки Lua и Julia, которые не имеют такого широкого применения в науке о данных, однако в настоящее время для них активно разрабатываются библиотеки для анализа данных.</p>

<p>Важную роль в практической работе с данными играют инструменты Big Data. В их число входят:</p>

<ul>
  <li>Hadoop — реализация модели распределённых вычислений MapReduce и набор различных утилит и библиотек для выполнения распределённых вычислений. В его основе лежит файловая система HDFS;</li>
  <li>Pig — платформа для создания MapReduce приложений с помощью Hadoop; </li>
  <li>Hive, Impala — инфраструктуры хранилища данных, построенного на основе Hadoop;</li>
  <li>Spark — инструментарий для распределённого анализа данных;</li>
  <li>NoSQL базы данных: HBase, MongoDB, Apache Cassandra.</li>
</ul>

<p>На всех этапах анализа данных большую роль играет их визуализация. Полезно взглянуть на некоторые графические представления данных перед началом работы, чтобы лучше понять, какие методы имеет смысл применять. Во время проведения анализа графики могут помочь отобразить промежуточную картину, а после окончания работы с данными с помощью грамотной визуализации можно наглядно представить и объяснить полученные результаты. Рассмотрим основные инструменты визуализации:</p>

<ul>
  <li>Matplotlib — библиотека для языка Python, предназначенная для визуализации в стиле графиков Matlab;</li>
  <li>Язык R содержит большое количество способов визуализации данных. С помощью его инструментов можно легко рисовать различные статистические графики: гистограммы, ящики с усами, диаграммы рассеяния, доверительные интервалы, временные ряды и т.д. Отдельно хочется выделить ggplot2 — мощную библиотеку для создания информативных и красивых графиков;</li>
  <li>D3.js — мощная JavaScript-библиотека для обработки и визуализации данных, с помощью которой можно создавать интерактивные графики.</li>
</ul>

<h2 id="section-2">Прикладные области</h2>

<p>Завершая обзор науки о данных, хочется рассказать об областях её активного применения. Это далеко не полный перечень, в нём представлены наиболее интересные на мой взгляд и получившие в последнее время активное развитие направления. Эти прикладные области во многом связаны с искусственным интеллектом.</p>

<p>Компьютерное зрение (Computer Vision) — это технологии, позволяющие машине решать задачи оптического распознавания объектов. К примерам задач этого класса можно отнести:</p>

<ul>
  <li>Оптическое распознавание символов (Optical Character Recognition, OCR) — распознавание символов, таких как буквы и цифры. Применяется для цифровой обработки и распознавания отсканированных текстов, рукописных текстов, надписей, содержащихся на фотографиях;</li>
  <li>Распознавание образов — идентификация и классификация содержания изображения;</li>
  <li>Отслеживание объекта на видео (tracking);</li>
  <li>Понимание положения — оценка того, какое положение, какую позу занимает объект на изображении;</li>
  <li>Поиск изображения по содержанию — поиск изображений, которые отвечают заданному запросу. Запрос может быть задан различными путями, например, с помощью текста или картинки.</li>
</ul>

<p>Обработка естественного языка (Natural Language Processing, NLP) — технологии, связанные с анализом и синтезом естественных языков. Целью этого направления является разработка систем, понимающих тексты на обычном человеческом языке. Это направление является очень важной частью анализа данных. Примеры задач, которыми занимается NLP:</p>

<ul>
  <li>Тэгирование текста (Part-of-speech tagging) — автоматическое распознавание частей речи слов в тексте. Может применяться для выделения именованных сущностей;</li>
  <li>Построение синтаксического дерева (Parse tree) — с помощью него анализируется смысл предложения;</li>
  <li>Машинный перевод текста с одного языка на другой;</li>
  <li>Информационный поиск;</li>
  <li>Определение темы текста;</li>
  <li>Анализ тональности текста.</li>
</ul>

<p>Распознавание речи (Speech Recognition) и синтез речи — направления исследований, целью которых является создание машин, способных понимать и воспроизводить человеческую речь, что позволит разработать новые более естественные для человека интерфейсы взаимодействия с компьютером.</p>

<p>Современные поисковые системы активно используют разработки в области науки о данных (например, к ним можно отнести известный алгоритм PageRank). Рекомендательные системы, позволяющие определить, что будет интересно пользователю на основе информации о нём и о его действиях в системе, также являются областью приложения для Data Science. Другим активно развивающимся направлением является биоинформатика, которая занимается исследованием генов, структуры белков и биологических систем.</p>

<h2 id="section-3">Заключение</h2>

<p>В этой статье я сделал обзор науки о данных такой, какой я её понимаю. В качестве некоторого summary этого обзора хочу привести прекрасную иллюстрацию дороги, которую необходимо пройти датологу (<a href="http://nirvacana.com/thoughts/becoming-a-data-scientist/">первоисточник</a>):</p>

<p><img src="http://datadeep.ru/images/RoadToDataScientist1.png" title="Data Scientist Road" /></p>

<p>Конечно, невозможно объять необъятное, поэтому специалистов, занимающихся наукой о данных, можно разделить на две категории:</p>

<ol>
  <li>Аналитики — эти люди заточены на анализ данных, чаще всего они приходят из статистики или математики. Они занимаются построением моделей из данных, вытаскиванием из них информации с помощью методов статистики и машинного обучения;</li>
  <li>Разработчики — эти люди прекрасно владеют всем тем, что было описано в разделе “Computer Science и программирование”. Они заточены на создание конечных, работающих с пользователем продуктов. Они умеют добывать, хранить и манипулировать данными.</li>
</ol>

<p>Такая классификация является очень условной, это два крайних класса, чаще всего на практике датологи попадают в среднюю между этими двумя категорию, согласно своим интересам и профессиональным обязанностям. </p>

<p>В дальнейшем в блоге datadeep.ru наша команда будет развивать и дополнять многие темы, затронутые в этой статье.</p>

<h2 id="data-science">Полезные материалы по Data Science</h2>

<p>Существует большое количество литературы, ресурсов в Интернете, online-курсов, посвящённых Data Science. Приведу ссылки на наиболее базовые и полезные на мой взгляд материалы:</p>

<ul>
  <li>Книги по Data Science и Machine Learning:
    <ul>
      <li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a>, Trevor Hastie, Robert Tibshirani, Jerome Friedman;</li>
      <li><a href="http://research.microsoft.com/en-us/um/people/cmbishop/PRML/">Pattern Recognition and Machine Learning</a>, Christopher M. Bishop;</li>
      <li><a href="http://www.cambridge.org/us/academic/subjects/computer-science/knowledge-management-databases-and-data-mining/data-mining-and-analysis-fundamental-concepts-and-algorithms">Data Mining and Analysis: Fundamental Concepts and Algorithms</a>, Mohammed J. Zaki, Wagner Meira Jr.;</li>
      <li><a href="http://www.recognition.mccme.ru/pub/RecognitionLab.html/slbook.pdf">Введение в методы статистического обучения</a>, А. Б. Мерков.</li>
    </ul>
  </li>
  <li>Книги по инструментам Data Science:
    <ul>
      <li><a href="http://shop.oreilly.com/product/0636920023784.do">Python for Data Analysis</a>, Wes McKinney;</li>
      <li><a href="http://shop.oreilly.com/product/0636920018483.do">Machine Learning for Hackers</a>, Drew Conway, John Myles White.</li>
    </ul>
  </li>
  <li>Online-курсы:
    <ul>
      <li><a href="https://www.coursera.org/course/ml">Machine Learning</a> на Coursera, преподаватель Andrew Ng;</li>
      <li><a href="https://www.edx.org/course/caltechx/caltechx-cs1156x-learning-data-2516#.VFqFQfmsWSo">Learning From Data</a> на edX, преподаватель Yaser S. Abu-Mostafa.</li>
    </ul>
  </li>
  <li>Полезные ресурсы, посвящённые Data Science:
    <ul>
      <li><a href="http://www.kdnuggets.com/">KDnuggets.com</a> — ресурс с большим количеством новостей и информации от создателя термина Data Mining Григория Пятецкого-Шапиро; </li>
      <li><a href="http://www.datasciencecentral.com/">datasciencecentral.com</a> — ресурс, содержащий блоги по статистике, машинному обучению и науке о данных в целом;</li>
      <li><a href="http://www.kaggle.com/">kaggle.com</a> — собрание соревнований по Data Science;</li>
      <li><a href="http://machinelearningmastery.com/blog/">machinelearningmastery.com</a> — блог по вопросам, связанным с машинным обучением;</li>
      <li><a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%97%D0%B0%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D0%B0">machinelearning.ru</a> — ресурс, посвящённый машинному обучению и анализу данных.</li>
    </ul>
  </li>
</ul>
]]></content>
  </entry>
  
</feed>
