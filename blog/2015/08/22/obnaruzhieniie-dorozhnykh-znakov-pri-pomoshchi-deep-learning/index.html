
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Обнаружение дорожных знаков при помощи Deep Learning - DataDeep</title>
  <meta name="author" content="Команда datadeep.ru">

  
  <meta name="description" content="Обнаружение дорожных знаков при помощи Deep learning">
  <meta name="keywords" content="machine learning, deep learning, computer vision">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://datadeep.ru/blog/2015/08/22/obnaruzhieniie-dorozhnykh-znakov-pri-pomoshchi-deep-learning">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="DataDeep" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-56118002-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">DataDeep</a></h1>
  
    <h2>Sapere aude</h2>
  
</hgroup>

</header>
  <nav role="navigation">
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:datadeep.ru" />
    <input class="search" type="text" name="q" results="0" placeholder="Поиск"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Блог</a></li>
  <li><a href="/blog/archives">Архив блога</a></li>
  <li><a href="/about_blog">О блоге</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Обнаружение дорожных знаков при помощи Deep Learning</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-08-22T15:15:32+03:00'><span class='date'>22/08/2015</span> <span class='time'>15:15</span></time>
        
           | <a href="#disqus_thread"
             data-disqus-identifier="http://datadeep.ru">Комментарии</a>
        
      </p>
    
  </header>


<div class="entry-content"><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.6/d3.min.js"></script>

<script type="text/javascript" src="http://code.jquery.com/jquery-1.11.3.min.js"></script>

<script type="text/javascript" src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

<link href="/d3/bootstrap_tooltip_popover.css" rel="stylesheet" />

<p>Команда блога DataDeep не смогла остаться в стороне от <a href="https://meduza.io/news/2015/07/17/samoupravlyaemaya-mashina-google-popala-v-pervoe-dtp-s-postradavshimi">новости об аварии самоуправляемого автомобиля Google</a>, и поэтому я решил написать пост о своём опыте разработки системы для обнаружения дорожных знаков, основанной на машинном обучении. Такую систему вполне можно отнести к компонентам, которые используются как для разработки механизмов автономного упраления автомобилем, так и в современных системах помощи водителю :)  </p>

<p><img src="/images/selfdrivingcar.jpg" width="768" height="576" title="Self-driving car" /></p>

<!-- more -->

<h2 id="section">Постановка задачи, описание данных</h2>

<p>Итак, мы хотим сделать приложение, которое будет максимально достоверно находить и выделять рамкой (region of interest, ROI) дорожные знаки на изображении, поступившем на вход. Сердцем метода, решающего эту задачу, будет, как не трудно предположить, машинное обучение. Для использования такого подхода необходимы тренировочные данные, в качестве которых будем использовать данные с соревнования <a href="http://benchmark.ini.rub.de/?section=gtsdb&amp;subsection=dataset">The German Traffic Sign Detection Benchmark</a>. Это соревнование по детектированию и определению категории дорожного знака, которое проводилось в 2013 году. В этих данных содержится информация о знаках из нескольких категорий, таких как предупреждающие, приоритета, запрещающие и предписывающие. Парным к нему является соревнование по распознаванию знаков The German Traffic Sign Recognition Benchmark, в котором алгоритм, построенный на основе глубоких нейронных сетей (deep learning), <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html?_r=0">превзошёл по точности распознавания уровень человека</a>. </p>

<p>Данные представляют собой 900 изображений размером $1360 \times 800$ в формате ppm, а также 1213 изображений дорожных знаков, взятых с этих картинок, размером от $16\times16$ до $128\times128$ в формате ppm.  Некоторые из больших изображений содержат один и более знак, в то время, как другие не содержат знаков вовсе. ROI задаётся с помощью четырёхмерного вектора с координатами прямоугольной рамки <script type="math/tex">(x_{min}, y_{min}, x_{max}, y_{max})</script>. Для всех 900 изображений заданы правильные ROI. Несколько примеров из данных:</p>

<p>Один дорожный знак:</p>

<p><img src="/images/0.jpg" title="Один знак" /></p>

<p>Два знака:</p>

<p><img src="/images/1.jpg" title="Два знака" /></p>

<p>Без знаков:</p>

<p><img src="/images/2.jpg" title="Без знаков" /></p>

<p>Таким образом, наша задача заключается в том, чтобы обучить алгоритм, который для входного изображения будет выдавать ноль или более четырёхмерных векторов по числу обнаруженных дорожных знаков.      </p>

<h2 id="state-of-the-art-">Обзор <em>state of the art</em> подходов</h2>

<p>Начиная примерно с 2012 года, когда на очень известном в сообществе computer vision соревновании по распознаванию изображений <a href="http://www.image-net.org/">ImageNet</a> победила команда университета Торонто под руководством Джеффри Хинтона, показав при этом значительный отрыв в точности от других команд, state of the art методом для распознавания изображений считается использование глубоких свёрточных нейронных сетей (Convolutional neural network, CNN), которые, в свою очередь, являются представителем класса алгоритмов машинного обучения deep learning (глубокое или, если угодно, глубинное обучение). Очень многие лучшие на сегодняшний день системы машинного зрения основаны на CNN, например <a href="https://research.facebook.com/publications/480567225376225/deepface-closing-the-gap-to-human-level-performance-in-face-verification/">система распознавания лиц от Facebook</a> (к слову, глава Facebook AI Research Ян Лекун является одним из пионеров в исследовании CNN и deep learning). </p>

<p>В области детектирования предметов на изображении одним из самых эффективных является метод <em>Regions with CNN features</em> или <em>R-CNN</em>, представленный в 2014 году. Этот метод можно разделить на следующие этапы:</p>

<ol>
  <li>Определение областей изображения, которые могут содержать интересующие нас объекты, с помощью алгоритма <em>Selective search</em>;</li>
  <li>Выделение из полученных областей признаков, используя свёрточную нейронную сеть;</li>
  <li>Эти признаки подаются на вход SVM (support vectors machine), которая классифицирует объект.</li>
</ol>

<p>Существуют и другие успешные методы детектирования, основанные на CNN, например <a href="http://arxiv.org/abs/1312.6229">построение регрессии</a> для нахождения четырёхмерного вектора ROI (т.е. на последнем уровне CNN находятся не вероятности, а целые значения). Однако, идея алгоритма, который мы будем строить, вдохновлена в первую очередь R-CNN, благодаря его простоте и эффективности, и реализует три его этапа, хотя имеет ряд значительных отличий. </p>

<h2 id="section-1">Описание метода</h2>

<p>Перед тем, как описать структуру метода для обнаружения дорожных знаков на изображении, скажу пару слов о технологиях, которые будут использованы. В качестве языка программирования применяется Python, так как для него есть API всех необходимых библиотек, и в данном случае нам больше важна гибкость и лёгкость прототипирования, чем скорость работы приложения. </p>

<p>Вся работа со свёрточными нейронными сетями ведётся с помощью изумительной библиотеки <a href="http://caffe.berkeleyvision.org/">Caffe</a>. Она позволяет конструировать, обучать и применять CNN, содержит state of the art виды слоёв и методы тренировки сети, обрабатывает данные в различных форматах (в том числе HDF5), позволяет обучать сети на графическом процессоре (GPU) с использованием CUDA, имеет обёртку для Python pycaffe. Для Caffe есть хранилище Model zoo, в котором содержаться обученные модели, которые можно использовать для своих задач. Также хочется отметить хорошие туториалы и большое сообщество. Архитектура нейронных сетей и параметры метода обучения задаются в Caffe в файлах <a href="https://developers.google.com/protocol-buffers/docs/overview">формата prototxt</a>.</p>

<p>Для обработки изображений используется библиотека OpenCV, которая, я думаю, не нуждается в дальнейшем представлении. </p>

<h3 id="mser">Детектор MSER</h3>

<p>Приступим непосредственно к методу решения задачи. На первом этапе будем определять области входного изображения, которые потенциально могут содержать дорожный знак. Для этого было рассмотрено несколько детекторов (в частности selective search из R-CNN, который не смог хорошо выделить области со знаками). Метрикой качества служило среднее евкидово расстояние между настоящим ROI на изображениях из тренировочных данных и ближайшим к нему ROI, полученным с помощью детектора.   Лучше всего себя показал метод <a href="https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions">MSER</a> (maximally stable extremal regions). Из выделенных MSER областей отбирались те, в которых длина и ширина лежат в пределах от 16 до 128 и их соотношение не превышает 1.5 (т.е. более-менее близки по форме к квадрату). Таким образом, мы получаем набор областей, в которых может содержаться один дорожный знак.</p>

<h3 id="main-cnn">Main CNN</h3>

<p>На следующем этапе алгоритма для определения того, содержит ли область изображения из предыдущего этапа знак, будем применять классификатор. В этом качестве выступит представитель класса методов deep learning — глубокая свёрточная нейронная сеть. Ей на вход будет поступать изображение, а на выходе будут две вероятности, сумма которых равна 1: того, что изображение содержит и не содержит дорожный знак. Архитектура нейронной сети, которую мы будем использовать, сходна c архитектурой весьма эффективной сети <em>Network in network</em> (NIN), которая хорошо себя показала в 2014 году в конкурсе <a href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> (определение, к какой из 10 категорий принадлежит изображение). </p>

<p>На вход нейронная сеть получает RGB изображение размером $32\times32$, которое предварительно преобразуется в такой формат, если нужно. Рассмотрим вкратце слои сети: </p>

<ul>
  <li><em>Свёрточный слой</em> (CONVOLUTION) — как видно из названия, является основной частью CNN. Он реализует обычную операцию свёртки: мы идём по изображению скользящим окном, перемножаем значения в окне с заданными весами (ядром), а затем всё складываем. Наборов весов может быть несколько. Проиллюстрируем то, что делает свёрточный слой (картинка взята с <a href="http://habrahabr.ru/">хабра</a>):</li>
</ul>

<p><img src="/images/cnn_principle.png" title="Свёртка" /> </p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)"><em>Rectified linear unit</em></a> (RELU) — слой, в котором нет какой-то сложной математики и, как следствие, настраиваемых параметров. Он служит для того, чтобы получить нелинейность. К каждому входному значению этого слоя применяется функция:</li>
</ul>

<p><img src="/images/relu.jpeg" title="Rectified linear unit" /></p>

<p>Это то, что происходит в нейроне, так называемая <em>activasion function</em>. В “классических” нейронных сетях для этого используется сигмоидная функция или тангенс. Однако в последнее время эмпирически было установлено, что простая функция RELU оказывается очень эффективной.</p>

<ul>
  <li>
    <p><em>Pooling</em> (POOLING) — служит для уменьшения размерности. Входной двумерный массив делится на сектора, в зависимости от параметров, и в каждом из них происходит максимизация (MAX) или усреднение (AVE) (два самых распространённых вида pooling’а).</p>
  </li>
  <li>
    <p><em>Dropout</em> (DROPOUT) — недавно открытый, очень эффективный и простой способ регуляризации (т.е. снижения эффекта переобучения). Его суть заключается в том, что с заданной вероятностью нейроны сети отключаются и не участвуют в текущей итерации обучения. </p>
  </li>
</ul>

<p>Архитектура всей сети представляет собой 3 больших последовательно соединённых слоя, каждый из которых состоит из [CONVOLUTION -&gt; RELU -&gt; CONVOLUTION -&gt; RELU -&gt; CONVOLUTION -&gt; RELU -&gt; POOLING -&gt; DROPOUT]. На самом последнем слое мы получаем две вероятности. Назовём эту сеть <em>Main CNN</em>. </p>

<h4>Структура Main CNN (при наведении на слой отображаются его параметры)</h4>

<div id="container">     
</div>

<script type="text/javascript">

function removetooltips () {
  $('.tooltip').each(function() {
    $(this).remove();
  }); 
}

function showtooltip (d) {
  $(this).tooltip({
	animation: true,  
    placement: 'auto right',
    container: 'body',
    trigger: 'manual',
    html : true,
    title: function() { 
	  var info
	  
	  if (d.type == "DATA"){
	          info = d.description
          }
      else{    
      info = 
      "<strong>Название</strong>: " + d.name + "<br><strong>Тип</strong>: " + d.type;
      
      if (d.type=="CONVOLUTION"){
			  info+=
			  '<hr><em>Параметры слоя:</em><br>'+"<strong>Число элементов на выходе</strong>: "+d.convolution_param.num_output
			  +'<br>'+"<strong>Размер ядра</strong>: "+d.convolution_param.kernel_size
			  +'<br>'+"<strong>Инициализация весов</strong>: "+d.convolution_param.weight_filler.type
			  +'<br>'+"<strong>Инициализация смещения</strong>: "+d.convolution_param.bias_filler.type
			  ;
		  }
		  
	 if (d.type=="POOLING"){
			  info +=
			  '<hr><em>Параметры слоя:</em><br>'+"<strong>Тип pooling'а</strong>: "+d.pooling_param.pool
			  +'<br>'+"<strong>Размер ядра</strong>: "+d.pooling_param.kernel_size
			  +'<br>'+"<strong>Шаг</strong>: "+d.pooling_param.stride
			  ;
		  }
		  
		  if (d.type=="DROPOUT"){
			  info+='<hr><em>Параметры слоя:</em><br>'+"<strong>Вероятность dropout'а</strong>: "+d.dropout_param.dropout_ratio
			  ;
		  }	  
        }
      
      
      return info;
      }
  });
  $(this).tooltip('show')
}


        
var margin = {top: 0, right: 0, bottom: 20, left: 10}

var width = 700 - margin.left - margin.right
var height = 640 - margin.top - margin.bottom

var svg = d3.select("#container").append("svg")
        .attr("width", width + margin.left + margin.right)
        .attr("height", height + margin.top + margin.bottom)
        .append("g")
        .attr("transform", "translate(" + margin.left + "," + margin.top + ")")   
         	
       
var colors = d3.scale.category10();  

var w = 150;   

//Read JSON file    
        
d3.json("/d3/layers.json",function(data){
			

var  Network  = svg.append("g").attr("class","Network");
                      
              
                      
                
h = (height/ data.layers.length);
   
var layer = Network.selectAll("g.layer")
                    .data(data.layers)
                    .enter()
                    .append("g")
                    .attr("class","layer")
                    .attr("transform",function(d,i){
	                    var dy = i*h;
	                    return 'translate(0,'+dy+')'
                    });
                    


var lrect = layer.append("rect")
				.attr('class',"layerrect")
				.attr("x",0)  
				.attr("y",0)
				.attr("rx",function(d){
					if(d.type=="DROPOUT"){return 12}
						else if (d.type=="RELU"){return 0}
							else
								{return 5}
					})
				.attr("height",h-5)
				.attr("width",w)
				.style("fill",function(d){
						return colors(d.type)			
				})
				.style("fill-opacity",0.7);

layer.append("rect")
	.attr('class',"arrow")
	.attr("x",w/2-1)  
	.attr("y",h-5)                  
	.attr("height",function(d,i){if(i<data.layers.length-1) {return 5} else {return 0};})
	.attr("width",2)
	.style("fill",function(d){
						return colors(d.type)			
	})
	.style("fill-opacity",0.7);


layer.append("text")
	.attr("dy", h/2+2)
	.attr("dx",w/2)
	.attr("fill","white")
	.style("text-anchor", "middle")
	.text(function(d){return d.name})

layer.on("mouseover", function(d,i) { 
									d3.select(this).select(".layerrect")
												   .attr( "width", w+10);
									showtooltip.call(this, d);                  
			                                               } )
     .on("mouseout", function() { 
	     							d3.select( this ).select(".layerrect")
	     											 .transition()
			                                         .ease("elastic")
			                                         .attr( "width", w);
			                        removetooltips();
			                                                } )

	return data;	
})

             
</script>

<p><a href="https://github.com/andrewbo29/traffic_signs_detector/blob/master/model/signet_nin_finetune_train_val.prototxt">Полное описание свёрточной нейронной сети</a> в формате prototxt, которое применятся для её обучения с помощью Caffe.</p>

<p>Для того, чтобы обучить всю эту сеть, будем использовать стандартный метод оптимизации <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Batch stochastic gradient descent</a> с уменьшением параметра learning rate в 10 раз каждые 1000 шагов, начальный learning rate — 0.000001. Кроме того, применим метод Momentum Нестерова с параметром 0.9. В качестве регуляризации будем использовать <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">Weight decay</a> с параметром 0.0001. Обучение будет остановлено или при достижении максимального количества итераций, или при малом изменении функции потерь. Prototxt файл со всеми параметрами оптимизации, который используется в Caffe:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Solver</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="json"><span class="line"><span class="err">test_iter:</span> <span class="mi">100</span>
</span><span class="line"><span class="err">test_interval:</span> <span class="mi">1000</span>
</span><span class="line"><span class="err">base_lr:</span> <span class="mf">0.000001</span>
</span><span class="line"><span class="err">momentum:</span> <span class="mf">0.9</span>
</span><span class="line"><span class="err">weight_decay:</span> <span class="mf">0.0001</span>
</span><span class="line"><span class="err">lr_policy:</span> <span class="s2">&quot;step&quot;</span>
</span><span class="line"><span class="err">gamma:</span> <span class="mf">0.1</span>
</span><span class="line"><span class="err">stepsize:</span> <span class="mi">1000</span>
</span><span class="line"><span class="err">display:</span> <span class="mi">100</span>
</span><span class="line"><span class="err">max_iter:</span> <span class="mi">50000</span>
</span><span class="line"><span class="err">snapshot:</span> <span class="mi">1000</span>
</span><span class="line"><span class="err">solver_mode:</span> <span class="err">GPU</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Для ускорения обучения будем применять подход <em>Fine-tuning</em>: веса нейронной сети инициализируются предобученными для другой (но похожей) задачи. Мы используем веса, которые были обучены авторами NIN для задачи CIFAR-10.</p>

<h3 id="features-learning-cnn">Features learning CNN</h3>

<p>Итак, с помощью описанной выше CNN мы отберём области изображения, скорее всего содержащие знак (т.е. те, для которых вероятность наличия знака, выданная сетью, больше порога 0.5). Для того, чтобы улучшить качество распознавания, построим поверх нейронной сети ещё один классификатор. Для этого будем использовать CNN, аналогичную той, которую мы уже построили, только без последних двух слоёв pooling’а и вероятностей. Если посмотреть на параметры в описании архитектуры используемой CNN, то от туда можно понять, что новая сеть будет выдавать на выходе вектор размерности 128. Назовём её <em>Features learning CNN</em>. В качестве весов она использует натренированные веса Main CNN. Features learning CNN мы будем применять к областям изображений, которые по мнению Main CNN содержат дорожный знак.  Мы получим 128-размерный вектор признаков, который будем “скармливать” машине опорных векторов (SVM) с полиномиальным ядром степени 2 и параметром регуляризации 0.1.</p>

<p>Таким образом, полный алгоритм представляет собой ансамбль:</p>

<p><img src="/images/pipeline.png" title="Pipeline" /></p>

<h3 id="bootstrap">Bootstrap</h3>

<p>Для того, чтобы нарисовать ROI, содержащую дорожный знак, нам остался ещё один шаг. В силу особенностей метода MSER может получиться ситуация, когда для одного знака получается несколько очень близко расположенных рамок (т.е. областей изображения, отобранных на предыдущем этапе). Объединив такие рамки в одну (взяв наибольшую из них), мы получим финальный ROI. </p>

<h2 id="section-2">Применение метода</h2>

<p>Теперь опишем то, как обучался алгоритм и что из этого вышло. Прежде всего, нам необходимы тренировочные данные для Main CNN. Разделим имеющиеся в нашем распоряжении 900 изображений на 600 тренировочных и 300 тестовых. В исходных данных уже есть изображения дорожных знаков, т.е. положительные прецеденты, однако нет отрицательных, т.е. изображений без знаков. Для того, чтобы получить эти данные, используем следующую процедуру: к каждому изображению из тренировочных данных применяется MSER и отбираются те его области, которые похожи по размерам на ROI (см. выше), не пересекаются с настоящим ROI, но при этом лежат относительно “не далеко” от него. Последний пункт нужен, т.к. CNN будет хорошо “отличать” дорожный знак от, например, неба или асфальта, но плохо от окна, фары машины, листвы и т.д., т.е. от объектов, которые на изображении находятся достаточно близко к знаку. Таким образом, если мы будем брать любые области, не пересекающиеся с ROI, то большинство из них будет содержать небо, дорожное покрытие, стены домов и т.п., что негативно отразится на качестве классификации. Всего таких отрицательных прецедентов отберём около 2000, чтобы выборка для обучения Main CNN была сбалансированной.</p>

<p>Примеры положительных прецедентов:</p>

<p><img src="/images/train_main_cnn_plus.png" title="Положительные прецеденты" /></p>

<p>Примеры отрицательных прецедентов:</p>

<p><img src="/images/train_main_cnn_minus.png" title="Отрицательные прецеденты" /></p>

<p>Чтобы улучшить качество распознавания дорожных знаков с помощью Main CNN будем использовать трюк, который является формой boosting’а:</p>

<ol>
  <li>Обучим Main CNN на полученных нами на предыдущем этапе тренировочных данных;</li>
  <li>Определим, на каких отрицательных прецедентах Main CNN ошибается;</li>
  <li>Сформируем из них и положительных прецедентов новую тренировочную выборку;</li>
  <li>Продолжим обучение Main CNN с помощью Fine-tuning, где в качестве начальных весов используются веса, полученные в пункте 1;</li>
  <li>Повторим пункты 1–4 три раза.</li>
</ol>

<p>Примеры новых отрицательных прецедентов:</p>

<p><img src="/images/train_main_cnn_new_minus.png" title="Новые отрицательные прецеденты" /></p>

<p>При обучении SVM на изначальных тренировочных данных Main CNN результаты следующие: F1-score — 0.85, точность — 0.85.</p>

<p>После тренировки всех частей ансамбля алгоритмов мы можем применить их к тестовым данным. В качестве метрики точности для изображений, содержащих дорожные знаки, возьмём наименьшее евклидово расстояние между векторами, описывающими ROI. Это не самая точная метрика, однако она даёт представление о качестве работы метода. Результаты на тестовых данных (300 изображений): 39.9; число случаев, когда алгоритм не показал ROI, а они есть (False negative): 33; число случаев, когда алгоритм показал ROI, а их нет (False positive): 5. Ниже представлено несколько характерных примеров работы алгоритма.</p>

<p>Все знаки правильно обнаружены:</p>

<p><img src="/images/all_1.jpeg" title="Все знаки" /></p>

<p><img src="/images/all_2.jpeg" title="Все знаки" /></p>

<p><img src="/images/all_3.jpeg" title="Все знаки" /></p>

<p>Алгоритм может ошибаться, принимая такие объекты, как фара машины, за знак:</p>

<p><img src="/images/light.jpeg" title="Фара машины" /></p>

<p>Иногда алгоритм находит не все знаки:</p>

<p><img src="/images/not_all.jpeg" title="Не все знаки" /></p>

<p>False positive:</p>

<p><img src="/images/false_positive.jpeg" title="False positive" /></p>

<p><img src="/images/false_positive_2.jpeg" title="False positive" /></p>

<h2 id="section-3">Заключение</h2>

<p>Подводя итог, можно сказать, что был разработан несложный, но вполне рабочий алгоритм, основанный на deep learning для обнаружения дорожных знаков на изображении. В силу того, что обучение происходило на машине с относительно слабой конфигурацией (8 Гб оперативной памяти, GPU: GeForce 730, 2Гб памяти), увеличение вычислительных мощностей и добавление дополнительных данных приведёт к улучшению качества работы как свёрточной нейронной сети, так и SVM. </p>

<p>В статье мы рассмотрели использование CNN, коснулись ReLU, Pooling, Dropout и других понятий, входящих в такую область машинного обучения, как deep learning. Для того, чтобы больше узнать об этом стремительно набирающем в последние несколько лет популярность направлении, в дальнейшем будет сделан цикл статьей по теории и практике глубоких нейронных сетей, благо название блога обязывает! </p>

<h2 id="section-4">Ссылки</h2>

<ol>
  <li><a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Статья с описанием метода команды университета Торонто</a>  </li>
  <li><a href="http://www.cs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf">Regions with CNN features</a></li>
  <li><a href="http://arxiv.org/abs/1312.4400">Network in network</a></li>
  <li><a href="https://github.com/andrewbo29/traffic_signs_detector">Код на github</a></li>
</ol>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Опубликовал <span class="fn">Andrei Boiarov</span></span>

      




<time class='entry-date' datetime='2015-08-22T15:15:32+03:00'><span class='date'>22/08/2015</span> <span class='time'>15:15</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/deep-learning/'>deep learning</a>, <a class='category' href='/blog/categories/komp'iutiernoie-zrieniie/'>Компьютерное зрение</a>, <a class='category' href='/blog/categories/mashinnoie-obuchieniie/'>Машинное обучение</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://datadeep.ru/blog/2015/08/22/obnaruzhieniie-dorozhnykh-znakov-pri-pomoshchi-deep-learning/" data-via="" data-counturl="http://datadeep.ru/blog/2015/08/22/obnaruzhieniie-dorozhnykh-znakov-pri-pomoshchi-deep-learning/" >Tweet</a>
  
  
  <div class="g-plusone" data-size="medium"></div>
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
  
    <div id="vk_like"></div>
    <script type="text/javascript">
    window.onload = function () {
        VK.init({apiId: 4631132, onlyWidgets: true});
        VK.Widgets.Like("vk_like", {type: "mini"});
    }
    </script>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/12/04/kratkoie-vviedieniie-v-d3-dot-js/" title="Previous Post: Краткое введение в D3.js">&laquo; Краткое введение в D3.js</a>
      
      
        <a class="basic-alignment right" href="/blog/2015/09/02/mnoghoobraziie-vizualizatsii/" title="Next Post: Многообразие визуализаций">Многообразие визуализаций &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Комментарии</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Недавние Посты</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/10/28/tiematichieskoie-modielirovaniie-ighry-priestolov/">Тематическое моделирование Игры Престолов</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/09/02/mnoghoobraziie-vizualizatsii/">Многообразие визуализаций</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/22/obnaruzhieniie-dorozhnykh-znakov-pri-pomoshchi-deep-learning/">Обнаружение дорожных знаков при помощи Deep Learning</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/04/kratkoie-vviedieniie-v-d3-dot-js/">Краткое введение в D3.js</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/11/20/optimizatsiia-v-mashinnom-obmuchienii/">Оптимизация в машинном обучении</a>
      </li>
    
  </ul>
</section>




<section>
  <h1>Категории</h1>
    <ul id="category-list"><li><a href='/blog/categories/deep-learning'>deep learning (1)</a></li><li><a href='/blog/categories/vizualizatsiia'>Визуализация (4)</a></li><li><a href='/blog/categories/komp-iutiernoie-zrieniie'>Компьютерное зрение (1)</a></li><li><a href='/blog/categories/mashinnoie-obuchieniie'>Машинное обучение (4)</a></li><li><a href='/blog/categories/obrabotka-tieksta'>Обработка текста (1)</a></li><li><a href='/blog/categories/optimizatsiia'>Оптимизация (1)</a></li><li><a href='/blog/categories/proghrammirovaniie'>Программирование (1)</a></li><li><a href='/blog/categories/statistika'>Статистика (1)</a></li><li><a href='/blog/categories/tiematichieskoie-modielirovaniie'>Тематическое моделирование (1)</a></li></ul>
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Команда datadeep.ru -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'datadeep';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://datadeep.ru/blog/2015/08/22/obnaruzhieniie-dorozhnykh-znakov-pri-pomoshchi-deep-learning/';
        var disqus_url = 'http://datadeep.ru/blog/2015/08/22/obnaruzhieniie-dorozhnykh-znakov-pri-pomoshchi-deep-learning/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>




  <script type="text/javascript" src="//vk.com/js/api/openapi.js?75"></script>




</body>
</html>

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

